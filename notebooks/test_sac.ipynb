{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa780004",
   "metadata": {},
   "source": [
    "# SAC smoke test on HalfCheetah-v5\n",
    "\n",
    "Minimal setup that instantiates the SAC agent with a short HalfCheetah-v5 rollout so we can sanity-check wiring before running long experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc22a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fwu/miniforge3/envs/SL/lib/python3.11/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/fwu/miniforge3/envs/SL/lib/python3.11/site-packages/torch/cuda/__init__.py:1034: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
      "  r = torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "/home/fwu/miniforge3/envs/SL/lib/python3.11/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/fwu/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/collectors/collectors.py:882: UserWarning: total_frames (1000000) is not exactly divisible by frames_per_batch (256). This means 192 additional frames will be collected.To silence this message, set the environment variable RL_WARNINGS to False.\n",
      "  warnings.warn(\n",
      "/home/fwu/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/collectors/collectors.py:899: UserWarning: init_random_frames (25000) is not exactly a multiple of frames_per_batch (256),  this results in more init_random_frames than requested (25088).To silence this message, set the environment variable RL_WARNINGS to False.\n",
      "  warnings.warn(\n",
      "Model Overview:\n",
      "<rlopt.agent.sac.sac.SAC object at 0x7f95f8a9a4d0>\n",
      "Policy Network:\n",
      "ProbabilisticActor(\n",
      "    module=ModuleList(\n",
      "      (0): TensorDictModule(\n",
      "          module=Sequential(\n",
      "            (0): MLP(\n",
      "              (0): Linear(in_features=17, out_features=256, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (3): ReLU()\n",
      "              (4): Linear(in_features=256, out_features=12, bias=True)\n",
      "            )\n",
      "            (1): NormalParamExtractor(\n",
      "              (scale_mapping): biased_softplus()\n",
      "            )\n",
      "          ),\n",
      "          device=cpu,\n",
      "          in_keys=['observation'],\n",
      "          out_keys=['loc', 'scale'])\n",
      "      (1): SafeProbabilisticModule(\n",
      "          in_keys=['loc', 'scale'],\n",
      "          out_keys=['action'],\n",
      "          distribution_class=<class 'torchrl.modules.distributions.continuous.TanhNormal'>, \n",
      "          distribution_kwargs={'low': tensor([-1., -1., -1., -1., -1., -1.]), 'high': tensor([1., 1., 1., 1., 1., 1.]), 'tanh_loc': False}),\n",
      "          default_interaction_type=random),\n",
      "          num_samples=None))\n",
      "    ),\n",
      "    device=cpu,\n",
      "    in_keys=['observation'],\n",
      "    out_keys=['loc', 'scale', 'action'])\n",
      "Q Network:\n",
      "ValueOperator(\n",
      "    module=MLP(\n",
      "      (0): Linear(in_features=23, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    ),\n",
      "    device=cpu,\n",
      "    in_keys=['observation', 'action'],\n",
      "    out_keys=['state_action_value'])\n",
      "  0%|          | 256/1000000 [00:00<07:08, 2332.44it/s]step=256 | train/step_reward_mean=-0.18363451957702637, train/step_reward_std=0.6767148971557617, train/step_reward_max=1.8876136541366577, train/step_reward_min=-1.8377811908721924, time/collect=0.10974359512329102, time/replay_extend=0.0007984638214111328, time/train=2.384185791015625e-07, time/speed=2332.44160216878\n",
      "  0%|          | 512/1000000 [00:00<07:12, 2310.00it/s, r_step=-0.18]step=512 | train/step_reward_mean=-0.07241284847259521, train/step_reward_std=0.5250347852706909, train/step_reward_max=1.272758960723877, train/step_reward_min=-1.7371647357940674, time/collect=0.10970199108123779, time/replay_extend=0.0006144046783447266, time/train=3.5762786865234375e-07, time/speed=2309.9997390533053\n",
      "  0%|          | 768/1000000 [00:00<07:11, 2314.15it/s, r_step=-0.07]step=768 | train/step_reward_mean=-0.42607370018959045, train/step_reward_std=0.7441734075546265, train/step_reward_max=1.8906986713409424, train/step_reward_min=-2.4985897541046143, time/collect=0.10949921607971191, time/replay_extend=0.0005502700805664062, time/train=3.178914388020833e-07, time/speed=2314.1493385065432\n",
      "  0%|          | 1024/1000000 [00:00<07:06, 2340.87it/s, r_step=-0.43]step=1024 | train/step_reward_mean=-0.40508341789245605, train/step_reward_std=0.6107516884803772, train/step_reward_max=1.1719036102294922, train/step_reward_min=-1.8140990734100342, episode/length=1000.0, episode/return=-263.9434814453125, episode/return_latest=-263.9434814453125, episode/num_completed=1.0, time/collect=0.10861331224441528, time/replay_extend=0.0005179643630981445, time/train=3.5762786865234375e-07, time/speed=2340.8682889741335\n",
      "  0%|          | 1280/1000000 [00:00<07:04, 2355.04it/s, r_step=-0.41, r_ep=-263.9, n_ep=1]step=1280 | train/step_reward_mean=-0.3385678827762604, train/step_reward_std=0.6746117472648621, train/step_reward_max=1.7142950296401978, train/step_reward_min=-2.3257672786712646, time/collect=0.10803556442260744, time/replay_extend=0.0004973411560058594, time/train=3.3378601074218753e-07, time/speed=2355.0444710693664\n",
      "  0%|          | 1536/1000000 [00:00<07:11, 2314.41it/s, r_step=-0.34]                     step=1536 | train/step_reward_mean=-0.3631603717803955, train/step_reward_std=0.7075288891792297, train/step_reward_max=1.3587353229522705, train/step_reward_min=-2.4532039165496826, time/collect=0.10862314701080324, time/replay_extend=0.00048581759134928387, time/train=3.1789143880208337e-07, time/speed=2314.4056631048898\n",
      "  0%|          | 1792/1000000 [00:00<07:09, 2326.15it/s, r_step=-0.36]step=1792 | train/step_reward_mean=-0.27267709374427795, train/step_reward_std=0.6915700435638428, train/step_reward_max=1.5704565048217773, train/step_reward_min=-2.377519130706787, time/collect=0.10846325329371861, time/replay_extend=0.000484466552734375, time/train=3.065381731305804e-07, time/speed=2326.1494336693986\n",
      "  0%|          | 2048/1000000 [00:00<07:08, 2330.38it/s, r_step=-0.27]step=2048 | train/step_reward_mean=-0.44950759410858154, train/step_reward_std=0.7943565249443054, train/step_reward_max=1.598870038986206, train/step_reward_min=-2.9262120723724365, episode/length=1000.0, episode/return=-322.0182342529297, episode/return_latest=-380.0929870605469, episode/num_completed=2.0, time/collect=0.10839825868606567, time/replay_extend=0.0004825294017791748, time/train=2.980232238769531e-07, time/speed=2330.38160015828\n",
      "  0%|          | 2304/1000000 [00:00<07:08, 2329.74it/s, r_step=-0.45, r_ep=-322.0, n_ep=2]step=2304 | train/step_reward_mean=-0.3435703217983246, train/step_reward_std=0.6836013197898865, train/step_reward_max=1.1422126293182373, train/step_reward_min=-2.3707497119903564, time/collect=0.10840551058451335, time/replay_extend=0.00047625435723198787, time/train=2.914004855685764e-07, time/speed=2329.7381670219083\n",
      "  0%|          | 2560/1000000 [00:01<07:04, 2347.42it/s, r_step=-0.34]                     step=2560 | train/step_reward_mean=-0.32543104887008667, train/step_reward_std=0.7496347427368164, train/step_reward_max=1.3922909498214722, train/step_reward_min=-2.6009535789489746, time/collect=0.10813047885894776, time/replay_extend=0.00047447681427001956, time/train=2.8610229492187504e-07, time/speed=2347.4153808027845\n",
      "  0%|          | 2816/1000000 [00:01<07:06, 2335.92it/s, r_step=-0.33]step=2816 | train/step_reward_mean=-0.4643320143222809, train/step_reward_std=0.6589190363883972, train/step_reward_max=1.0361204147338867, train/step_reward_min=-2.534041404724121, time/collect=0.10813177715648305, time/replay_extend=0.00047189539129083806, time/train=2.6009299538352276e-07, time/speed=2335.9222727001197\n",
      "  0%|          | 3072/1000000 [00:01<07:04, 2347.12it/s, r_step=-0.46]step=3072 | train/step_reward_mean=-0.3385342061519623, train/step_reward_std=0.651943027973175, train/step_reward_max=1.4043093919754028, train/step_reward_min=-2.7667644023895264, episode/length=1000.0, episode/return=-336.4839782714844, episode/return_latest=-365.41546630859375, episode/num_completed=3.0, time/collect=0.1079307993253072, time/replay_extend=0.0004686117172241211, time/train=2.582867940266927e-07, time/speed=2347.1204220637073\n",
      "  0%|          | 3328/1000000 [00:01<07:01, 2364.32it/s, r_step=-0.34, r_ep=-336.5, n_ep=3]step=3328 | train/step_reward_mean=-0.6872280836105347, train/step_reward_std=0.6475779414176941, train/step_reward_max=1.100833773612976, train/step_reward_min=-2.1806859970092773, time/collect=0.10769123297471267, time/replay_extend=0.00046660349919245794, time/train=2.567584698016827e-07, time/speed=2364.323646282076\n",
      "  0%|          | 3584/1000000 [00:01<06:59, 2373.09it/s, r_step=-0.69]                     step=3584 | train/step_reward_mean=-0.44084393978118896, train/step_reward_std=0.6328068375587463, train/step_reward_max=1.844864845275879, train/step_reward_min=-2.0217199325561523, time/collect=0.10753943238939559, time/replay_extend=0.0004726648330688477, time/train=2.724783761160714e-07, time/speed=2373.0933924733854\n",
      "  0%|          | 3840/1000000 [00:01<06:57, 2386.48it/s, r_step=-0.44]step=3840 | train/step_reward_mean=-0.3015947937965393, train/step_reward_std=0.6150639653205872, train/step_reward_max=1.3282005786895752, train/step_reward_min=-2.0007386207580566, time/collect=0.10733289718627931, time/replay_extend=0.0004660765329996745, time/train=2.702077229817708e-07, time/speed=2386.47695669732\n",
      "  0%|          | 4096/1000000 [00:01<06:58, 2381.62it/s, r_step=-0.30]step=4096 | train/step_reward_mean=-0.2424250990152359, train/step_reward_std=0.6377115249633789, train/step_reward_max=1.8281952142715454, train/step_reward_min=-1.793904423713684, episode/length=1000.0, episode/return=-352.3230438232422, episode/return_latest=-399.8402404785156, episode/num_completed=4.0, time/collect=0.10723480582237245, time/replay_extend=0.00046397745609283447, time/train=2.682209014892578e-07, time/speed=2381.6247027743793\n",
      "  0%|          | 4352/1000000 [00:01<06:57, 2386.98it/s, r_step=-0.24, r_ep=-352.3, n_ep=4]step=4352 | train/step_reward_mean=-0.3598955273628235, train/step_reward_std=0.5598626732826233, train/step_reward_max=1.4252020120620728, train/step_reward_min=-1.8445634841918945, time/collect=0.10711817180409153, time/replay_extend=0.00046488818000344666, time/train=2.9451706830193016e-07, time/speed=2386.9791557738713\n",
      "  0%|          | 4608/1000000 [00:01<06:56, 2390.19it/s, r_step=-0.36]                     step=4608 | train/step_reward_mean=-0.4376291334629059, train/step_reward_std=0.6356501579284668, train/step_reward_max=1.1865671873092651, train/step_reward_min=-2.1956613063812256, time/collect=0.1070196761025323, time/replay_extend=0.0004625320434570312, time/train=2.914004855685764e-07, time/speed=2390.1931059896756\n",
      "  0%|          | 4864/1000000 [00:02<06:55, 2392.16it/s, r_step=-0.44]step=4864 | train/step_reward_mean=-0.15550071001052856, train/step_reward_std=0.675746738910675, train/step_reward_max=1.5613305568695068, train/step_reward_min=-2.173848867416382, time/collect=0.10694138627303275, time/replay_extend=0.00045832834745708256, time/train=2.8861196417557566e-07, time/speed=2392.160394540178\n",
      "  1%|          | 5120/1000000 [00:02<06:57, 2382.90it/s, r_step=-0.16]step=5120 | train/step_reward_mean=-0.16561666131019592, train/step_reward_std=0.6808192133903503, train/step_reward_max=1.4443438053131104, train/step_reward_min=-1.830309271812439, episode/length=1000.0, episode/return=-340.1189331054687, episode/return_latest=-291.302490234375, episode/num_completed=5.0, time/collect=0.10695028305053711, time/replay_extend=0.0004572510719299315, time/train=2.86102294921875e-07, time/speed=2382.897586233733\n",
      "  1%|          | 5376/1000000 [00:02<06:56, 2386.29it/s, r_step=-0.17, r_ep=-340.1, n_ep=5]step=5376 | train/step_reward_mean=-0.5493679642677307, train/step_reward_std=0.6543324589729309, train/step_reward_max=1.002967357635498, train/step_reward_min=-2.2408902645111084, time/collect=0.10684495880490258, time/replay_extend=0.000454471224830264, time/train=2.838316417875744e-07, time/speed=2386.2857373952606\n",
      "  1%|          | 5632/1000000 [00:02<06:55, 2393.58it/s, r_step=-0.55]                     step=5632 | train/step_reward_mean=-0.36942392587661743, train/step_reward_std=0.6852601766586304, train/step_reward_max=1.241730809211731, train/step_reward_min=-2.610767126083374, time/collect=0.10675703395496716, time/replay_extend=0.0004552386023781515, time/train=2.8176741166548297e-07, time/speed=2393.5842558051386\n",
      "  1%|          | 5888/1000000 [00:02<06:55, 2391.19it/s, r_step=-0.37]step=5888 | train/step_reward_mean=-0.24910232424736023, train/step_reward_std=0.7238568067550659, train/step_reward_max=1.5199483633041382, train/step_reward_min=-1.941489338874817, time/collect=0.10671645662058955, time/replay_extend=0.0004524148028829822, time/train=2.9024870499320654e-07, time/speed=2391.1858877040804\n",
      "  1%|          | 6144/1000000 [00:02<06:55, 2391.37it/s, r_step=-0.25]step=6144 | train/step_reward_mean=-0.12171974033117294, train/step_reward_std=0.6307722926139832, train/step_reward_max=1.5312763452529907, train/step_reward_min=-1.7673124074935913, episode/length=1000.0, episode/return=-339.44536844889325, episode/return_latest=-336.0775451660156, episode/num_completed=6.0, time/collect=0.1066714624563853, time/replay_extend=0.00045586625734965, time/train=2.980232238769531e-07, time/speed=2391.3689378801555\n",
      "  1%|          | 6400/1000000 [00:02<06:58, 2376.46it/s, r_step=-0.12, r_ep=-339.4, n_ep=6]step=6400 | train/step_reward_mean=-0.4429400861263275, train/step_reward_std=0.7502987384796143, train/step_reward_max=1.286812663078308, train/step_reward_min=-2.571512222290039, time/collect=0.1067184543609619, time/replay_extend=0.00045446395874023423, time/train=3.0517578125e-07, time/speed=2376.462439329767\n",
      "  1%|          | 6656/1000000 [00:02<06:59, 2370.11it/s, r_step=-0.44]                     step=6656 | train/step_reward_mean=-0.3203636109828949, train/step_reward_std=0.7416154146194458, train/step_reward_max=1.6640276908874512, train/step_reward_min=-2.2352256774902344, time/collect=0.10670582147744985, time/replay_extend=0.0004548659691443809, time/train=3.1177814190204327e-07, time/speed=2370.1144921479795\n",
      "  1%|          | 6912/1000000 [00:02<06:58, 2373.24it/s, r_step=-0.32]step=6912 | train/step_reward_mean=-0.39394253492355347, train/step_reward_std=0.6513354778289795, train/step_reward_max=1.4162352085113525, train/step_reward_min=-2.148385524749756, time/collect=0.10668823454115124, time/replay_extend=0.00045120274579083463, time/train=3.09061121057581e-07, time/speed=2373.23697885928\n",
      "  1%|          | 7168/1000000 [00:03<06:57, 2379.81it/s, r_step=-0.39]step=7168 | train/step_reward_mean=-0.23811742663383484, train/step_reward_std=0.6227973103523254, train/step_reward_max=1.2384523153305054, train/step_reward_min=-1.912135362625122, episode/length=1000.0, episode/return=-341.9820338657924, episode/return_latest=-357.2020263671875, episode/num_completed=7.0, time/collect=0.10664014305387223, time/replay_extend=0.00045038121087210507, time/train=3.150531223842076e-07, time/speed=2379.809104252357\n",
      "  1%|          | 7424/1000000 [00:03<06:55, 2389.76it/s, r_step=-0.24, r_ep=-342.0, n_ep=7]step=7424 | train/step_reward_mean=-0.21979567408561707, train/step_reward_std=0.6244816184043884, train/step_reward_max=1.3208187818527222, train/step_reward_min=-2.1197524070739746, time/collect=0.10657705931827939, time/replay_extend=0.0004470594998063711, time/train=3.124105519261854e-07, time/speed=2389.759945709348\n",
      "  1%|          | 7680/1000000 [00:03<06:54, 2391.74it/s, r_step=-0.22]                     step=7680 | train/step_reward_mean=-0.1943046748638153, train/step_reward_std=0.5971029996871948, train/step_reward_max=1.1231509447097778, train/step_reward_min=-1.9704861640930176, time/collect=0.106546417872111, time/replay_extend=0.0004441181818644205, time/train=3.099441528320313e-07, time/speed=2391.7425833312263\n",
      "  1%|          | 7936/1000000 [00:03<06:53, 2397.12it/s, r_step=-0.19]step=7936 | train/step_reward_mean=-0.2859341502189636, train/step_reward_std=0.6998713612556458, train/step_reward_max=1.5228811502456665, train/step_reward_min=-2.3998448848724365, time/collect=0.10647266910922143, time/replay_extend=0.0004412051170103011, time/train=3.076368762600807e-07, time/speed=2397.118576153006\n",
      "  1%|          | 8192/1000000 [00:03<06:53, 2400.19it/s, r_step=-0.29]step=8192 | train/step_reward_mean=-0.15832842886447906, train/step_reward_std=0.7376798987388611, train/step_reward_max=2.1880364418029785, train/step_reward_min=-2.140460252761841, episode/length=1000.0, episode/return=-327.0092430114746, episode/return_latest=-222.19970703125, episode/num_completed=8.0, time/collect=0.1064331978559494, time/replay_extend=0.0004393905401229858, time/train=3.05473804473877e-07, time/speed=2400.1893087935305\n",
      "  1%|          | 8448/1000000 [00:03<06:52, 2402.92it/s, r_step=-0.16, r_ep=-327.0, n_ep=8]step=8448 | train/step_reward_mean=-0.2738567590713501, train/step_reward_std=0.6174859404563904, train/step_reward_max=1.5364385843276978, train/step_reward_min=-2.213451623916626, time/collect=0.10638973207184763, time/replay_extend=0.00043753421667850376, time/train=3.0344182794744323e-07, time/speed=2402.922510184082\n",
      "  1%|          | 8704/1000000 [00:03<06:51, 2408.28it/s, r_step=-0.27]                     step=8704 | train/step_reward_mean=-0.28410977125167847, train/step_reward_std=0.6481736898422241, train/step_reward_max=1.6149437427520752, train/step_reward_min=-1.9411553144454956, time/collect=0.1063370985143325, time/replay_extend=0.0004352751900168026, time/train=3.0152937945197614e-07, time/speed=2408.277997324878\n",
      "  1%|          | 8960/1000000 [00:03<06:50, 2413.21it/s, r_step=-0.28]step=8960 | train/step_reward_mean=-0.2868783473968506, train/step_reward_std=0.6475846767425537, train/step_reward_max=1.4162195920944214, train/step_reward_min=-2.3891377449035645, time/collect=0.1062819480895996, time/replay_extend=0.00043330192565917965, time/train=3.1335013253348214e-07, time/speed=2413.2087381251094\n",
      "  1%|          | 9216/1000000 [00:03<06:50, 2412.15it/s, r_step=-0.29]step=9216 | train/step_reward_mean=-0.37784677743911743, train/step_reward_std=0.7505421042442322, train/step_reward_max=1.8447097539901733, train/step_reward_min=-2.358196973800659, episode/length=1000.0, episode/return=-315.6607496473524, episode/return_latest=-224.872802734375, episode/num_completed=9.0, time/collect=0.10622598065270318, time/replay_extend=0.000432080692715115, time/train=3.1126870049370655e-07, time/speed=2412.1460911605454\n",
      "  1%|          | 9472/1000000 [00:03<06:50, 2413.25it/s, r_step=-0.38, r_ep=-315.7, n_ep=9]step=9472 | train/step_reward_mean=-0.20052263140678406, train/step_reward_std=0.7494285702705383, train/step_reward_max=1.7651373147964478, train/step_reward_min=-2.2087292671203613, time/collect=0.10618737581613903, time/replay_extend=0.0004357840563799884, time/train=3.157435236750422e-07, time/speed=2413.251447649328\n",
      "  1%|          | 9728/1000000 [00:04<06:55, 2382.00it/s, r_step=-0.20]                     step=9728 | train/step_reward_mean=-0.3193424940109253, train/step_reward_std=0.6269797682762146, train/step_reward_max=1.7983360290527344, train/step_reward_min=-1.6865251064300537, time/collect=0.10625483487781728, time/replay_extend=0.0004369208687230161, time/train=3.137086567125822e-07, time/speed=2381.996822728913\n",
      "  1%|          | 9984/1000000 [00:04<06:54, 2390.16it/s, r_step=-0.32]step=9984 | train/step_reward_mean=-0.28433287143707275, train/step_reward_std=0.591978132724762, train/step_reward_max=1.210667371749878, train/step_reward_min=-2.2690834999084473, time/collect=0.10621588658063844, time/replay_extend=0.00043475322234324924, time/train=3.117781419020432e-07, time/speed=2390.155262888598\n",
      "  1%|          | 10240/1000000 [00:04<06:55, 2382.04it/s, r_step=-0.28]step=10240 | train/step_reward_mean=-0.340241014957428, train/step_reward_std=0.6330989599227905, train/step_reward_max=1.6143416166305542, train/step_reward_min=-2.0776753425598145, episode/length=1000.0, episode/return=-316.4816528320313, episode/return_latest=-323.8697814941406, episode/num_completed=10.0, time/collect=0.10621984601020817, time/replay_extend=0.0004343509674072266, time/train=3.1590461730957025e-07, time/speed=2382.0443915751894\n",
      "  1%|          | 10496/1000000 [00:04<06:55, 2379.96it/s, r_step=-0.34, r_ep=-316.5, n_ep=10]step=10496 | train/step_reward_mean=-0.27427488565444946, train/step_reward_std=0.6128848791122437, train/step_reward_max=0.9507184028625488, train/step_reward_min=-1.9819623231887817, time/collect=0.10619285630016796, time/replay_extend=0.0004347882619718226, time/train=3.1401471393864325e-07, time/speed=2379.9596387889533\n",
      "  1%|          | 10752/1000000 [00:04<06:54, 2387.83it/s, r_step=-0.27]                      step=10752 | train/step_reward_mean=-0.19362975656986237, train/step_reward_std=0.5781139135360718, train/step_reward_max=1.16508150100708, train/step_reward_min=-2.027773141860962, time/collect=0.10616550559089301, time/replay_extend=0.00043325197129022506, time/train=3.122148059663318e-07, time/speed=2387.831421189857\n",
      "  1%|          | 11008/1000000 [00:04<06:54, 2386.63it/s, r_step=-0.19]step=11008 | train/step_reward_mean=-0.08439786732196808, train/step_reward_std=0.5664663910865784, train/step_reward_max=1.5734621286392212, train/step_reward_min=-1.6014388799667358, episode/length=1000.0, episode/return=-307.75714111328125, episode/return_latest=-220.51202392578125, episode/num_completed=11.0, time/collect=0.10616522057111875, time/replay_extend=0.0004339384478191996, time/train=3.104986146438953e-07, time/speed=2386.6298709089183\n",
      "  1%|          | 11264/1000000 [00:04<08:12, 2009.36it/s, r_step=-0.08, r_ep=-307.8, n_ep=11]step=11264 | train/step_reward_mean=-0.3305820822715759, train/step_reward_std=0.6259167194366455, train/step_reward_max=1.2833882570266724, train/step_reward_min=-2.1413087844848633, time/collect=0.10768456892533738, time/replay_extend=0.0004350651394237171, time/train=3.0886043201793323e-07, time/speed=2009.3619323378218\n",
      "  1%|          | 11520/1000000 [00:04<07:47, 2114.32it/s, r_step=-0.33]                      step=11520 | train/step_reward_mean=-0.28018638491630554, train/step_reward_std=0.631163477897644, train/step_reward_max=1.2833380699157715, train/step_reward_min=-2.267526865005493, time/collect=0.10761843787299265, time/replay_extend=0.0004349125756157768, time/train=3.1259324815538195e-07, time/speed=2114.3231137344474\n",
      "  1%|          | 11776/1000000 [00:05<07:30, 2194.93it/s, r_step=-0.28]step=11776 | train/step_reward_mean=-0.2849295735359192, train/step_reward_std=0.7361528277397156, train/step_reward_max=1.8262906074523926, train/step_reward_min=-1.969741702079773, time/collect=0.10753838393999185, time/replay_extend=0.0004357514174088187, time/train=3.161637679390285e-07, time/speed=2194.934109932928\n",
      "  1%|          | 12032/1000000 [00:05<07:20, 2243.31it/s, r_step=-0.28]step=12032 | train/step_reward_mean=-0.32725489139556885, train/step_reward_std=0.6801261305809021, train/step_reward_max=1.478093147277832, train/step_reward_min=-2.3231942653656006, episode/length=1000.0, episode/return=-306.65502675374347, episode/return_latest=-294.5317687988281, episode/num_completed=12.0, time/collect=0.10751905847103041, time/replay_extend=0.00043566683505443806, time/train=3.19582350710605e-07, time/speed=2243.312861209432\n",
      "  1%|          | 12288/1000000 [00:05<07:10, 2292.78it/s, r_step=-0.33, r_ep=-306.7, n_ep=12]step=12288 | train/step_reward_mean=-0.1754121035337448, train/step_reward_std=0.7088465690612793, train/step_reward_max=1.3299388885498047, train/step_reward_min=-2.7426562309265137, time/collect=0.10745492080847424, time/replay_extend=0.0004353274901707966, time/train=3.2285849253336585e-07, time/speed=2292.7764455175943\n",
      "  1%|▏         | 12544/1000000 [00:05<07:03, 2330.54it/s, r_step=-0.18]                      step=12544 | train/step_reward_mean=0.013015847653150558, train/step_reward_std=0.5933284163475037, train/step_reward_max=2.0147218704223633, train/step_reward_min=-1.698888897895813, time/collect=0.10739288038137008, time/replay_extend=0.0004335617532535474, time/train=3.211352289939413e-07, time/speed=2330.543314022224\n",
      "  1%|▏         | 12800/1000000 [00:05<06:58, 2358.65it/s, r_step=0.01] step=12800 | train/step_reward_mean=-0.2803521454334259, train/step_reward_std=0.6816274523735046, train/step_reward_max=2.44714093208313, train/step_reward_min=-2.325084686279297, time/collect=0.10733084678649903, time/replay_extend=0.00043245792388916, time/train=3.194808959960937e-07, time/speed=2358.6519793772113\n",
      "  1%|▏         | 13056/1000000 [00:05<06:56, 2366.98it/s, r_step=-0.28]step=13056 | train/step_reward_mean=-0.26021385192871094, train/step_reward_std=0.5326347947120667, train/step_reward_max=0.7189167737960815, train/step_reward_min=-1.9984982013702393, episode/length=1000.0, episode/return=-297.6415064885066, episode/return_latest=-189.47926330566406, episode/num_completed=13.0, time/collect=0.10728831852183623, time/replay_extend=0.0004328138688031363, time/train=3.1789143880208326e-07, time/speed=2366.9758557245473\n",
      "  1%|▏         | 13312/1000000 [00:05<06:58, 2356.32it/s, r_step=-0.26, r_ep=-297.6, n_ep=13]step=13312 | train/step_reward_mean=-0.2945503294467926, train/step_reward_std=0.6447696685791016, train/step_reward_max=1.4129202365875244, train/step_reward_min=-2.6517326831817627, time/collect=0.1073108223768381, time/replay_extend=0.00043568702844473016, time/train=3.163631145770732e-07, time/speed=2356.3178556184685\n",
      "  1%|▏         | 13568/1000000 [00:05<06:57, 2365.16it/s, r_step=-0.29]                      step=13568 | train/step_reward_mean=-0.2495390772819519, train/step_reward_std=0.6272190809249878, train/step_reward_max=1.3203524351119995, train/step_reward_min=-1.9848756790161133, time/collect=0.1072808121735195, time/replay_extend=0.00043536582083072284, time/train=3.148924629643277e-07, time/speed=2365.1579961775756\n",
      "  1%|▏         | 13824/1000000 [00:05<06:55, 2375.02it/s, r_step=-0.25]step=13824 | train/step_reward_mean=-0.25358515977859497, train/step_reward_std=0.5984457731246948, train/step_reward_max=1.5996476411819458, train/step_reward_min=-1.7852267026901245, time/collect=0.10724714067247179, time/replay_extend=0.00043486224280463306, time/train=3.134762799298321e-07, time/speed=2375.023804934634\n",
      "  1%|▏         | 14080/1000000 [00:05<06:53, 2381.96it/s, r_step=-0.25]step=14080 | train/step_reward_mean=-0.12425537407398224, train/step_reward_std=0.645716667175293, train/step_reward_max=1.7779775857925415, train/step_reward_min=-2.174847364425659, episode/length=1000.0, episode/return=-292.6376070295061, episode/return_latest=-227.5869140625, episode/num_completed=14.0, time/collect=0.10721499703147196, time/replay_extend=0.0004355127161199395, time/train=3.1211159446022716e-07, time/speed=2381.964719800009\n",
      "  1%|▏         | 14336/1000000 [00:06<06:52, 2387.45it/s, r_step=-0.12, r_ep=-292.6, n_ep=14]step=14336 | train/step_reward_mean=-0.3102693557739258, train/step_reward_std=0.7591733336448669, train/step_reward_max=1.9544883966445923, train/step_reward_min=-2.0216593742370605, time/collect=0.10716387629508974, time/replay_extend=0.0004364379814692904, time/train=3.107956477573938e-07, time/speed=2387.446190738293\n",
      "  1%|▏         | 14592/1000000 [00:06<06:52, 2386.87it/s, r_step=-0.31]                      step=14592 | train/step_reward_mean=-0.4379768371582031, train/step_reward_std=0.5849209427833557, train/step_reward_max=1.45469069480896, train/step_reward_min=-2.1275689601898193, time/collect=0.10714261155379447, time/replay_extend=0.0004377532423588265, time/train=3.09525874623081e-07, time/speed=2386.866540557847\n",
      "  1%|▏         | 14848/1000000 [00:06<06:51, 2394.11it/s, r_step=-0.44]step=14848 | train/step_reward_mean=-0.24486082792282104, train/step_reward_std=0.636900782585144, train/step_reward_max=1.3113120794296265, train/step_reward_min=-1.7139922380447388, time/collect=0.10709859173873376, time/replay_extend=0.0004368856035429853, time/train=3.1241055192618523e-07, time/speed=2394.112119010991\n",
      "  2%|▏         | 15104/1000000 [00:06<06:50, 2396.58it/s, r_step=-0.24]step=15104 | train/step_reward_mean=-0.37734535336494446, train/step_reward_std=0.6222142577171326, train/step_reward_max=1.1788156032562256, train/step_reward_min=-2.081005811691284, episode/length=1000.0, episode/return=-294.4497039794922, episode/return_latest=-319.8190612792969, episode/num_completed=15.0, time/collect=0.10706871242846473, time/replay_extend=0.00043557458004708994, time/train=3.111564506918696e-07, time/speed=2396.578802243599\n",
      "  2%|▏         | 15360/1000000 [00:06<06:50, 2400.49it/s, r_step=-0.38, r_ep=-294.4, n_ep=15]step=15360 | train/step_reward_mean=-0.45562151074409485, train/step_reward_std=0.7263906598091125, train/step_reward_max=1.2948734760284424, train/step_reward_min=-2.8335800170898438, time/collect=0.10703389247258503, time/replay_extend=0.0004351377487182614, time/train=3.1391779581705724e-07, time/speed=2400.494489126697\n",
      "  2%|▏         | 15616/1000000 [00:06<06:51, 2389.68it/s, r_step=-0.46]                      step=15616 | train/step_reward_mean=-0.19713839888572693, train/step_reward_std=0.6783512830734253, train/step_reward_max=1.697680115699768, train/step_reward_min=-2.6789069175720215, time/collect=0.10701086872913797, time/replay_extend=0.0004344611871437945, time/train=3.12680103739754e-07, time/speed=2389.6844449557843\n",
      "  2%|▏         | 15872/1000000 [00:06<06:51, 2393.29it/s, r_step=-0.20]step=15872 | train/step_reward_mean=-0.47455698251724243, train/step_reward_std=0.681460976600647, train/step_reward_max=1.3831762075424194, train/step_reward_min=-2.1688179969787598, time/collect=0.10698036993703533, time/replay_extend=0.00043414869616108524, time/train=3.114823372133316e-07, time/speed=2393.2856674496347\n",
      "  2%|▏         | 16128/1000000 [00:06<06:59, 2345.24it/s, r_step=-0.47]step=16128 | train/step_reward_mean=-0.3946540951728821, train/step_reward_std=0.6017414331436157, train/step_reward_max=1.3486883640289307, train/step_reward_min=-2.2008872032165527, episode/length=1000.0, episode/return=-299.6304750442505, episode/return_latest=-377.342041015625, episode/num_completed=16.0, time/collect=0.10707471484229676, time/replay_extend=0.00043561345054989736, time/train=3.1032259502108125e-07, time/speed=2345.244483264723\n",
      "  2%|▏         | 16384/1000000 [00:06<06:57, 2356.31it/s, r_step=-0.39, r_ep=-299.6, n_ep=16]step=16384 | train/step_reward_mean=-0.21460328996181488, train/step_reward_std=0.6465124487876892, train/step_reward_max=1.480051875114441, train/step_reward_min=-1.9899768829345703, time/collect=0.10705462470650672, time/replay_extend=0.00043556094169616667, time/train=3.129243850708007e-07, time/speed=2356.3084989615863\n",
      "  2%|▏         | 16640/1000000 [00:07<06:53, 2376.15it/s, r_step=-0.21]                      step=16640 | train/step_reward_mean=-0.5114595890045166, train/step_reward_std=0.7002637386322021, train/step_reward_max=1.5512195825576782, train/step_reward_min=-2.7051007747650146, time/collect=0.10701207381028395, time/replay_extend=0.0004350112034724306, time/train=3.1544612004206725e-07, time/speed=2376.1458986606826\n",
      "  2%|▏         | 16896/1000000 [00:07<06:51, 2387.99it/s, r_step=-0.51]step=16896 | train/step_reward_mean=-0.32606950402259827, train/step_reward_std=0.6632272005081177, train/step_reward_max=1.697807788848877, train/step_reward_min=-2.136556386947632, time/collect=0.1069654081806992, time/replay_extend=0.00043543902310458067, time/train=3.1427903608842323e-07, time/speed=2387.9897709819875\n",
      "  2%|▏         | 17152/1000000 [00:07<06:52, 2381.72it/s, r_step=-0.33]step=17152 | train/step_reward_mean=-0.1835794746875763, train/step_reward_std=0.6524956822395325, train/step_reward_max=1.5673719644546509, train/step_reward_min=-2.241489887237549, episode/length=1000.0, episode/return=-302.4567574893727, episode/return_latest=-347.6772766113281, episode/num_completed=17.0, time/collect=0.10696327152536876, time/replay_extend=0.0004355800685597886, time/train=3.131467904617537e-07, time/speed=2381.716991869522\n",
      "  2%|▏         | 17408/1000000 [00:07<06:51, 2390.41it/s, r_step=-0.18, r_ep=-302.5, n_ep=17]step=17408 | train/step_reward_mean=-0.22464345395565033, train/step_reward_std=0.6453477740287781, train/step_reward_max=1.3914711475372314, train/step_reward_min=-2.266652822494507, time/collect=0.10692929169710945, time/replay_extend=0.00043581864413093087, time/train=3.12047846177045e-07, time/speed=2390.4113405037524\n",
      "  2%|▏         | 17664/1000000 [00:07<06:49, 2400.90it/s, r_step=-0.22]                      step=17664 | train/step_reward_mean=-0.19514749944210052, train/step_reward_std=0.7317017316818237, train/step_reward_max=1.6033899784088135, train/step_reward_min=-2.0405561923980713, time/collect=0.10689136947410695, time/replay_extend=0.0004361435986947319, time/train=3.1098075534986414e-07, time/speed=2400.9015071188346\n",
      "  2%|▏         | 17920/1000000 [00:07<06:48, 2403.22it/s, r_step=-0.20]step=17920 | train/step_reward_mean=-0.2667061388492584, train/step_reward_std=0.6246354579925537, train/step_reward_max=1.3480514287948608, train/step_reward_min=-2.0304932594299316, time/collect=0.10686414922986713, time/replay_extend=0.0004367998668125695, time/train=3.065381731305804e-07, time/speed=2403.215555791425\n",
      "  2%|▏         | 18176/1000000 [00:07<06:51, 2384.11it/s, r_step=-0.27]step=18176 | train/step_reward_mean=-0.11759714782238007, train/step_reward_std=0.6272277235984802, train/step_reward_max=2.0156304836273193, train/step_reward_min=-2.034257411956787, episode/length=1000.0, episode/return=-298.0534506903754, episode/return_latest=-223.19723510742188, episode/num_completed=18.0, time/collect=0.106865664603005, time/replay_extend=0.00043809581810319906, time/train=3.055787422287632e-07, time/speed=2384.109553992956\n",
      "  2%|▏         | 18432/1000000 [00:07<06:51, 2386.13it/s, r_step=-0.12, r_ep=-298.1, n_ep=18]step=18432 | train/step_reward_mean=-0.3053918778896332, train/step_reward_std=0.5648375749588013, train/step_reward_max=1.6679234504699707, train/step_reward_min=-1.9187718629837036, time/collect=0.10684790213902794, time/replay_extend=0.00043735239240858274, time/train=3.046459621853299e-07, time/speed=2386.125527286174\n",
      "  2%|▏         | 18688/1000000 [00:07<06:50, 2390.08it/s, r_step=-0.31]                      step=18688 | train/step_reward_mean=-0.2702476382255554, train/step_reward_std=0.49665677547454834, train/step_reward_max=1.4097330570220947, train/step_reward_min=-1.6995338201522827, time/collect=0.1068280625016722, time/replay_extend=0.0004368154969933913, time/train=3.07004745692423e-07, time/speed=2390.080135822007\n",
      "  2%|▏         | 18944/1000000 [00:08<06:49, 2396.70it/s, r_step=-0.27]step=18944 | train/step_reward_mean=-0.2713031470775604, train/step_reward_std=0.5242586731910706, train/step_reward_max=1.2605364322662354, train/step_reward_min=-1.7297817468643188, time/collect=0.1068021703410793, time/replay_extend=0.0004363092216285498, time/train=3.0607790560335737e-07, time/speed=2396.7001574391224\n",
      "  2%|▏         | 19200/1000000 [00:08<06:49, 2396.31it/s, r_step=-0.27]step=19200 | train/step_reward_mean=-0.25086331367492676, train/step_reward_std=0.5564412474632263, train/step_reward_max=1.7787885665893555, train/step_reward_min=-1.7478595972061157, episode/length=1000.0, episode/return=-295.3111740915399, episode/return_latest=-245.9501953125, episode/num_completed=19.0, time/collect=0.10678590456644695, time/replay_extend=0.00043697992960611967, time/train=3.051757812500001e-07, time/speed=2396.3108853896583\n",
      "  2%|▏         | 19456/1000000 [00:08<06:49, 2395.79it/s, r_step=-0.25, r_ep=-295.3, n_ep=19]step=19456 | train/step_reward_mean=-0.4789438843727112, train/step_reward_std=0.7056344747543335, train/step_reward_max=1.0236420631408691, train/step_reward_min=-2.4797091484069824, time/collect=0.10675789494263498, time/replay_extend=0.00043746358469912866, time/train=3.0429739701120484e-07, time/speed=2395.788269667176\n",
      "  2%|▏         | 19712/1000000 [00:08<06:48, 2398.88it/s, r_step=-0.48]                      step=19712 | train/step_reward_mean=-0.40562233328819275, train/step_reward_std=0.6624444723129272, train/step_reward_max=1.587548851966858, train/step_reward_min=-2.6066184043884277, time/collect=0.10673583637584338, time/replay_extend=0.0004370955677775592, time/train=3.0344182794744323e-07, time/speed=2398.88405196238\n",
      "  2%|▏         | 19968/1000000 [00:08<06:48, 2401.17it/s, r_step=-0.41]step=19968 | train/step_reward_mean=-0.4294900596141815, train/step_reward_std=0.6293577551841736, train/step_reward_max=1.1380736827850342, train/step_reward_min=-2.423931837081909, time/collect=0.10671451458564171, time/replay_extend=0.00043681034675011255, time/train=3.026081965519832e-07, time/speed=2401.1653996692735\n",
      "  2%|▏         | 20224/1000000 [00:08<06:49, 2394.16it/s, r_step=-0.43]step=20224 | train/step_reward_mean=-0.1957782655954361, train/step_reward_std=0.5990273356437683, train/step_reward_max=1.7944855690002441, train/step_reward_min=-1.6777266263961792, episode/length=1000.0, episode/return=-300.12651138305665, episode/return_latest=-391.617919921875, episode/num_completed=20.0, time/collect=0.10670581045030039, time/replay_extend=0.00043624262266521197, time/train=3.0179566974881336e-07, time/speed=2394.1644681475686\n",
      "  2%|▏         | 20480/1000000 [00:08<06:49, 2394.07it/s, r_step=-0.20, r_ep=-300.1, n_ep=20]step=20480 | train/step_reward_mean=-0.0025464536156505346, train/step_reward_std=0.5600242614746094, train/step_reward_max=1.5673202276229858, train/step_reward_min=-1.465315341949463, time/collect=0.10669224262237549, time/replay_extend=0.000435584783554077, time/train=3.0100345611572275e-07, time/speed=2394.0650187442006\n",
      "  2%|▏         | 20736/1000000 [00:08<06:50, 2384.16it/s, r_step=-0.00]                      step=20736 | train/step_reward_mean=-0.15137489140033722, train/step_reward_std=0.5122156739234924, train/step_reward_max=1.2865902185440063, train/step_reward_min=-1.373881459236145, time/collect=0.10668774593023606, time/replay_extend=0.00043614411059721, time/train=3.002308033130788e-07, time/speed=2384.1640419821115\n",
      "  2%|▏         | 20992/1000000 [00:08<06:52, 2371.22it/s, r_step=-0.15]step=20992 | train/step_reward_mean=-0.6217265129089355, train/step_reward_std=0.7416820526123047, train/step_reward_max=1.7748700380325317, train/step_reward_min=-2.6232073307037354, time/collect=0.10670413912796392, time/replay_extend=0.00043644556185094304, time/train=3.023845393483233e-07, time/speed=2371.224575121444\n",
      "  2%|▏         | 21248/1000000 [00:08<06:53, 2367.03it/s, r_step=-0.62]step=21248 | train/step_reward_mean=-0.3671639561653137, train/step_reward_std=0.6681682467460632, train/step_reward_max=1.476301908493042, train/step_reward_min=-2.6223833560943604, episode/length=1000.0, episode/return=-297.7243405296689, episode/return_latest=-249.68092346191406, episode/num_completed=21.0, time/collect=0.10671051439032496, time/replay_extend=0.0004372252039162507, time/train=3.016138651284828e-07, time/speed=2367.0306927202564\n",
      "  2%|▏         | 21504/1000000 [00:09<06:51, 2376.44it/s, r_step=-0.37, r_ep=-297.7, n_ep=21]step=21504 | train/step_reward_mean=-0.21372030675411224, train/step_reward_std=0.5796141624450684, train/step_reward_max=1.4832273721694946, train/step_reward_min=-1.8578873872756958, time/collect=0.10669314577465965, time/replay_extend=0.0004367147173200333, time/train=3.0086154029482896e-07, time/speed=2376.443165709302\n",
      "  2%|▏         | 21760/1000000 [00:09<06:51, 2379.50it/s, r_step=-0.21]                      step=21760 | train/step_reward_mean=-0.18908663094043732, train/step_reward_std=0.47633007168769836, train/step_reward_max=1.2004611492156982, train/step_reward_min=-1.575402021408081, time/collect=0.10668426401474895, time/replay_extend=0.00043712503769818454, time/train=3.00126917221967e-07, time/speed=2379.499149886405\n",
      "  2%|▏         | 22016/1000000 [00:09<06:53, 2365.55it/s, r_step=-0.19]step=22016 | train/step_reward_mean=-0.24687795341014862, train/step_reward_std=0.5687717795372009, train/step_reward_max=1.5835789442062378, train/step_reward_min=-2.057683229446411, episode/length=1000.0, episode/return=-296.1507207697088, episode/return_latest=-263.1047058105469, episode/num_completed=22.0, time/collect=0.10668764557949331, time/replay_extend=0.0004368632338767826, time/train=2.994093784066135e-07, time/speed=2365.549503651846\n",
      "  2%|▏         | 22272/1000000 [00:09<06:54, 2359.95it/s, r_step=-0.25, r_ep=-296.2, n_ep=22]step=22272 | train/step_reward_mean=-0.23650403320789337, train/step_reward_std=0.5240376591682434, train/step_reward_max=0.9591357707977295, train/step_reward_min=-1.7869175672531128, time/collect=0.1066993762706888, time/replay_extend=0.00043710620923974027, time/train=2.987083347364405e-07, time/speed=2359.953084191961\n",
      "  2%|▏         | 22528/1000000 [00:09<06:51, 2372.79it/s, r_step=-0.24]                      step=22528 | train/step_reward_mean=-0.32792502641677856, train/step_reward_std=0.7836917638778687, train/step_reward_max=2.0097267627716064, train/step_reward_min=-2.57196044921875, time/collect=0.10668235204436562, time/replay_extend=0.000437630848451094, time/train=2.980232238769533e-07, time/speed=2372.787531731303\n",
      "  2%|▏         | 22784/1000000 [00:09<06:50, 2381.45it/s, r_step=-0.33]step=22784 | train/step_reward_mean=-0.12636950612068176, train/step_reward_std=0.6410506367683411, train/step_reward_max=1.3546650409698486, train/step_reward_min=-2.0272927284240723, time/collect=0.1066643629181251, time/replay_extend=0.0004379668932282521, time/train=2.973535087671174e-07, time/speed=2381.454065062005\n",
      "  2%|▏         | 23040/1000000 [00:09<06:52, 2365.64it/s, r_step=-0.13]step=23040 | train/step_reward_mean=-0.2834601104259491, train/step_reward_std=0.609157145023346, train/step_reward_max=1.1145344972610474, train/step_reward_min=-2.0404999256134033, episode/length=1000.0, episode/return=-293.07568094004756, episode/return_latest=-225.4248046875, episode/num_completed=23.0, time/collect=0.1066859828101264, time/replay_extend=0.00043788750966389955, time/train=2.993477715386286e-07, time/speed=2365.639131298732\n",
      "  2%|▏         | 23296/1000000 [00:09<06:51, 2370.66it/s, r_step=-0.28, r_ep=-293.1, n_ep=23]step=23296 | train/step_reward_mean=-0.415716290473938, train/step_reward_std=0.6295799016952515, train/step_reward_max=1.4611166715621948, train/step_reward_min=-2.3393099308013916, time/collect=0.10666905654655708, time/replay_extend=0.00043752167251083864, time/train=3.012982043591176e-07, time/speed=2370.6622703610074\n",
      "  2%|▏         | 23552/1000000 [00:10<08:01, 2026.64it/s, r_step=-0.42]                      step=23552 | train/step_reward_mean=-0.4214021861553192, train/step_reward_std=0.7356961369514465, train/step_reward_max=1.482844352722168, train/step_reward_min=-2.7759008407592773, time/collect=0.1073301719582599, time/replay_extend=0.00043990301049273933, time/train=3.0061473017153544e-07, time/speed=2026.6382907085226\n",
      "  2%|▏         | 23808/1000000 [00:10<07:39, 2124.42it/s, r_step=-0.42]step=23808 | train/step_reward_mean=-0.44107985496520996, train/step_reward_std=0.6452957987785339, train/step_reward_max=1.1355531215667725, train/step_reward_min=-2.090221643447876, time/collect=0.10730524729656916, time/replay_extend=0.00043969256903535566, time/train=2.9994595435357873e-07, time/speed=2124.4193900917626\n",
      "  2%|▏         | 24064/1000000 [00:10<07:24, 2193.69it/s, r_step=-0.44]step=24064 | train/step_reward_mean=-0.1919669806957245, train/step_reward_std=0.6423147916793823, train/step_reward_max=1.5560587644577026, train/step_reward_min=-2.6723861694335938, episode/length=1000.0, episode/return=-296.57105255126953, episode/return_latest=-376.964599609375, episode/num_completed=24.0, time/collect=0.10729505660686087, time/replay_extend=0.00043983662382085265, time/train=2.9929140780834456e-07, time/speed=2193.6931036286696\n",
      "  2%|▏         | 24320/1000000 [00:10<07:14, 2243.58it/s, r_step=-0.19, r_ep=-296.6, n_ep=24]step=24320 | train/step_reward_mean=-0.0980755090713501, train/step_reward_std=0.5241175293922424, train/step_reward_max=1.1605899333953857, train/step_reward_min=-1.4995232820510864, time/collect=0.10728734668932462, time/replay_extend=0.00044052726344058377, time/train=3.011603104440791e-07, time/speed=2243.576195844685\n",
      "  2%|▏         | 24576/1000000 [00:10<07:07, 2279.16it/s, r_step=-0.10]                      step=24576 | train/step_reward_mean=-0.08401934802532196, train/step_reward_std=0.6251885890960693, train/step_reward_max=2.045698881149292, train/step_reward_min=-1.6525243520736694, time/collect=0.10727329303820927, time/replay_extend=0.00044069687525431306, time/train=3.005067507425946e-07, time/speed=2279.161898403104\n",
      "  2%|▏         | 24832/1000000 [00:10<07:02, 2310.26it/s, r_step=-0.08]step=24832 | train/step_reward_mean=-0.2701203227043152, train/step_reward_std=0.5215030908584595, train/step_reward_max=1.192803144454956, train/step_reward_min=-1.9448703527450562, time/collect=0.10724930910720039, time/replay_extend=0.000440813831447326, time/train=2.998666664988726e-07, time/speed=2310.2599410210337\n",
      "  3%|▎         | 25088/1000000 [00:10<06:58, 2329.22it/s, r_step=-0.27]step=25088 | train/step_reward_mean=-0.2520764172077179, train/step_reward_std=0.6194447875022888, train/step_reward_max=1.9869955778121948, train/step_reward_min=-1.8893458843231201, episode/length=1000.0, episode/return=-292.2083728027344, episode/return_latest=-187.50405883789062, episode/num_completed=25.0, train/loss_actor=-8.891701698303223, train/loss_qvalue=3.115495443344116, train/loss_alpha=-0.19564518332481384, train/alpha=0.9254111051559448, time/collect=0.10724193709237234, time/replay_extend=0.00044087244539844743, time/train=0.030211146996945753, time/rb - sample=0.00031073298305273083, time/update=0.011242005974054343, time/speed=2329.2201143942307\n",
      "  3%|▎         | 25344/1000000 [00:13<1:04:35, 251.51it/s, r_step=-0.25, r_ep=-292.2, n_ep=25, π_loss=-8.892, α=0.925]step=25344 | train/step_reward_mean=-0.28993168473243713, train/step_reward_std=0.772754967212677, train/step_reward_max=1.781890630722046, train/step_reward_min=-2.164167881011963, train/loss_actor=-11.664471626281738, train/loss_qvalue=1.3133430480957031, train/loss_alpha=-0.5882598161697388, train/alpha=0.856713593006134, time/collect=0.10791428402216748, time/replay_extend=0.0004421508673465613, time/train=0.05451629860232575, time/rb - sample=0.00030095688998699183, time/update=0.010227417107671494, time/speed=251.51498118123752\n",
      "  3%|▎         | 25600/1000000 [00:16<1:34:51, 171.21it/s, r_step=-0.29, π_loss=-11.664, α=0.857]                     step=25600 | train/step_reward_mean=-0.21067273616790771, train/step_reward_std=0.5633653402328491, train/step_reward_max=1.490831971168518, train/step_reward_min=-1.8975131511688232, train/loss_actor=-14.388320922851562, train/loss_qvalue=1.383527159690857, train/loss_alpha=-0.9807009696960449, train/alpha=0.793181836605072, time/collect=0.10854681491851807, time/replay_extend=0.000444493293762207, time/train=0.07911850452423096, time/rb - sample=0.00030072902639706966, time/update=0.00998799347629149, time/speed=171.20551204440258\n",
      "  3%|▎         | 25856/1000000 [00:19<1:57:41, 137.95it/s, r_step=-0.21, π_loss=-14.388, α=0.793]step=25856 | train/step_reward_mean=-0.306035578250885, train/step_reward_std=0.5300937294960022, train/step_reward_max=0.9240265488624573, train/step_reward_min=-2.064213514328003, train/loss_actor=-17.076580047607422, train/loss_qvalue=1.581254482269287, train/loss_alpha=-1.3737281560897827, train/alpha=0.7343817949295044, time/collect=0.10923200078529888, time/replay_extend=0.0004443532169455348, time/train=0.10385993919750251, time/rb - sample=0.0002985282335430385, time/update=0.009932145476341254, time/speed=137.95096625355058\n",
      "  3%|▎         | 26112/1000000 [00:21<2:14:48, 120.41it/s, r_step=-0.31, π_loss=-17.077, α=0.734]step=26112 | train/step_reward_mean=-0.21670445799827576, train/step_reward_std=0.6378412842750549, train/step_reward_max=1.420133352279663, train/step_reward_min=-2.0791854858398438, episode/length=1000.0, episode/return=-290.8311333289513, episode/return_latest=-256.400146484375, episode/num_completed=26.0, train/loss_actor=-19.559829711914062, train/loss_qvalue=1.7785472869873047, train/loss_alpha=-1.7670714855194092, train/alpha=0.6799530982971191, time/collect=0.1098994904873418, time/replay_extend=0.0004461115481806736, time/train=0.12775614916109573, time/rb - sample=0.00030186995863914465, time/update=0.009865334443748007, time/speed=120.40969063994491\n",
      "  3%|▎         | 26368/1000000 [00:24<2:26:04, 111.09it/s, r_step=-0.22, r_ep=-290.8, n_ep=26, π_loss=-19.560, α=0.680]step=26368 | train/step_reward_mean=-0.25416886806488037, train/step_reward_std=0.6906936764717102, train/step_reward_max=1.3897790908813477, train/step_reward_min=-2.5390524864196777, train/loss_actor=-21.799169540405273, train/loss_qvalue=1.9258384704589844, train/loss_alpha=-2.1592047214508057, train/alpha=0.6295920014381409, time/collect=0.11055832464718125, time/replay_extend=0.00044864589728198, time/train=0.15164892418870649, time/rb - sample=0.0003026435151696201, time/update=0.009853067652632788, time/speed=111.08665499231883\n",
      "  3%|▎         | 26624/1000000 [00:27<2:34:48, 104.79it/s, r_step=-0.25, π_loss=-21.799, α=0.630]                      step=26624 | train/step_reward_mean=-0.17104576528072357, train/step_reward_std=0.5712860822677612, train/step_reward_max=1.0777441263198853, train/step_reward_min=-2.477140426635742, train/loss_actor=-23.83769416809082, train/loss_qvalue=2.0362389087677, train/loss_alpha=-2.5529391765594482, train/alpha=0.5829550623893738, time/collect=0.11118062872153063, time/replay_extend=0.0004481856639568622, time/train=0.17440018745569086, time/rb - sample=0.0003017552995256007, time/update=0.009806204188082887, time/speed=104.7943944899823\n",
      "  3%|▎         | 26880/1000000 [00:30<2:39:36, 101.61it/s, r_step=-0.17, π_loss=-23.838, α=0.583]step=26880 | train/step_reward_mean=-0.06584684550762177, train/step_reward_std=0.5577654242515564, train/step_reward_max=1.4821171760559082, train/step_reward_min=-1.49170982837677, train/loss_actor=-25.62139892578125, train/loss_qvalue=2.131887674331665, train/loss_alpha=-2.946664571762085, train/alpha=0.5397803783416748, time/collect=0.1118210588182722, time/replay_extend=0.00044990494137718556, time/train=0.19657130014328733, time/rb - sample=0.0002998587442561975, time/update=0.009764764807187019, time/speed=101.61328531917205\n",
      "  3%|▎         | 27136/1000000 [00:32<2:42:39, 99.68it/s, r_step=-0.07, π_loss=-25.621, α=0.540] step=27136 | train/step_reward_mean=-0.27820801734924316, train/step_reward_std=0.6041061282157898, train/step_reward_max=1.6501038074493408, train/step_reward_min=-2.3908579349517822, episode/length=1000.0, episode/return=-286.7591394495081, episode/return_latest=-180.88729858398438, episode/num_completed=27.0, train/loss_actor=-27.19559669494629, train/loss_qvalue=2.239335536956787, train/loss_alpha=-3.340158700942993, train/alpha=0.4998079836368561, time/collect=0.11242023728928478, time/replay_extend=0.00045232727842510863, time/train=0.2186061593721498, time/rb - sample=0.0002996654560168582, time/update=0.009744213273127874, time/speed=99.68477862533676\n",
      "  3%|▎         | 27392/1000000 [00:35<2:45:23, 98.01it/s, r_step=-0.28, r_ep=-286.8, n_ep=27, π_loss=-27.196, α=0.500]step=27392 | train/step_reward_mean=-0.00010764040052890778, train/step_reward_std=0.7365599274635315, train/step_reward_max=2.2479753494262695, train/step_reward_min=-2.1546356678009033, train/loss_actor=-28.58852767944336, train/loss_qvalue=2.320347785949707, train/loss_alpha=-3.731085777282715, train/alpha=0.46282297372817993, time/collect=0.11305541858494841, time/replay_extend=0.0004546642303466796, time/train=0.2415523350795853, time/rb - sample=0.0002997044473886489, time/update=0.00978279998525978, time/speed=98.00805502346647\n",
      "  3%|▎         | 27648/1000000 [00:38<2:49:52, 95.40it/s, r_step=-0.00, π_loss=-28.589, α=0.463]                      step=27648 | train/step_reward_mean=-0.2615760862827301, train/step_reward_std=0.7141741514205933, train/step_reward_max=1.8726484775543213, train/step_reward_min=-2.6333115100860596, train/loss_actor=-29.782936096191406, train/loss_qvalue=2.400878667831421, train/loss_alpha=-4.12354040145874, train/alpha=0.4285796284675598, time/collect=0.11362305614683364, time/replay_extend=0.0004570660767731842, time/train=0.263018235012337, time/rb - sample=0.00029919601299545963, time/update=0.009774566712704573, time/speed=95.40074313745298\n",
      "  3%|▎         | 27904/1000000 [00:41<2:50:47, 94.86it/s, r_step=-0.26, π_loss=-29.783, α=0.429]step=27904 | train/step_reward_mean=-0.3506399095058441, train/step_reward_std=0.6526544690132141, train/step_reward_max=1.1779687404632568, train/step_reward_min=-1.9097881317138672, train/loss_actor=-30.835094451904297, train/loss_qvalue=2.4934771060943604, train/loss_alpha=-4.517502784729004, train/alpha=0.3968646228313446, time/collect=0.11416759622206384, time/replay_extend=0.00045882889983850876, time/train=0.2840257915881796, time/rb - sample=0.0002999228114883107, time/update=0.009764211873213437, time/speed=94.85716231303154\n",
      "  3%|▎         | 28160/1000000 [00:43<2:51:24, 94.49it/s, r_step=-0.35, π_loss=-30.835, α=0.397]step=28160 | train/step_reward_mean=-0.4320026934146881, train/step_reward_std=0.7115956544876099, train/step_reward_max=1.0846091508865356, train/step_reward_min=-2.7383334636688232, episode/length=1000.0, episode/return=-284.5286778041295, episode/return_latest=-224.30621337890625, episode/num_completed=28.0, train/loss_actor=-31.69268035888672, train/loss_qvalue=2.631223678588867, train/loss_alpha=-4.907625198364258, train/alpha=0.36751317977905273, time/collect=0.11475674022327771, time/replay_extend=0.0004579110579057173, time/train=0.3048199371858077, time/rb - sample=0.00029908034663933997, time/update=0.009762514167680179, time/speed=94.49216254585833\n",
      "  3%|▎         | 28416/1000000 [00:46<2:52:11, 94.04it/s, r_step=-0.43, r_ep=-284.5, n_ep=28, π_loss=-31.693, α=0.368]step=28416 | train/step_reward_mean=-0.3720118999481201, train/step_reward_std=0.849735677242279, train/step_reward_max=1.8349967002868652, train/step_reward_min=-2.6041038036346436, train/loss_actor=-32.4254150390625, train/loss_qvalue=2.73008394241333, train/loss_alpha=-5.30079984664917, train/alpha=0.34033164381980896, time/collect=0.11531583682910818, time/replay_extend=0.0004588655523351721, time/train=0.3247631240535427, time/rb - sample=0.0002990780797387881, time/update=0.009745591985327855, time/speed=94.04355511730579\n",
      "  3%|▎         | 28672/1000000 [00:49<2:51:40, 94.30it/s, r_step=-0.37, π_loss=-32.425, α=0.340]                      step=28672 | train/step_reward_mean=-0.4541172385215759, train/step_reward_std=0.689860999584198, train/step_reward_max=1.412382960319519, train/step_reward_min=-2.210585355758667, train/loss_actor=-32.98447036743164, train/loss_qvalue=2.832254409790039, train/loss_alpha=-5.693882942199707, train/alpha=0.3151571750640869, time/collect=0.11586754449776242, time/replay_extend=0.0004610802446092878, time/train=0.34470452581133165, time/rb - sample=0.00029947714259227184, time/update=0.009740792339046797, time/speed=94.29994297406046\n",
      "  3%|▎         | 28928/1000000 [00:51<2:52:01, 94.08it/s, r_step=-0.45, π_loss=-32.984, α=0.315]step=28928 | train/step_reward_mean=-0.24944499135017395, train/step_reward_std=0.7825701236724854, train/step_reward_max=1.80527663230896, train/step_reward_min=-2.1575253009796143, train/loss_actor=-33.45623779296875, train/loss_qvalue=2.9827873706817627, train/loss_alpha=-6.082305431365967, train/alpha=0.29186055064201355, time/collect=0.11639775850076592, time/replay_extend=0.0004637389056450498, time/train=0.3643405753954322, time/rb - sample=0.000299554958473892, time/update=0.009738153370562929, time/speed=94.07838139503549\n",
      "  3%|▎         | 29184/1000000 [00:54<2:52:24, 93.85it/s, r_step=-0.25, π_loss=-33.456, α=0.292]step=29184 | train/step_reward_mean=-0.10771908611059189, train/step_reward_std=0.6802294850349426, train/step_reward_max=1.6940892934799194, train/step_reward_min=-2.075531482696533, episode/length=1000.0, episode/return=-287.4528440278152, episode/return_latest=-369.3294982910156, episode/num_completed=29.0, train/loss_actor=-33.84367370605469, train/loss_qvalue=3.135190963745117, train/loss_alpha=-6.4784722328186035, train/alpha=0.27027368545532227, time/collect=0.11693659999914338, time/replay_extend=0.0004648555789077491, time/train=0.3836419540539122, time/rb - sample=0.00029919767642722474, time/update=0.009736568886129277, time/speed=93.84609980133335\n",
      "  3%|▎         | 29440/1000000 [00:57<2:52:54, 93.55it/s, r_step=-0.11, r_ep=-287.5, n_ep=29, π_loss=-33.844, α=0.270]step=29440 | train/step_reward_mean=-0.21832460165023804, train/step_reward_std=0.6230028867721558, train/step_reward_max=1.631514549255371, train/step_reward_min=-1.9553616046905518, train/loss_actor=-34.09716796875, train/loss_qvalue=3.3313276767730713, train/loss_alpha=-6.866611480712891, train/alpha=0.250294029712677, time/collect=0.11757315138111947, time/replay_extend=0.00046531635781993044, time/train=0.40333667630734654, time/rb - sample=0.0002990346401929856, time/update=0.009753180512537542, time/speed=93.54990847714303\n",
      "  3%|▎         | 29696/1000000 [01:00<2:54:40, 92.59it/s, r_step=-0.22, π_loss=-34.097, α=0.250]                      step=29696 | train/step_reward_mean=-0.45748114585876465, train/step_reward_std=0.7884458899497986, train/step_reward_max=1.6167594194412231, train/step_reward_min=-2.452592372894287, train/loss_actor=-34.20534896850586, train/loss_qvalue=3.393592357635498, train/loss_alpha=-7.260186195373535, train/alpha=0.23178765177726746, time/collect=0.11810222987470959, time/replay_extend=0.00046692634450978257, time/train=0.4221944562320052, time/rb - sample=0.000299076108556044, time/update=0.009755991938474897, time/speed=92.58613728847473\n",
      "  3%|▎         | 29952/1000000 [01:03<2:54:31, 92.64it/s, r_step=-0.46, π_loss=-34.205, α=0.232]step=29952 | train/step_reward_mean=-0.4307433068752289, train/step_reward_std=0.7815892100334167, train/step_reward_max=1.7921439409255981, train/step_reward_min=-2.5635428428649902, train/loss_actor=-34.23359680175781, train/loss_qvalue=3.5073790550231934, train/loss_alpha=-7.652883052825928, train/alpha=0.2146487683057785, time/collect=0.1185235793773945, time/replay_extend=0.00046930761418790905, time/train=0.4403162328605978, time/rb - sample=0.0002985482569783917, time/update=0.009749636938795402, time/speed=92.6353965273373\n",
      "  3%|▎         | 30208/1000000 [01:05<2:53:38, 93.09it/s, r_step=-0.43, π_loss=-34.234, α=0.215]step=30208 | train/step_reward_mean=-0.4581778049468994, train/step_reward_std=0.8378505706787109, train/step_reward_max=1.6348543167114258, train/step_reward_min=-3.3931427001953125, episode/length=1000.0, episode/return=-287.0997639973958, episode/return_latest=-276.8604431152344, episode/num_completed=30.0, train/loss_actor=-34.26487731933594, train/loss_qvalue=3.6943235397338867, train/loss_alpha=-8.046955108642578, train/alpha=0.19877450168132782, time/collect=0.11899621001744679, time/replay_extend=0.0004708322428040586, time/train=0.4598821785490392, time/rb - sample=0.00029850201237769237, time/update=0.009781913698783899, time/speed=93.08737301420021\n",
      "  3%|▎         | 30464/1000000 [01:08<2:57:01, 91.28it/s, r_step=-0.46, r_ep=-287.1, n_ep=30, π_loss=-34.265, α=0.199]step=30464 | train/step_reward_mean=-0.5308987498283386, train/step_reward_std=0.7539504766464233, train/step_reward_max=1.6010563373565674, train/step_reward_min=-2.375506639480591, train/loss_actor=-34.12201690673828, train/loss_qvalue=3.8761074542999268, train/loss_alpha=-8.43664264678955, train/alpha=0.1840788871049881, time/collect=0.11951196494222693, time/replay_extend=0.0004716821077491056, time/train=0.47774035790387326, time/rb - sample=0.0002986837432465759, time/update=0.009781906719912118, time/speed=91.28368637025932\n",
      "  3%|▎         | 30720/1000000 [01:11<2:56:09, 91.70it/s, r_step=-0.53, π_loss=-34.122, α=0.184]                      step=30720 | train/step_reward_mean=-0.503231406211853, train/step_reward_std=0.7019211053848267, train/step_reward_max=1.1299817562103271, train/step_reward_min=-3.0089974403381348, train/loss_actor=-33.965972900390625, train/loss_qvalue=3.9698410034179688, train/loss_alpha=-8.834085464477539, train/alpha=0.17046211659908295, time/collect=0.11997524499893193, time/replay_extend=0.00047127405802408867, time/train=0.4951345046361288, time/rb - sample=0.00029844078032866743, time/update=0.009778926756394888, time/speed=91.70239516531666\n",
      "  3%|▎         | 30976/1000000 [01:14<2:55:17, 92.13it/s, r_step=-0.50, π_loss=-33.966, α=0.170]step=30976 | train/step_reward_mean=-0.2684568166732788, train/step_reward_std=0.7008646130561829, train/step_reward_max=2.4747023582458496, train/step_reward_min=-2.1660962104797363, train/loss_actor=-33.715362548828125, train/loss_qvalue=4.183224201202393, train/loss_alpha=-9.22082805633545, train/alpha=0.15786154568195343, time/collect=0.12046344812251324, time/replay_extend=0.0004710993490928462, time/train=0.5119640866586985, time/rb - sample=0.00029868811058501356, time/update=0.009770235784041327, time/speed=92.13399838642232\n",
      "  3%|▎         | 31232/1000000 [01:16<2:53:47, 92.91it/s, r_step=-0.27, π_loss=-33.715, α=0.158]step=31232 | train/step_reward_mean=-0.06618785113096237, train/step_reward_std=0.6727970242500305, train/step_reward_max=1.832588791847229, train/step_reward_min=-1.9244707822799683, episode/length=1000.0, episode/return=-292.7105181294103, episode/return_latest=-461.03314208984375, episode/num_completed=31.0, train/loss_actor=-33.43745040893555, train/loss_qvalue=4.22634220123291, train/loss_alpha=-9.613445281982422, train/alpha=0.14619134366512299, time/collect=0.12085450086437291, time/replay_extend=0.00047214500239638044, time/train=0.5289293859825761, time/rb - sample=0.00029871076345443643, time/update=0.009770314693450872, time/speed=92.9088404328767\n",
      "  3%|▎         | 31488/1000000 [01:19<2:53:48, 92.87it/s, r_step=-0.07, r_ep=-292.7, n_ep=31, π_loss=-33.437, α=0.146]step=31488 | train/step_reward_mean=-0.2638842463493347, train/step_reward_std=0.5513939261436462, train/step_reward_max=1.3399784564971924, train/step_reward_min=-1.910264015197754, train/loss_actor=-33.10149383544922, train/loss_qvalue=4.431197166442871, train/loss_alpha=-10.004294395446777, train/alpha=0.13538461923599243, time/collect=0.12130083107366797, time/replay_extend=0.00047341207178627586, time/train=0.546050203524954, time/rb - sample=0.00029916029710035997, time/update=0.009777843271597003, time/speed=92.86976029827844\n",
      "  3%|▎         | 31744/1000000 [01:22<2:54:50, 92.29it/s, r_step=-0.26, π_loss=-33.101, α=0.135]                      step=31744 | train/step_reward_mean=-0.2852587103843689, train/step_reward_std=0.5150461792945862, train/step_reward_max=1.3892568349838257, train/step_reward_min=-1.8029803037643433, train/loss_actor=-32.73506546020508, train/loss_qvalue=4.528942108154297, train/loss_alpha=-10.39378833770752, train/alpha=0.12537825107574463, time/collect=0.12175094312237159, time/replay_extend=0.0004768544627774148, time/train=0.5635107005796126, time/rb - sample=0.00029959833180462874, time/update=0.00979589626055065, time/speed=92.294770030659\n",
      "  3%|▎         | 32000/1000000 [01:25<2:56:58, 91.16it/s, r_step=-0.29, π_loss=-32.735, α=0.125]step=32000 | train/step_reward_mean=-0.28854209184646606, train/step_reward_std=0.5094925761222839, train/step_reward_max=0.8801098465919495, train/step_reward_min=-1.9951684474945068, episode/length=1000.0, episode/return=-290.8546938896179, episode/return_latest=-233.3241424560547, episode/num_completed=32.0, train/loss_actor=-32.303016662597656, train/loss_qvalue=4.5190887451171875, train/loss_alpha=-10.789985656738281, train/alpha=0.11610805243253708, time/collect=0.12218401336669925, time/replay_extend=0.00047816848754882825, time/train=0.5800364513397218, time/rb - sample=0.0003001458410705836, time/update=0.00980109588376106, time/speed=91.1575704808709\n",
      "  3%|▎         | 32256/1000000 [01:28<2:56:56, 91.16it/s, r_step=-0.29, r_ep=-290.9, n_ep=32, π_loss=-32.303, α=0.116]step=32256 | train/step_reward_mean=-0.5475790500640869, train/step_reward_std=0.6171571612358093, train/step_reward_max=1.4294203519821167, train/step_reward_min=-2.129688024520874, train/loss_actor=-31.787927627563477, train/loss_qvalue=4.664602279663086, train/loss_alpha=-11.180264472961426, train/alpha=0.10752463340759277, time/collect=0.12260395950741242, time/replay_extend=0.0004793462299165273, time/train=0.5963537238893056, time/rb - sample=0.000300484580983375, time/update=0.00980703651519679, time/speed=91.15626317189296\n",
      "  3%|▎         | 32512/1000000 [01:30<2:56:57, 91.12it/s, r_step=-0.55, π_loss=-31.788, α=0.108]                      step=32512 | train/step_reward_mean=-0.3444581627845764, train/step_reward_std=0.6657863855361938, train/step_reward_max=1.3696633577346802, train/step_reward_min=-2.697176456451416, train/loss_actor=-31.313486099243164, train/loss_qvalue=4.8446526527404785, train/loss_alpha=-11.567421913146973, train/alpha=0.09957805275917053, time/collect=0.1230074965109037, time/replay_extend=0.0004806649966502754, time/train=0.6122228817676936, time/rb - sample=0.00030090895791848424, time/update=0.009809293722112927, time/speed=91.12464145608149\n",
      "  3%|▎         | 32768/1000000 [01:33<2:56:34, 91.30it/s, r_step=-0.34, π_loss=-31.313, α=0.100]step=32768 | train/step_reward_mean=-0.35257065296173096, train/step_reward_std=0.6241116523742676, train/step_reward_max=1.1158438920974731, train/step_reward_min=-2.1068320274353027, train/loss_actor=-30.724519729614258, train/loss_qvalue=4.917006492614746, train/loss_alpha=-11.966446876525879, train/alpha=0.09221538156270981, time/collect=0.12344036996364598, time/replay_extend=0.00048301368951797496, time/train=0.6287651658058168, time/rb - sample=0.00030071462594693653, time/update=0.009826866789690882, time/speed=91.29507185649872\n",
      "  3%|▎         | 33024/1000000 [01:36<2:58:25, 90.33it/s, r_step=-0.35, π_loss=-30.725, α=0.092]step=33024 | train/step_reward_mean=-0.3426944315433502, train/step_reward_std=0.6102215051651001, train/step_reward_max=1.3323930501937866, train/step_reward_min=-2.013033151626587, episode/length=1000.0, episode/return=-294.17410601991594, episode/return_latest=-400.3952941894531, episode/num_completed=33.0, train/loss_actor=-30.13960838317871, train/loss_qvalue=5.081358909606934, train/loss_alpha=-12.357978820800781, train/alpha=0.08539721369743347, time/collect=0.12382174647131634, time/replay_extend=0.00048550339632256095, time/train=0.6434633510057318, time/rb - sample=0.00030108689679764146, time/update=0.009817792219109833, time/speed=90.32853815659256\n",
      "  3%|▎         | 33280/1000000 [01:39<2:55:58, 91.56it/s, r_step=-0.34, r_ep=-294.2, n_ep=33, π_loss=-30.140, α=0.085]step=33280 | train/step_reward_mean=0.05274989455938339, train/step_reward_std=0.7153071761131287, train/step_reward_max=1.6434581279754639, train/step_reward_min=-1.8339853286743164, train/loss_actor=-29.599149703979492, train/loss_qvalue=4.990365982055664, train/loss_alpha=-12.744926452636719, train/alpha=0.07908516377210617, time/collect=0.12425637061779318, time/replay_extend=0.0004875769981971155, time/train=0.6590518731337329, time/rb - sample=0.0003015461349577598, time/update=0.009826339978837586, time/speed=91.55813215851923\n",
      "  3%|▎         | 33536/1000000 [01:42<2:56:57, 91.03it/s, r_step=0.05, π_loss=-29.599, α=0.079]                       step=33536 | train/step_reward_mean=-0.42483776807785034, train/step_reward_std=0.6990892887115479, train/step_reward_max=1.1639093160629272, train/step_reward_min=-2.7672412395477295, train/loss_actor=-28.93729019165039, train/loss_qvalue=5.2535200119018555, train/loss_alpha=-13.13844108581543, train/alpha=0.07323920726776123, time/collect=0.12465111535924084, time/replay_extend=0.0004886507077981498, time/train=0.6738555522365426, time/rb - sample=0.0003017751664361522, time/update=0.00982632608536411, time/speed=91.02738593345569\n",
      "  3%|▎         | 33792/1000000 [01:45<2:56:08, 91.42it/s, r_step=-0.42, π_loss=-28.937, α=0.073]step=33792 | train/step_reward_mean=-0.17095264792442322, train/step_reward_std=0.6693371534347534, train/step_reward_max=1.730281949043274, train/step_reward_min=-1.8392404317855835, train/loss_actor=-28.305683135986328, train/loss_qvalue=5.362563610076904, train/loss_alpha=-13.526887893676758, train/alpha=0.06782622635364532, time/collect=0.1250050429141883, time/replay_extend=0.000490650986180161, time/train=0.6893379597952873, time/rb - sample=0.000301723554730415, time/update=0.009839898427682242, time/speed=91.42455391386659\n",
      "  3%|▎         | 34048/1000000 [01:47<2:57:52, 90.51it/s, r_step=-0.17, π_loss=-28.306, α=0.068]step=34048 | train/step_reward_mean=-0.470318466424942, train/step_reward_std=0.7473690509796143, train/step_reward_max=1.690337061882019, train/step_reward_min=-2.4908435344696045, episode/length=1000.0, episode/return=-293.7059797399184, episode/return_latest=-278.2578125, episode/num_completed=34.0, train/loss_actor=-27.588882446289062, train/loss_qvalue=5.485820770263672, train/loss_alpha=-13.923863410949707, train/alpha=0.0628117024898529, time/collect=0.12538210252173862, time/replay_extend=0.0004921748225850271, time/train=0.7040793770237974, time/rb - sample=0.0003019270435389551, time/update=0.009845135086733415, time/speed=90.50813001407495\n",
      "  3%|▎         | 34304/1000000 [01:50<2:57:44, 90.56it/s, r_step=-0.47, r_ep=-293.7, n_ep=34, π_loss=-27.589, α=0.063]step=34304 | train/step_reward_mean=-0.4399677515029907, train/step_reward_std=0.7339543700218201, train/step_reward_max=1.3592545986175537, train/step_reward_min=-3.4335296154022217, train/loss_actor=-26.85315704345703, train/loss_qvalue=5.561666488647461, train/loss_alpha=-14.308085441589355, train/alpha=0.05816960334777832, time/collect=0.12572762147704167, time/replay_extend=0.000494341352092686, time/train=0.7184713847601593, time/rb - sample=0.0003019808414014612, time/update=0.009848397124457965, time/speed=90.5555519009979\n",
      "  3%|▎         | 34560/1000000 [01:53<2:57:21, 90.73it/s, r_step=-0.44, π_loss=-26.853, α=0.058]                      step=34560 | train/step_reward_mean=-0.19150757789611816, train/step_reward_std=0.6975530982017517, train/step_reward_max=1.3462847471237183, train/step_reward_min=-1.997685432434082, train/loss_actor=-26.190086364746094, train/loss_qvalue=5.678863525390625, train/loss_alpha=-14.703302383422852, train/alpha=0.053869929164648056, time/collect=0.12608956584223996, time/replay_extend=0.0004950152503119575, time/train=0.7325146922358761, time/rb - sample=0.0003019962949972413, time/update=0.0098496383350146, time/speed=90.72698766509326\n",
      "  3%|▎         | 34816/1000000 [01:56<2:57:00, 90.88it/s, r_step=-0.19, π_loss=-26.190, α=0.054]step=34816 | train/step_reward_mean=-0.32242658734321594, train/step_reward_std=0.5812036395072937, train/step_reward_max=1.0757545232772827, train/step_reward_min=-1.9801884889602661, train/loss_actor=-25.46581268310547, train/loss_qvalue=5.849785804748535, train/loss_alpha=-15.098564147949219, train/alpha=0.04988718777894974, time/collect=0.12654073799357698, time/replay_extend=0.0004958773360532873, time/train=0.7461191187886631, time/rb - sample=0.00030193408616842446, time/update=0.009847726147526306, time/speed=90.88041236235664\n",
      "  4%|▎         | 35072/1000000 [01:59<2:55:48, 91.47it/s, r_step=-0.32, π_loss=-25.466, α=0.050]step=35072 | train/step_reward_mean=-0.24086283147335052, train/step_reward_std=0.7620304226875305, train/step_reward_max=1.9643211364746094, train/step_reward_min=-2.8581881523132324, episode/length=1000.0, episode/return=-293.66166425432476, episode/return_latest=-292.1549377441406, episode/num_completed=35.0, train/loss_actor=-24.729021072387695, train/loss_qvalue=5.878719806671143, train/loss_alpha=-15.49833869934082, train/alpha=0.046197161078453064, time/collect=0.1268689719429852, time/replay_extend=0.0004969008647612412, time/train=0.760122133867584, time/rb - sample=0.000302037014625967, time/update=0.009853738103993209, time/speed=91.47402967138491\n",
      "  4%|▎         | 35328/1000000 [02:01<2:56:39, 91.01it/s, r_step=-0.24, r_ep=-293.7, n_ep=35, π_loss=-24.729, α=0.046]step=35328 | train/step_reward_mean=-0.015024981461465359, train/step_reward_std=0.6462728381156921, train/step_reward_max=1.6408838033676147, train/step_reward_min=-1.9171119928359985, train/loss_actor=-24.000717163085938, train/loss_qvalue=6.005436897277832, train/loss_alpha=-15.884098052978516, train/alpha=0.04278179630637169, time/collect=0.12725156632022583, time/replay_extend=0.0004981721656909888, time/train=0.7745008364967677, time/rb - sample=0.0003020900824084521, time/update=0.009867109903475097, time/speed=91.01099617237523\n",
      "  4%|▎         | 35584/1000000 [02:04<2:58:41, 89.95it/s, r_step=-0.02, π_loss=-24.001, α=0.043]                      step=35584 | train/step_reward_mean=-0.06311776489019394, train/step_reward_std=0.5618358254432678, train/step_reward_max=1.5536422729492188, train/step_reward_min=-1.7361111640930176, train/loss_actor=-23.291410446166992, train/loss_qvalue=5.86104154586792, train/loss_alpha=-16.276132583618164, train/alpha=0.03961891680955887, time/collect=0.12761237295411476, time/replay_extend=0.0005000598139042478, time/train=0.787646729311497, time/rb - sample=0.0003019836066024651, time/update=0.009866754590932782, time/speed=89.94804973592835\n",
      "  4%|▎         | 35840/1000000 [02:07<2:57:25, 90.57it/s, r_step=-0.06, π_loss=-23.291, α=0.040]step=35840 | train/step_reward_mean=-0.1416618973016739, train/step_reward_std=0.6636160016059875, train/step_reward_max=1.4897493124008179, train/step_reward_min=-2.099778175354004, train/loss_actor=-22.5394287109375, train/loss_qvalue=5.946745872497559, train/loss_alpha=-16.664148330688477, train/alpha=0.0366903655230999, time/collect=0.12796903678349086, time/replay_extend=0.0005010894366673062, time/train=0.8004581127847944, time/rb - sample=0.000302259550364905, time/update=0.00986416588082561, time/speed=90.56766354969504\n",
      "  4%|▎         | 36096/1000000 [02:10<2:56:09, 91.20it/s, r_step=-0.14, π_loss=-22.539, α=0.037]step=36096 | train/step_reward_mean=-0.3303302228450775, train/step_reward_std=0.7224448323249817, train/step_reward_max=1.6100053787231445, train/step_reward_min=-2.142892599105835, episode/length=1000.0, episode/return=-288.09834988911945, episode/return_latest=-93.3823471069336, episode/num_completed=36.0, train/loss_actor=-21.7847957611084, train/loss_qvalue=6.048770904541016, train/loss_alpha=-17.05747413635254, train/alpha=0.03397836908698082, time/collect=0.12831220221012196, time/replay_extend=0.0005019962364900197, time/train=0.8136739460289055, time/rb - sample=0.0003022076773711232, time/update=0.009869351030581345, time/speed=91.1965428257436\n",
      "  4%|▎         | 36352/1000000 [02:13<2:56:45, 90.86it/s, r_step=-0.33, r_ep=-288.1, n_ep=36, π_loss=-21.785, α=0.034]step=36352 | train/step_reward_mean=-0.41054511070251465, train/step_reward_std=0.6919277906417847, train/step_reward_max=1.1034038066864014, train/step_reward_min=-2.3222177028656006, train/loss_actor=-21.059999465942383, train/loss_qvalue=6.066356182098389, train/loss_alpha=-17.445903778076172, train/alpha=0.03146689012646675, time/collect=0.12864836001060379, time/replay_extend=0.0005032445343447404, time/train=0.8261717188526206, time/rb - sample=0.00030220459318823327, time/update=0.009867707432972024, time/speed=90.8605856629222\n",
      "  4%|▎         | 36608/1000000 [02:16<2:55:43, 91.38it/s, r_step=-0.41, π_loss=-21.060, α=0.031]                      step=36608 | train/step_reward_mean=-0.38553592562675476, train/step_reward_std=0.6671493053436279, train/step_reward_max=1.0417982339859009, train/step_reward_min=-2.209212303161621, train/loss_actor=-20.246482849121094, train/loss_qvalue=6.1268391609191895, train/loss_alpha=-17.840543746948242, train/alpha=0.029140684753656387, time/collect=0.12896824216509198, time/replay_extend=0.0005041919388137497, time/train=0.839114190815212, time/rb - sample=0.0003024232371345813, time/update=0.009873427126718567, time/speed=91.37603001545484\n",
      "  4%|▎         | 36864/1000000 [02:18<2:56:35, 90.90it/s, r_step=-0.39, π_loss=-20.246, α=0.029]step=36864 | train/step_reward_mean=-0.0888904258608818, train/step_reward_std=0.5821399688720703, train/step_reward_max=1.7476768493652344, train/step_reward_min=-1.4702672958374023, train/loss_actor=-19.496726989746094, train/loss_qvalue=6.189232349395752, train/loss_alpha=-18.23419952392578, train/alpha=0.02698632888495922, time/collect=0.1292679872777727, time/replay_extend=0.0005046857727898491, time/train=0.8513712767097684, time/rb - sample=0.0003025986729784218, time/update=0.009872888492301382, time/speed=90.89708248111234\n",
      "  4%|▎         | 37120/1000000 [02:21<2:55:55, 91.22it/s, r_step=-0.09, π_loss=-19.497, α=0.027]step=37120 | train/step_reward_mean=-0.46887460350990295, train/step_reward_std=0.5810900926589966, train/step_reward_max=1.2508018016815186, train/step_reward_min=-2.225456476211548, episode/length=1000.0, episode/return=-289.45441024367875, episode/return_latest=-338.2725830078125, episode/num_completed=37.0, train/loss_actor=-18.659820556640625, train/loss_qvalue=6.295986652374268, train/loss_alpha=-18.62671661376953, train/alpha=0.02499120868742466, time/collect=0.12959813413948848, time/replay_extend=0.0005059982168263401, time/train=0.8633539824650205, time/rb - sample=0.0003026913618668915, time/update=0.009871203568763974, time/speed=91.22201313944508\n",
      "  4%|▎         | 37376/1000000 [02:24<2:55:13, 91.56it/s, r_step=-0.47, r_ep=-289.5, n_ep=37, π_loss=-18.660, α=0.025]step=37376 | train/step_reward_mean=-0.46117010712623596, train/step_reward_std=0.7342936992645264, train/step_reward_max=1.7015464305877686, train/step_reward_min=-2.778280258178711, train/loss_actor=-17.892759323120117, train/loss_qvalue=6.300941467285156, train/loss_alpha=-19.021677017211914, train/alpha=0.023143412545323372, time/collect=0.1299314253950772, time/replay_extend=0.0005070069064832712, time/train=0.8758042969115792, time/rb - sample=0.0003026707706098657, time/update=0.009877038739469532, time/speed=91.56317615852599\n",
      "  4%|▍         | 37632/1000000 [02:27<2:56:21, 90.95it/s, r_step=-0.46, π_loss=-17.893, α=0.023]                      step=37632 | train/step_reward_mean=-0.12017233669757843, train/step_reward_std=0.5704699158668518, train/step_reward_max=1.9119999408721924, train/step_reward_min=-1.7595115900039673, train/loss_actor=-17.10184669494629, train/loss_qvalue=6.405200481414795, train/loss_alpha=-19.39563751220703, train/alpha=0.021433530375361443, time/collect=0.1302431635305184, time/replay_extend=0.0005079824097302493, time/train=0.8876323553980613, time/rb - sample=0.00030270531773567263, time/update=0.009877397101372434, time/speed=90.95001569530393\n",
      "  4%|▍         | 37888/1000000 [02:30<2:55:51, 91.18it/s, r_step=-0.12, π_loss=-17.102, α=0.021]step=37888 | train/step_reward_mean=-0.30900534987449646, train/step_reward_std=0.5220301151275635, train/step_reward_max=1.1822348833084106, train/step_reward_min=-2.001163959503174, train/loss_actor=-16.31532859802246, train/loss_qvalue=6.454923629760742, train/loss_alpha=-19.8022518157959, train/alpha=0.01984880492091179, time/collect=0.13054479779423894, time/replay_extend=0.0005087514181394833, time/train=0.8995705859081164, time/rb - sample=0.0003029820052724265, time/update=0.009880553127503815, time/speed=91.17899272008331\n",
      "  4%|▍         | 38144/1000000 [02:32<2:58:00, 90.06it/s, r_step=-0.31, π_loss=-16.315, α=0.020]step=38144 | train/step_reward_mean=-0.4782100021839142, train/step_reward_std=0.6302931904792786, train/step_reward_max=1.4095194339752197, train/step_reward_min=-2.4526374340057373, episode/length=1000.0, episode/return=-290.107080760755, episode/return_latest=-314.2558898925781, episode/num_completed=38.0, train/loss_actor=-15.506659507751465, train/loss_qvalue=6.417840003967285, train/loss_alpha=-20.1807918548584, train/alpha=0.018382113426923752, time/collect=0.13146893610090216, time/replay_extend=0.0005105421847145028, time/train=0.9109422472499361, time/rb - sample=0.0003030276320015009, time/update=0.00987926967298748, time/speed=90.05571066627564\n",
      "  4%|▍         | 38400/1000000 [02:35<2:56:37, 90.74it/s, r_step=-0.48, r_ep=-290.1, n_ep=38, π_loss=-15.507, α=0.018]step=38400 | train/step_reward_mean=-0.2854786217212677, train/step_reward_std=0.5894487500190735, train/step_reward_max=1.2362548112869263, train/step_reward_min=-1.8226958513259888, train/loss_actor=-14.727655410766602, train/loss_qvalue=6.5109076499938965, train/loss_alpha=-20.588024139404297, train/alpha=0.017022782936692238, time/collect=0.13176294803619382, time/replay_extend=0.0005112520853678385, time/train=0.9223141940434774, time/rb - sample=0.00030300695941133296, time/update=0.009879778877322326, time/speed=90.73715282938784\n",
      "  4%|▍         | 38656/1000000 [02:38<2:56:06, 90.98it/s, r_step=-0.29, π_loss=-14.728, α=0.017]                      step=38656 | train/step_reward_mean=-0.414293497800827, train/step_reward_std=0.6717836260795593, train/step_reward_max=1.122653603553772, train/step_reward_min=-2.3262524604797363, train/loss_actor=-13.947498321533203, train/loss_qvalue=6.512665271759033, train/loss_alpha=-20.96805191040039, train/alpha=0.01576467789709568, time/collect=0.13204977370255827, time/replay_extend=0.0005113399581403921, time/train=0.933667588707627, time/rb - sample=0.00030309712100359994, time/update=0.0098815975814229, time/speed=90.97946959231068\n",
      "  4%|▍         | 38912/1000000 [02:41<2:56:02, 90.99it/s, r_step=-0.41, π_loss=-13.947, α=0.016]step=38912 | train/step_reward_mean=-0.2729624807834625, train/step_reward_std=0.7313754558563232, train/step_reward_max=1.543533444404602, train/step_reward_min=-2.361008882522583, train/loss_actor=-13.163586616516113, train/loss_qvalue=6.522686958312988, train/loss_alpha=-21.36471176147461, train/alpha=0.014599339105188847, time/collect=0.13232376700953433, time/replay_extend=0.0005128148354982074, time/train=0.9453353505385549, time/rb - sample=0.0003032488579099817, time/update=0.009888281774791709, time/speed=90.99359356617626\n",
      "  4%|▍         | 39168/1000000 [02:44<2:57:24, 90.27it/s, r_step=-0.27, π_loss=-13.164, α=0.015]step=39168 | train/step_reward_mean=-0.13191033899784088, train/step_reward_std=0.6244993805885315, train/step_reward_max=1.4293798208236694, train/step_reward_min=-2.728844404220581, episode/length=1000.0, episode/return=-291.78168057172724, episode/return_latest=-355.4164733886719, episode/num_completed=39.0, train/loss_actor=-12.403562545776367, train/loss_qvalue=6.611942291259766, train/loss_alpha=-21.754411697387695, train/alpha=0.013520079664885998, time/collect=0.13263409589630326, time/replay_extend=0.000513368182712131, time/train=0.9566038340524909, time/rb - sample=0.00030348170548677325, time/update=0.00989201914386016, time/speed=90.26653468144943\n",
      "  4%|▍         | 39424/1000000 [02:47<2:57:36, 90.14it/s, r_step=-0.13, r_ep=-291.8, n_ep=39, π_loss=-12.404, α=0.014]step=39424 | train/step_reward_mean=-0.0880453884601593, train/step_reward_std=0.6967487335205078, train/step_reward_max=1.5271477699279785, train/step_reward_min=-1.7950197458267212, train/loss_actor=-11.648588180541992, train/loss_qvalue=6.523678302764893, train/loss_alpha=-22.154678344726562, train/alpha=0.012520365417003632, time/collect=0.13293238429280071, time/replay_extend=0.0005145847023307502, time/train=0.9676843928052233, time/rb - sample=0.0003035482868813623, time/update=0.009895341225752636, time/speed=90.13600717876727\n",
      "  4%|▍         | 39680/1000000 [02:49<2:57:38, 90.10it/s, r_step=-0.09, π_loss=-11.649, α=0.013]                      step=39680 | train/step_reward_mean=-0.4987422525882721, train/step_reward_std=0.6684854030609131, train/step_reward_max=1.1992839574813843, train/step_reward_min=-2.3108651638031006, train/loss_actor=-10.818888664245605, train/loss_qvalue=6.685427665710449, train/loss_alpha=-22.543842315673828, train/alpha=0.011594710871577263, time/collect=0.13323238126693235, time/replay_extend=0.0005171468180994832, time/train=0.9785873905304939, time/rb - sample=0.00030352650531407014, time/update=0.009898274446484258, time/speed=90.09614777588543\n",
      "  4%|▍         | 39936/1000000 [02:52<2:57:32, 90.13it/s, r_step=-0.50, π_loss=-10.819, α=0.012]step=39936 | train/step_reward_mean=-0.5628554821014404, train/step_reward_std=0.7122147679328918, train/step_reward_max=1.5425550937652588, train/step_reward_min=-3.1852264404296875, train/loss_actor=-10.068643569946289, train/loss_qvalue=6.650503158569336, train/loss_alpha=-22.935443878173828, train/alpha=0.010737569071352482, time/collect=0.13350530618276352, time/replay_extend=0.0005178420971601436, time/train=0.9893195629119873, time/rb - sample=0.0003036558943784833, time/update=0.009900629473060796, time/speed=90.12943748936392\n",
      "  4%|▍         | 40192/1000000 [02:55<2:57:17, 90.23it/s, r_step=-0.56, π_loss=-10.069, α=0.011]step=40192 | train/step_reward_mean=-0.08913175761699677, train/step_reward_std=0.7370390892028809, train/step_reward_max=2.428718090057373, train/step_reward_min=-1.8893282413482666, episode/length=1000.0, episode/return=-292.27549304962156, episode/return_latest=-311.5341796875, episode/num_completed=40.0, train/loss_actor=-9.24569034576416, train/loss_qvalue=6.895142555236816, train/loss_alpha=-23.32676887512207, train/alpha=0.009943781420588493, time/collect=0.13377483787050673, time/replay_extend=0.0005187107499238031, time/train=0.999457218085125, time/rb - sample=0.000303574961920578, time/update=0.009898441936820655, time/speed=90.2253200196922\n",
      "  4%|▍         | 40448/1000000 [02:58<2:55:49, 90.96it/s, r_step=-0.09, r_ep=-292.3, n_ep=40, π_loss=-9.246, α=0.010]step=40448 | train/step_reward_mean=-0.6177358031272888, train/step_reward_std=0.7474785447120667, train/step_reward_max=1.340657114982605, train/step_reward_min=-2.8621432781219482, train/loss_actor=-8.452226638793945, train/loss_qvalue=6.971985816955566, train/loss_alpha=-23.720958709716797, train/alpha=0.009208561852574348, time/collect=0.13405965551545349, time/replay_extend=0.00051972383185278, time/train=1.010043904751162, time/rb - sample=0.00030373798713820787, time/update=0.009901926868030198, time/speed=90.9550596035503\n",
      "  4%|▍         | 40704/1000000 [03:01<2:56:27, 90.61it/s, r_step=-0.62, π_loss=-8.452, α=0.009]                      step=40704 | train/step_reward_mean=-0.20147761702537537, train/step_reward_std=0.6675887703895569, train/step_reward_max=1.5195876359939575, train/step_reward_min=-2.6409125328063965, train/loss_actor=-7.641114234924316, train/loss_qvalue=6.933626174926758, train/loss_alpha=-24.104990005493164, train/alpha=0.008527926169335842, time/collect=0.1343262015648608, time/replay_extend=0.0005217138326392982, time/train=1.020807095293729, time/rb - sample=0.00030413935441643786, time/update=0.009908145248529301, time/speed=90.60886266920018\n",
      "  4%|▍         | 40960/1000000 [03:04<2:57:57, 89.82it/s, r_step=-0.20, π_loss=-7.641, α=0.009]step=40960 | train/step_reward_mean=-0.1068630963563919, train/step_reward_std=0.6634994149208069, train/step_reward_max=2.139070510864258, train/step_reward_min=-2.30466365814209, train/loss_actor=-6.924755096435547, train/loss_qvalue=6.952137470245361, train/loss_alpha=-24.504371643066406, train/alpha=0.007897447794675827, time/collect=0.13464047312736513, time/replay_extend=0.0005237281322479246, time/train=1.0309364974498751, time/rb - sample=0.0003044153785421719, time/update=0.009909325042768983, time/speed=89.82168009291381\n",
      "  4%|▍         | 41216/1000000 [03:06<2:57:23, 90.08it/s, r_step=-0.11, π_loss=-6.925, α=0.008]step=41216 | train/step_reward_mean=-0.33944517374038696, train/step_reward_std=0.6813310384750366, train/step_reward_max=1.2270197868347168, train/step_reward_min=-2.370126485824585, episode/length=1000.0, episode/return=-291.6429809942478, episode/return_latest=-266.3424987792969, episode/num_completed=41.0, train/loss_actor=-6.17106294631958, train/loss_qvalue=7.151403903961182, train/loss_alpha=-24.890945434570312, train/alpha=0.0073136757127940655, time/collect=0.13490237212329179, time/replay_extend=0.0005239611086638075, time/train=1.0419397768766987, time/rb - sample=0.0003052529500564548, time/update=0.009919715026626263, time/speed=90.07981238492974\n",
      "  4%|▍         | 41472/1000000 [03:10<3:01:41, 87.93it/s, r_step=-0.34, r_ep=-291.6, n_ep=41, π_loss=-6.171, α=0.007]step=41472 | train/step_reward_mean=-0.14011362195014954, train/step_reward_std=0.6082497835159302, train/step_reward_max=1.7691259384155273, train/step_reward_min=-1.7662607431411743, train/loss_actor=-5.383146286010742, train/loss_qvalue=7.164956092834473, train/loss_alpha=-25.28024673461914, train/alpha=0.006773084867745638, time/collect=0.13573220629750948, time/replay_extend=0.0005249609181910383, time/train=1.0514586295610595, time/rb - sample=0.0003052065578790801, time/update=0.009917531578013438, time/speed=87.92933697862382\n",
      "  4%|▍         | 41728/1000000 [03:12<2:58:54, 89.27it/s, r_step=-0.14, π_loss=-5.383, α=0.007]                      step=41728 | train/step_reward_mean=-0.3479936122894287, train/step_reward_std=0.7212905883789062, train/step_reward_max=1.4291383028030396, train/step_reward_min=-2.4160070419311523, train/loss_actor=-4.655191898345947, train/loss_qvalue=7.275557518005371, train/loss_alpha=-25.665851593017578, train/alpha=0.00627256790176034, time/collect=0.13600077219535972, time/replay_extend=0.0005261576248824229, time/train=1.0614576281214054, time/rb - sample=0.00030512479839451244, time/update=0.009921214190509186, time/speed=89.27288550333996\n",
      "  4%|▍         | 41984/1000000 [03:15<2:58:45, 89.32it/s, r_step=-0.35, π_loss=-4.655, α=0.006]step=41984 | train/step_reward_mean=0.003131992183625698, train/step_reward_std=0.6204796433448792, train/step_reward_max=1.949859380722046, train/step_reward_min=-1.7159878015518188, train/loss_actor=-3.8986446857452393, train/loss_qvalue=7.288545608520508, train/loss_alpha=-26.07381820678711, train/alpha=0.0058087450452148914, time/collect=0.13626258111581574, time/replay_extend=0.0005265009112474393, time/train=1.071043125013026, time/rb - sample=0.0003050569472695445, time/update=0.00992196591209556, time/speed=89.32295537251963\n",
      "  4%|▍         | 42240/1000000 [03:18<2:57:49, 89.77it/s, r_step=0.00, π_loss=-3.899, α=0.006] step=42240 | train/step_reward_mean=-0.28407198190689087, train/step_reward_std=0.6293829679489136, train/step_reward_max=1.576316237449646, train/step_reward_min=-1.8439462184906006, episode/length=1000.0, episode/return=-289.7929362342471, episode/return_latest=-213.94110107421875, episode/num_completed=42.0, train/loss_actor=-3.105236053466797, train/loss_qvalue=7.31974983215332, train/loss_alpha=-26.46912956237793, train/alpha=0.005379185546189547, time/collect=0.13654792236559324, time/replay_extend=0.0005278067155317825, time/train=1.0802100398323753, time/rb - sample=0.0003050173057571911, time/update=0.009919823599321791, time/speed=89.76536002817481\n",
      "  4%|▍         | 42496/1000000 [03:21<2:56:07, 90.61it/s, r_step=-0.28, r_ep=-289.8, n_ep=42, π_loss=-3.105, α=0.005]step=42496 | train/step_reward_mean=-0.5130437612533569, train/step_reward_std=0.669601321220398, train/step_reward_max=1.0526944398880005, train/step_reward_min=-2.1381571292877197, train/loss_actor=-2.3377084732055664, train/loss_qvalue=7.474233150482178, train/loss_alpha=-26.850563049316406, train/alpha=0.004981582518666983, time/collect=0.13678097868540207, time/replay_extend=0.0005274766899016965, time/train=1.0892611368592964, time/rb - sample=0.0003048688497232324, time/update=0.009917802393328371, time/speed=90.60850522357454\n",
      "  4%|▍         | 42752/1000000 [03:24<2:54:56, 91.19it/s, r_step=-0.51, π_loss=-2.338, α=0.005]                      step=42752 | train/step_reward_mean=-0.39003854990005493, train/step_reward_std=0.6205662488937378, train/step_reward_max=1.248843789100647, train/step_reward_min=-2.1672255992889404, train/loss_actor=-1.6372931003570557, train/loss_qvalue=7.46242094039917, train/loss_alpha=-27.2403621673584, train/alpha=0.004613394849002361, time/collect=0.13704203845498095, time/replay_extend=0.0005284854751861023, time/train=1.0982266043474576, time/rb - sample=0.00030495797150901057, time/update=0.009915812832436305, time/speed=91.19356438203302\n",
      "  4%|▍         | 43008/1000000 [03:26<2:54:03, 91.64it/s, r_step=-0.39, π_loss=-1.637, α=0.005]step=43008 | train/step_reward_mean=-0.18353575468063354, train/step_reward_std=0.6239803433418274, train/step_reward_max=1.6112487316131592, train/step_reward_min=-2.1088507175445557, episode/length=1000.0, episode/return=-291.05420933213344, episode/return_latest=-344.0276794433594, episode/num_completed=43.0, train/loss_actor=-0.8394981026649475, train/loss_qvalue=7.492640018463135, train/loss_alpha=-27.625141143798828, train/alpha=0.004272447898983955, time/collect=0.13725915693101434, time/replay_extend=0.000528413624990554, time/train=1.1069585397129968, time/rb - sample=0.0003049332438640152, time/update=0.00991282171346762, time/speed=91.63575483979751\n",
      "  4%|▍         | 43264/1000000 [03:29<2:53:04, 92.13it/s, r_step=-0.18, r_ep=-291.1, n_ep=43, π_loss=-0.839, α=0.004]step=43264 | train/step_reward_mean=-0.2217625230550766, train/step_reward_std=0.6384154558181763, train/step_reward_max=1.6962472200393677, train/step_reward_min=-2.162874460220337, train/loss_actor=-0.13600720465183258, train/loss_qvalue=7.6454620361328125, train/loss_alpha=-28.021215438842773, train/alpha=0.0039566135965287685, time/collect=0.1374901258028471, time/replay_extend=0.0005288815357275968, time/train=1.1157808769384079, time/rb - sample=0.0003049772543211738, time/update=0.00991159527459069, time/speed=92.13265924646993\n",
      "  4%|▍         | 43520/1000000 [03:32<2:53:02, 92.12it/s, r_step=-0.22, π_loss=-0.136, α=0.004]                      step=43520 | train/step_reward_mean=-0.41583526134490967, train/step_reward_std=0.6032746434211731, train/step_reward_max=1.162062644958496, train/step_reward_min=-2.0836241245269775, train/loss_actor=0.6309115886688232, train/loss_qvalue=7.829972743988037, train/loss_alpha=-28.4270076751709, train/alpha=0.0036640185862779617, time/collect=0.13773954896365903, time/replay_extend=0.0005292724160587085, time/train=1.1244599650887883, time/rb - sample=0.00030495538950374256, time/update=0.009910130222672354, time/speed=92.12195937259241\n",
      "  4%|▍         | 43776/1000000 [03:35<2:52:51, 92.19it/s, r_step=-0.42, π_loss=0.631, α=0.004] step=43776 | train/step_reward_mean=-0.36785173416137695, train/step_reward_std=0.6081350445747375, train/step_reward_max=1.4523941278457642, train/step_reward_min=-2.30631685256958, train/loss_actor=1.3503000736236572, train/loss_qvalue=7.947944164276123, train/loss_alpha=-28.818592071533203, train/alpha=0.0033930805511772633, time/collect=0.13796571960226145, time/replay_extend=0.0005300337808173998, time/train=1.1333201391655103, time/rb - sample=0.00030488610217296934, time/update=0.00991130033759641, time/speed=92.19386539721907\n",
      "  4%|▍         | 44032/1000000 [03:37<2:53:37, 91.76it/s, r_step=-0.37, π_loss=1.350, α=0.003]step=44032 | train/step_reward_mean=-0.4191961884498596, train/step_reward_std=0.7240486741065979, train/step_reward_max=1.699013352394104, train/step_reward_min=-2.783257007598877, episode/length=1000.0, episode/return=-292.15587910738856, episode/return_latest=-339.5276794433594, episode/num_completed=44.0, train/loss_actor=2.0535082817077637, train/loss_qvalue=7.955931186676025, train/loss_alpha=-29.195449829101562, train/alpha=0.0031423016916960478, time/collect=0.13820468686347792, time/replay_extend=0.0005306656970534212, time/train=1.142022307529006, time/rb - sample=0.0003048494085669471, time/update=0.00991192211707423, time/speed=91.76190279654061\n",
      "  4%|▍         | 44288/1000000 [03:40<2:53:55, 91.58it/s, r_step=-0.42, r_ep=-292.2, n_ep=44, π_loss=2.054, α=0.003]step=44288 | train/step_reward_mean=-0.24774429202079773, train/step_reward_std=0.660443127155304, train/step_reward_max=1.4124650955200195, train/step_reward_min=-2.3358376026153564, train/loss_actor=2.7824721336364746, train/loss_qvalue=8.073058128356934, train/loss_alpha=-29.58881378173828, train/alpha=0.002910042181611061, time/collect=0.13842397755970162, time/replay_extend=0.0005300541144574995, time/train=1.152164521244909, time/rb - sample=0.00030517666355559154, time/update=0.009925858620063946, time/speed=91.5828493856939\n",
      "  4%|▍         | 44544/1000000 [03:43<2:58:56, 88.99it/s, r_step=-0.25, π_loss=2.782, α=0.003]                      step=44544 | train/step_reward_mean=-0.2020629197359085, train/step_reward_std=0.617693305015564, train/step_reward_max=1.4691526889801025, train/step_reward_min=-2.03197979927063, train/loss_actor=3.5213866233825684, train/loss_qvalue=8.128007888793945, train/loss_alpha=-29.984609603881836, train/alpha=0.002694921800866723, time/collect=0.13859530564012204, time/replay_extend=0.0005312925097586093, time/train=1.1605118184254086, time/rb - sample=0.000305364646211067, time/update=0.009924759459379345, time/speed=88.99291739159355\n",
      "  4%|▍         | 44800/1000000 [03:46<2:57:22, 89.75it/s, r_step=-0.20, π_loss=3.521, α=0.003]step=44800 | train/step_reward_mean=-0.28945109248161316, train/step_reward_std=0.6150302886962891, train/step_reward_max=1.1512941122055054, train/step_reward_min=-2.358975410461426, train/loss_actor=4.207005500793457, train/loss_qvalue=8.107831954956055, train/loss_alpha=-30.382539749145508, train/alpha=0.0024956678971648216, time/collect=0.13888479641505655, time/replay_extend=0.0005308219364711216, time/train=1.16941787311009, time/rb - sample=0.00030554255518393003, time/update=0.009929421190649945, time/speed=89.75089701860428\n",
      "  5%|▍         | 45056/1000000 [03:49<2:58:12, 89.31it/s, r_step=-0.29, π_loss=4.207, α=0.002]step=45056 | train/step_reward_mean=-0.3800317049026489, train/step_reward_std=0.653066873550415, train/step_reward_max=1.3421499729156494, train/step_reward_min=-2.0712194442749023, episode/length=1000.0, episode/return=-291.85316314697263, episode/return_latest=-278.5336608886719, episode/num_completed=45.0, train/loss_actor=4.9523091316223145, train/loss_qvalue=8.27397346496582, train/loss_alpha=-30.767431259155273, train/alpha=0.0023112015333026648, time/collect=0.13909766755320813, time/replay_extend=0.0005315366116437044, time/train=1.1777588061311026, time/rb - sample=0.00030546081311339944, time/update=0.0099301852073661, time/speed=89.30824044157669\n",
      "  5%|▍         | 45312/1000000 [03:52<2:57:12, 89.79it/s, r_step=-0.38, r_ep=-291.9, n_ep=45, π_loss=4.952, α=0.002]step=45312 | train/step_reward_mean=-0.5367226004600525, train/step_reward_std=0.7162447571754456, train/step_reward_max=1.3269447088241577, train/step_reward_min=-2.64997935295105, train/loss_actor=5.6757354736328125, train/loss_qvalue=8.247238159179688, train/loss_alpha=-31.154327392578125, train/alpha=0.002140368800610304, time/collect=0.13930825325055313, time/replay_extend=0.0005321112056236483, time/train=1.185848372130744, time/rb - sample=0.00030536302365362085, time/update=0.009929591650143179, time/speed=89.78578767000528\n",
      "  5%|▍         | 45568/1000000 [03:55<2:56:02, 90.36it/s, r_step=-0.54, π_loss=5.676, α=0.002]                      step=45568 | train/step_reward_mean=-0.11275558173656464, train/step_reward_std=0.6430768966674805, train/step_reward_max=1.6312298774719238, train/step_reward_min=-1.6954243183135986, train/loss_actor=6.371318340301514, train/loss_qvalue=8.301410675048828, train/loss_alpha=-31.541004180908203, train/alpha=0.001982207642868161, time/collect=0.1395331688141555, time/replay_extend=0.000532580225655202, time/train=1.1936611097850154, time/rb - sample=0.00030540633532735495, time/update=0.00992727637244955, time/speed=90.35901420070338\n",
      "  5%|▍         | 45824/1000000 [03:57<2:54:31, 91.12it/s, r_step=-0.11, π_loss=6.371, α=0.002]step=45824 | train/step_reward_mean=-0.3011574447154999, train/step_reward_std=0.6667718291282654, train/step_reward_max=2.0938780307769775, train/step_reward_min=-2.0514075756073, train/loss_actor=7.061017036437988, train/loss_qvalue=8.427200317382812, train/loss_alpha=-31.94864273071289, train/alpha=0.0018356399377807975, time/collect=0.13973322926952852, time/replay_extend=0.0005335061909766169, time/train=1.2017040838742388, time/rb - sample=0.00030545161173837414, time/update=0.009927721024013795, time/speed=91.12311608126028\n",
      "  5%|▍         | 46080/1000000 [04:00<2:54:29, 91.11it/s, r_step=-0.30, π_loss=7.061, α=0.002]step=46080 | train/step_reward_mean=-0.2710939645767212, train/step_reward_std=0.684051513671875, train/step_reward_max=1.4648829698562622, train/step_reward_min=-2.0901548862457275, episode/length=1000.0, episode/return=-292.1824667557426, episode/return_latest=-307.0011291503906, episode/num_completed=46.0, train/loss_actor=7.813465118408203, train/loss_qvalue=8.45766830444336, train/loss_alpha=-32.33714294433594, train/alpha=0.0016999300569295883, time/collect=0.13992879788080853, time/replay_extend=0.0005347808202107746, time/train=1.2098248296313814, time/rb - sample=0.0003054585891315679, time/update=0.009929607319364993, time/speed=91.11486159954102\n",
      "  5%|▍         | 46336/1000000 [04:03<2:55:05, 90.78it/s, r_step=-0.27, r_ep=-292.2, n_ep=46, π_loss=7.813, α=0.002]step=46336 | train/step_reward_mean=-0.16876360774040222, train/step_reward_std=0.6021525859832764, train/step_reward_max=1.723209023475647, train/step_reward_min=-2.365466833114624, train/loss_actor=8.472237586975098, train/loss_qvalue=8.379213333129883, train/loss_alpha=-32.72183609008789, train/alpha=0.0015742749674245715, time/collect=0.1401329541074637, time/replay_extend=0.0005348440033296194, time/train=1.2179425026171773, time/rb - sample=0.00030549675492303114, time/update=0.009932142371932602, time/speed=90.77584615779024\n",
      "  5%|▍         | 46592/1000000 [04:06<2:55:39, 90.46it/s, r_step=-0.17, π_loss=8.472, α=0.002]                      step=46592 | train/step_reward_mean=-0.14345279335975647, train/step_reward_std=0.6305158734321594, train/step_reward_max=2.4060211181640625, train/step_reward_min=-1.9778021574020386, train/loss_actor=9.066225051879883, train/loss_qvalue=8.482135772705078, train/loss_alpha=-33.13237762451172, train/alpha=0.0014578532427549362, time/collect=0.14030722471383905, time/replay_extend=0.0005351789705045929, time/train=1.2255450539536528, time/rb - sample=0.00030551156138671913, time/update=0.009931080908897987, time/speed=90.46389420656207\n",
      "  5%|▍         | 46848/1000000 [04:09<2:54:43, 90.92it/s, r_step=-0.14, π_loss=9.066, α=0.001]step=46848 | train/step_reward_mean=-0.23401139676570892, train/step_reward_std=0.5222214460372925, train/step_reward_max=1.1948261260986328, train/step_reward_min=-1.9746745824813843, train/loss_actor=9.737327575683594, train/loss_qvalue=8.351384162902832, train/loss_alpha=-33.51134490966797, train/alpha=0.0013500829227268696, time/collect=0.14051891024646868, time/replay_extend=0.000535382599127097, time/train=1.2332375714036283, time/rb - sample=0.00030547666341758833, time/update=0.00993152996958338, time/speed=90.92165652380439\n",
      "  5%|▍         | 47104/1000000 [04:11<2:54:32, 90.99it/s, r_step=-0.23, π_loss=9.737, α=0.001]step=47104 | train/step_reward_mean=-0.24278928339481354, train/step_reward_std=0.5550349950790405, train/step_reward_max=1.3618863821029663, train/step_reward_min=-1.9451478719711304, episode/length=1000.0, episode/return=-290.76034691993226, episode/return_latest=-225.34283447265625, episode/num_completed=47.0, train/loss_actor=10.372397422790527, train/loss_qvalue=8.367879867553711, train/loss_alpha=-33.90303039550781, train/alpha=0.0012502747122198343, time/collect=0.1407004542972731, time/replay_extend=0.0005355995634327762, time/train=1.2412498450797536, time/rb - sample=0.0003056131388949187, time/update=0.009935131906692261, time/speed=90.98666504381515\n",
      "  5%|▍         | 47360/1000000 [04:14<2:55:54, 90.26it/s, r_step=-0.24, r_ep=-290.8, n_ep=47, π_loss=10.372, α=0.001]step=47360 | train/step_reward_mean=-0.08692909777164459, train/step_reward_std=0.5139687061309814, train/step_reward_max=1.3224629163742065, train/step_reward_min=-1.597995400428772, train/loss_actor=11.074822425842285, train/loss_qvalue=8.479107856750488, train/loss_alpha=-34.29569625854492, train/alpha=0.0011578461853787303, time/collect=0.14091395945162394, time/replay_extend=0.000536329681808884, time/train=1.2484923053432155, time/rb - sample=0.00030561207412656754, time/update=0.009933179921724534, time/speed=90.25694313541122\n",
      "  5%|▍         | 47616/1000000 [04:17<2:54:32, 90.94it/s, r_step=-0.09, π_loss=11.075, α=0.001]                      step=47616 | train/step_reward_mean=-0.3060315251350403, train/step_reward_std=0.5233022570610046, train/step_reward_max=1.2654709815979004, train/step_reward_min=-2.1550493240356445, train/loss_actor=11.70587158203125, train/loss_qvalue=8.41201400756836, train/loss_alpha=-34.67671203613281, train/alpha=0.0010722745209932327, time/collect=0.14112080809890593, time/replay_extend=0.0005377005505305464, time/train=1.2559452364521642, time/rb - sample=0.0003057124009460477, time/update=0.009933519522460627, time/speed=90.94443323804121\n",
      "  5%|▍         | 47872/1000000 [04:20<2:54:30, 90.93it/s, r_step=-0.31, π_loss=11.706, α=0.001]step=47872 | train/step_reward_mean=-0.31244051456451416, train/step_reward_std=0.5648582577705383, train/step_reward_max=1.0637661218643188, train/step_reward_min=-2.2130508422851562, train/loss_actor=12.368486404418945, train/loss_qvalue=8.24217700958252, train/loss_alpha=-35.08644485473633, train/alpha=0.0009929850930348039, time/collect=0.14132632673742945, time/replay_extend=0.0005370805607760016, time/train=1.2631525623607125, time/rb - sample=0.00030555300828482716, time/update=0.009932765271514618, time/speed=90.93031393968634\n",
      "  5%|▍         | 48128/1000000 [04:23<2:53:55, 91.22it/s, r_step=-0.31, π_loss=12.368, α=0.001]step=48128 | train/step_reward_mean=-0.30164825916290283, train/step_reward_std=0.5801466107368469, train/step_reward_max=1.3559695482254028, train/step_reward_min=-2.4226818084716797, episode/length=1000.0, episode/return=-289.6463122367859, episode/return_latest=-237.28668212890625, episode/num_completed=48.0, train/loss_actor=13.004999160766602, train/loss_qvalue=8.42231559753418, train/loss_alpha=-35.46731948852539, train/alpha=0.0009195845341309905, time/collect=0.14153453137012248, time/replay_extend=0.0005389769026573668, time/train=1.2706397137743362, time/rb - sample=0.00030571541615894235, time/update=0.009934575798419755, time/speed=91.21781021829125\n",
      "  5%|▍         | 48384/1000000 [04:26<2:54:38, 90.82it/s, r_step=-0.30, r_ep=-289.6, n_ep=48, π_loss=13.005, α=0.001]step=48384 | train/step_reward_mean=-0.25675642490386963, train/step_reward_std=0.6474306583404541, train/step_reward_max=1.5901468992233276, train/step_reward_min=-1.9556105136871338, train/loss_actor=13.684906005859375, train/loss_qvalue=8.517843246459961, train/loss_alpha=-35.877525329589844, train/alpha=0.0008515857043676078, time/collect=0.14171124009228264, time/replay_extend=0.0005394012208968874, time/train=1.2776782462205836, time/rb - sample=0.0003058225341627072, time/update=0.009933444600471289, time/speed=90.81703762907192\n",
      "  5%|▍         | 48640/1000000 [04:28<2:53:50, 91.21it/s, r_step=-0.26, π_loss=13.685, α=0.001]                      step=48640 | train/step_reward_mean=-0.2933329939842224, train/step_reward_std=0.5622217059135437, train/step_reward_max=1.8710540533065796, train/step_reward_min=-2.042757034301758, train/loss_actor=14.221741676330566, train/loss_qvalue=8.467534065246582, train/loss_alpha=-36.242210388183594, train/alpha=0.0007886500679887831, time/collect=0.14188875775588194, time/replay_extend=0.0005403430838333932, time/train=1.2846623508553756, time/rb - sample=0.00030585519608950813, time/update=0.009932566344016932, time/speed=91.21340300887822\n",
      "  5%|▍         | 48896/1000000 [04:31<2:53:21, 91.44it/s, r_step=-0.29, π_loss=14.222, α=0.001]step=48896 | train/step_reward_mean=-0.2849059998989105, train/step_reward_std=0.5943760275840759, train/step_reward_max=1.3363839387893677, train/step_reward_min=-2.252127170562744, train/loss_actor=14.882475852966309, train/loss_qvalue=8.419543266296387, train/loss_alpha=-36.63718795776367, train/alpha=0.0007303603924810886, time/collect=0.14205859094390078, time/replay_extend=0.0005409230736537754, time/train=1.2918556760118893, time/rb - sample=0.0003058398935071901, time/update=0.009933993794975084, time/speed=91.44240272142237\n",
      "  5%|▍         | 49152/1000000 [04:34<2:53:58, 91.09it/s, r_step=-0.28, π_loss=14.882, α=0.001]step=49152 | train/step_reward_mean=-0.3709243834018707, train/step_reward_std=0.6994829773902893, train/step_reward_max=1.7726149559020996, train/step_reward_min=-2.2893688678741455, episode/length=1000.0, episode/return=-289.2331114788445, episode/return_latest=-269.39947509765625, episode/num_completed=49.0, train/loss_actor=15.57706069946289, train/loss_qvalue=8.383108139038086, train/loss_alpha=-37.032623291015625, train/alpha=0.0006763769779354334, time/collect=0.14223083729545283, time/replay_extend=0.0005414436260859171, time/train=1.2988156229257584, time/rb - sample=0.0003057324670647259, time/update=0.009934233854475737, time/speed=91.08999423495807\n",
      "  5%|▍         | 49408/1000000 [04:37<2:53:59, 91.06it/s, r_step=-0.37, r_ep=-289.2, n_ep=49, π_loss=15.577, α=0.001]step=49408 | train/step_reward_mean=-0.10955056548118591, train/step_reward_std=0.5586573481559753, train/step_reward_max=1.1143651008605957, train/step_reward_min=-1.4664405584335327, train/loss_actor=16.1752986907959, train/loss_qvalue=8.417377471923828, train/loss_alpha=-37.42720413208008, train/alpha=0.0006263732793740928, time/collect=0.14244711831443674, time/replay_extend=0.0005420971410879816, time/train=1.3057002490048581, time/rb - sample=0.0003059007964717788, time/update=0.009934153136176327, time/speed=91.05544501225489\n",
      "  5%|▍         | 49664/1000000 [04:40<2:53:59, 91.03it/s, r_step=-0.11, π_loss=16.175, α=0.001]                      step=49664 | train/step_reward_mean=-0.3642193675041199, train/step_reward_std=0.6471849679946899, train/step_reward_max=1.2222689390182495, train/step_reward_min=-2.0306177139282227, train/loss_actor=16.863056182861328, train/loss_qvalue=8.452775955200195, train/loss_alpha=-37.8215217590332, train/alpha=0.0005800673388876021, time/collect=0.14266250551361406, time/replay_extend=0.0005437787046137545, time/train=1.3125152673917948, time/rb - sample=0.0003059455145572828, time/update=0.009934219042050437, time/speed=91.03360074186088\n",
      "  5%|▍         | 49920/1000000 [04:42<2:53:50, 91.09it/s, r_step=-0.36, π_loss=16.863, α=0.001]step=49920 | train/step_reward_mean=-0.40105611085891724, train/step_reward_std=0.6176632046699524, train/step_reward_max=1.3586612939834595, train/step_reward_min=-2.1306960582733154, train/loss_actor=17.45801544189453, train/loss_qvalue=8.409956932067871, train/loss_alpha=-38.20786666870117, train/alpha=0.0005371872684918344, time/collect=0.14283691675235072, time/replay_extend=0.0005435466766357422, time/train=1.3196421928894828, time/rb - sample=0.00030605079682201255, time/update=0.009937188721128839, time/speed=91.08786312302335\n",
      "  5%|▌         | 50176/1000000 [04:45<2:55:10, 90.37it/s, r_step=-0.40, π_loss=17.458, α=0.001]step=50176 | train/step_reward_mean=-0.43360674381256104, train/step_reward_std=0.7240746021270752, train/step_reward_max=1.8731482028961182, train/step_reward_min=-3.158163070678711, episode/length=1000.0, episode/return=-290.1623896789551, episode/return_latest=-335.697021484375, episode/num_completed=50.0, train/loss_actor=18.05435562133789, train/loss_qvalue=8.457418441772461, train/loss_alpha=-38.61351013183594, train/alpha=0.0004974683979526162, time/collect=0.14301986718664372, time/replay_extend=0.0005447073858611439, time/train=1.326042722682564, time/rb - sample=0.00030607621025556905, time/update=0.009935128784766678, time/speed=90.3688363956387\n",
      "  5%|▌         | 50432/1000000 [04:48<2:53:32, 91.19it/s, r_step=-0.43, r_ep=-290.2, n_ep=50, π_loss=18.054, α=0.000]step=50432 | train/step_reward_mean=-0.184754878282547, train/step_reward_std=0.574979841709137, train/step_reward_max=1.2696484327316284, train/step_reward_min=-1.666940450668335, train/loss_actor=18.675865173339844, train/loss_qvalue=8.407652854919434, train/loss_alpha=-39.00978469848633, train/alpha=0.0004606839211191982, time/collect=0.1431626027005579, time/replay_extend=0.0005448288118778753, time/train=1.3333421866905872, time/rb - sample=0.0003063852526247448, time/update=0.009940231274813405, time/speed=91.19254392908623\n",
      "  5%|▌         | 50688/1000000 [04:51<2:55:59, 89.90it/s, r_step=-0.18, π_loss=18.676, α=0.000]                      step=50688 | train/step_reward_mean=-0.24344216287136078, train/step_reward_std=0.7144160866737366, train/step_reward_max=1.1801948547363281, train/step_reward_min=-2.2425506114959717, train/loss_actor=19.335067749023438, train/loss_qvalue=8.620551109313965, train/loss_alpha=-39.39443588256836, train/alpha=0.00042662530904635787, time/collect=0.14332362497695775, time/replay_extend=0.0005446154661852905, time/train=1.3401360054208775, time/rb - sample=0.0003067113477552237, time/update=0.009941909406887398, time/speed=89.90409149791334\n",
      "  5%|▌         | 50944/1000000 [04:54<2:56:12, 89.77it/s, r_step=-0.24, π_loss=19.335, α=0.000]step=50944 | train/step_reward_mean=-0.4077950119972229, train/step_reward_std=0.6902261972427368, train/step_reward_max=1.2680261135101318, train/step_reward_min=-2.359661102294922, train/loss_actor=19.979835510253906, train/loss_qvalue=8.693655014038086, train/loss_alpha=-39.77220916748047, train/alpha=0.0003950940736103803, time/collect=0.14351484643754053, time/replay_extend=0.0005454537856518924, time/train=1.3464952054335244, time/rb - sample=0.00030665707719676125, time/update=0.009941138646693173, time/speed=89.7703490730952\n",
      "  5%|▌         | 51200/1000000 [04:57<2:55:01, 90.35it/s, r_step=-0.41, π_loss=19.980, α=0.000]step=51200 | train/step_reward_mean=-0.19868184626102448, train/step_reward_std=0.6660848259925842, train/step_reward_max=1.748447299003601, train/step_reward_min=-1.8983030319213867, episode/length=1000.0, episode/return=-290.41098396450866, episode/return_latest=-302.8406982421875, episode/num_completed=51.0, train/loss_actor=20.505691528320312, train/loss_qvalue=8.560354232788086, train/loss_alpha=-40.189537048339844, train/alpha=0.00036587895010598004, time/collect=0.14371528029441838, time/replay_extend=0.0005471432209014894, time/train=1.3534415757656098, time/rb - sample=0.00030657750310249227, time/update=0.009945346648325581, time/speed=90.34662228335414\n",
      "  5%|▌         | 51456/1000000 [05:00<2:56:34, 89.53it/s, r_step=-0.20, r_ep=-290.4, n_ep=51, π_loss=20.506, α=0.000]step=51456 | train/step_reward_mean=-0.35244590044021606, train/step_reward_std=0.6866593956947327, train/step_reward_max=1.5775419473648071, train/step_reward_min=-1.7573626041412354, train/loss_actor=21.153133392333984, train/loss_qvalue=8.76891803741455, train/loss_alpha=-40.55350112915039, train/alpha=0.00033883884316310287, time/collect=0.14388965136969273, time/replay_extend=0.0005476783164105014, time/train=1.359488426749386, time/rb - sample=0.00030660140328108766, time/update=0.009943101975995162, time/speed=89.53438576855604\n",
      "  5%|▌         | 51712/1000000 [05:02<2:54:22, 90.63it/s, r_step=-0.35, π_loss=21.153, α=0.000]                      step=51712 | train/step_reward_mean=-0.4704776704311371, train/step_reward_std=0.6440340280532837, train/step_reward_max=1.1611299514770508, train/step_reward_min=-2.2102105617523193, train/loss_actor=21.78773307800293, train/loss_qvalue=8.739620208740234, train/loss_alpha=-40.95832443237305, train/alpha=0.0003137818712275475, time/collect=0.1440333529274063, time/replay_extend=0.0005482895539538697, time/train=1.3656564950942993, time/rb - sample=0.00030656928817430655, time/update=0.009942315731729762, time/speed=90.63495492875796\n",
      "  5%|▌         | 51968/1000000 [05:05<2:53:37, 91.00it/s, r_step=-0.47, π_loss=21.788, α=0.000]step=51968 | train/step_reward_mean=-0.19168606400489807, train/step_reward_std=0.6291250586509705, train/step_reward_max=1.3270012140274048, train/step_reward_min=-1.7686147689819336, train/loss_actor=22.32408905029297, train/loss_qvalue=8.733664512634277, train/loss_alpha=-41.35509490966797, train/alpha=0.0002905801811721176, time/collect=0.14420664134283964, time/replay_extend=0.0005483063570971562, time/train=1.371791192463466, time/rb - sample=0.0003065632585928083, time/update=0.009941722951688835, time/speed=91.00061619817707\n",
      "  5%|▌         | 52224/1000000 [05:08<2:53:05, 91.26it/s, r_step=-0.19, π_loss=22.324, α=0.000]step=52224 | train/step_reward_mean=-0.30409783124923706, train/step_reward_std=0.6315014362335205, train/step_reward_max=1.5940725803375244, train/step_reward_min=-2.0089521408081055, episode/length=1000.0, episode/return=-291.01170539855957, episode/return_latest=-321.64849853515625, episode/num_completed=52.0, train/loss_actor=22.86423110961914, train/loss_qvalue=8.743734359741211, train/loss_alpha=-41.72713851928711, train/alpha=0.0002691038534976542, time/collect=0.14435318638296693, time/replay_extend=0.0005491282425674741, time/train=1.3779701929466397, time/rb - sample=0.0003065299242734871, time/update=0.009941944782839753, time/speed=91.25769506218667\n",
      "  5%|▌         | 52480/1000000 [05:11<2:53:13, 91.17it/s, r_step=-0.30, r_ep=-291.0, n_ep=52, π_loss=22.864, α=0.000]step=52480 | train/step_reward_mean=-0.14929069578647614, train/step_reward_std=0.7497678995132446, train/step_reward_max=1.746977686882019, train/step_reward_min=-2.715696334838867, train/loss_actor=23.53049087524414, train/loss_qvalue=8.84712028503418, train/loss_alpha=-42.141544342041016, train/alpha=0.00024920361465774477, time/collect=0.14452739692315827, time/replay_extend=0.0005495769221608235, time/train=1.3840596047843374, time/rb - sample=0.00030651654082315514, time/update=0.009941925587891434, time/speed=91.16553838006418\n",
      "  5%|▌         | 52736/1000000 [05:13<2:53:11, 91.16it/s, r_step=-0.15, π_loss=23.530, α=0.000]                      step=52736 | train/step_reward_mean=-0.35995131731033325, train/step_reward_std=0.60743248462677, train/step_reward_max=1.1798372268676758, train/step_reward_min=-2.046189546585083, train/loss_actor=24.01409912109375, train/loss_qvalue=8.791947364807129, train/loss_alpha=-42.51638412475586, train/alpha=0.00023078711819835007, time/collect=0.1446920668037193, time/replay_extend=0.000549933285389132, time/train=1.390133320706562, time/rb - sample=0.0003064508045758633, time/update=0.009942281341880844, time/speed=91.15768434490207\n",
      "  5%|▌         | 52992/1000000 [05:16<2:55:04, 90.15it/s, r_step=-0.36, π_loss=24.014, α=0.000]step=52992 | train/step_reward_mean=-0.2744249701499939, train/step_reward_std=0.582876980304718, train/step_reward_max=1.3320033550262451, train/step_reward_min=-1.9075052738189697, train/loss_actor=24.559085845947266, train/loss_qvalue=8.815698623657227, train/loss_alpha=-42.92024230957031, train/alpha=0.00021372306218836457, time/collect=0.14532509057418166, time/replay_extend=0.0005501802416815277, time/train=1.3957879670000308, time/rb - sample=0.00030637475746598695, time/update=0.009940000809729123, time/speed=90.15200844833103\n",
      "  5%|▌         | 53248/1000000 [05:19<2:53:09, 91.13it/s, r_step=-0.27, π_loss=24.559, α=0.000]step=53248 | train/step_reward_mean=-0.5344473123550415, train/step_reward_std=0.6105950474739075, train/step_reward_max=0.8608488440513611, train/step_reward_min=-2.1349782943725586, episode/length=1000.0, episode/return=-290.2982213722085, episode/return_latest=-253.19705200195312, episode/num_completed=53.0, train/loss_actor=25.1386661529541, train/loss_qvalue=8.865117073059082, train/loss_alpha=-43.308834075927734, train/alpha=0.00019791880913544446, time/collect=0.145473246391003, time/replay_extend=0.0005505772737356336, time/train=1.4014616001110813, time/rb - sample=0.0003064129551922907, time/update=0.00993818100877445, time/speed=91.1250006700408\n",
      "  5%|▌         | 53504/1000000 [05:22<2:52:01, 91.70it/s, r_step=-0.53, r_ep=-290.3, n_ep=53, π_loss=25.139, α=0.000]step=53504 | train/step_reward_mean=-0.345963716506958, train/step_reward_std=0.6660487055778503, train/step_reward_max=1.4159934520721436, train/step_reward_min=-2.6000137329101562, train/loss_actor=25.69058609008789, train/loss_qvalue=8.979883193969727, train/loss_alpha=-43.689266204833984, train/alpha=0.00018328847363591194, time/collect=0.14560351189243742, time/replay_extend=0.0005509317206423822, time/train=1.407233651174883, time/rb - sample=0.0003064273374288161, time/update=0.009937529094583794, time/speed=91.70137984786344\n",
      "  5%|▌         | 53760/1000000 [05:25<2:51:53, 91.74it/s, r_step=-0.35, π_loss=25.691, α=0.000]                      step=53760 | train/step_reward_mean=-0.5319551229476929, train/step_reward_std=0.6869403719902039, train/step_reward_max=1.5514657497406006, train/step_reward_min=-2.2190887928009033, train/loss_actor=26.339323043823242, train/loss_qvalue=8.67436695098877, train/loss_alpha=-44.08794403076172, train/alpha=0.00016973931633401662, time/collect=0.14575530347369972, time/replay_extend=0.0005515688941592266, time/train=1.4127897432872227, time/rb - sample=0.00030645680308868977, time/update=0.00993570669727254, time/speed=91.74491314260206\n",
      "  5%|▌         | 54016/1000000 [05:27<2:51:13, 92.08it/s, r_step=-0.53, π_loss=26.339, α=0.000]step=54016 | train/step_reward_mean=-0.17607258260250092, train/step_reward_std=0.5694649815559387, train/step_reward_max=1.0607036352157593, train/step_reward_min=-1.9877196550369263, episode/length=1000.0, episode/return=-292.4367920204445, episode/return_latest=-405.7810363769531, episode/num_completed=54.0, train/loss_actor=26.85846710205078, train/loss_qvalue=8.887250900268555, train/loss_alpha=-44.49052429199219, train/alpha=0.00015718543727416545, time/collect=0.14590933537596215, time/replay_extend=0.0005516994620951434, time/train=1.4186291412154646, time/rb - sample=0.00030650614286984823, time/update=0.009936320513748298, time/speed=92.07814662048793\n",
      "  5%|▌         | 54272/1000000 [05:30<2:51:59, 91.65it/s, r_step=-0.18, r_ep=-292.4, n_ep=54, π_loss=26.858, α=0.000]step=54272 | train/step_reward_mean=-0.2830580472946167, train/step_reward_std=0.7723333239555359, train/step_reward_max=1.8834776878356934, train/step_reward_min=-2.2494800090789795, train/loss_actor=27.339996337890625, train/loss_qvalue=8.909085273742676, train/loss_alpha=-44.87181091308594, train/alpha=0.00014556324458681047, time/collect=0.1460579689943566, time/replay_extend=0.0005517545736060955, time/train=1.4243183799509733, time/rb - sample=0.0003065557988441454, time/update=0.009936237748226405, time/speed=91.64534035970053\n",
      "  5%|▌         | 54528/1000000 [05:33<2:52:07, 91.55it/s, r_step=-0.28, π_loss=27.340, α=0.000]                      step=54528 | train/step_reward_mean=-0.5821852684020996, train/step_reward_std=0.7764917612075806, train/step_reward_max=1.4155231714248657, train/step_reward_min=-2.522123098373413, train/loss_actor=27.926864624023438, train/loss_qvalue=8.885449409484863, train/loss_alpha=-45.264991760253906, train/alpha=0.0001348041114397347, time/collect=0.14620263363833724, time/replay_extend=0.0005521203430605609, time/train=1.4300109153622194, time/rb - sample=0.0003066924480913985, time/update=0.009936477988958359, time/speed=91.54770548075423\n",
      "  5%|▌         | 54784/1000000 [05:36<2:52:22, 91.39it/s, r_step=-0.58, π_loss=27.927, α=0.000]step=54784 | train/step_reward_mean=-0.18600088357925415, train/step_reward_std=0.7094749808311462, train/step_reward_max=1.7046452760696411, train/step_reward_min=-2.389784574508667, train/loss_actor=28.480716705322266, train/loss_qvalue=8.938714981079102, train/loss_alpha=-45.650333404541016, train/alpha=0.00012484022590797395, time/collect=0.1463332889236023, time/replay_extend=0.0005522821551171422, time/train=1.4357096402444574, time/rb - sample=0.00030691012676454464, time/update=0.009937047234012033, time/speed=91.38799876683234\n",
      "  6%|▌         | 55040/1000000 [05:39<2:52:59, 91.04it/s, r_step=-0.19, π_loss=28.481, α=0.000]step=55040 | train/step_reward_mean=-0.13776829838752747, train/step_reward_std=0.6294552087783813, train/step_reward_max=1.7032506465911865, train/step_reward_min=-2.3161346912384033, episode/length=1000.0, episode/return=-292.37734999223187, episode/return_latest=-289.16748046875, episode/num_completed=55.0, train/loss_actor=28.945009231567383, train/loss_qvalue=8.917078018188477, train/loss_alpha=-46.066444396972656, train/alpha=0.00011560774146346375, time/collect=0.1465147805768391, time/replay_extend=0.0005531965300094253, time/train=1.4414823731710746, time/rb - sample=0.00030703364350532516, time/update=0.009938603322321608, time/speed=91.04152518527812\n",
      "  6%|▌         | 55296/1000000 [05:42<2:53:42, 90.64it/s, r_step=-0.14, r_ep=-292.4, n_ep=55, π_loss=28.945, α=0.000]step=55296 | train/step_reward_mean=-0.3709992468357086, train/step_reward_std=0.7219546437263489, train/step_reward_max=1.7179120779037476, train/step_reward_min=-2.3886878490448, train/loss_actor=29.573625564575195, train/loss_qvalue=8.788692474365234, train/loss_alpha=-46.4422607421875, train/alpha=0.00010706171451602131, time/collect=0.1466318015699034, time/replay_extend=0.0005534478911647093, time/train=1.4471941579271248, time/rb - sample=0.0003070577493860892, time/update=0.009940180207500978, time/speed=90.64072369798629\n",
      "  6%|▌         | 55552/1000000 [05:44<2:54:17, 90.32it/s, r_step=-0.37, π_loss=29.574, α=0.000]                      step=55552 | train/step_reward_mean=-0.5366305708885193, train/step_reward_std=0.7026058435440063, train/step_reward_max=1.17588210105896, train/step_reward_min=-2.762047290802002, train/loss_actor=30.073015213012695, train/loss_qvalue=8.790596008300781, train/loss_alpha=-46.84490203857422, train/alpha=9.996994776884094e-05, time/collect=0.14678980677907924, time/replay_extend=0.0005534903794389719, time/train=1.452519576121036, time/rb - sample=0.00030703548497209513, time/update=0.009939419035799849, time/speed=90.31694104079904\n",
      "  6%|▌         | 55808/1000000 [05:47<2:53:18, 90.80it/s, r_step=-0.54, π_loss=30.073, α=0.000]step=55808 | train/step_reward_mean=-0.3458566665649414, train/step_reward_std=0.6193166375160217, train/step_reward_max=1.3941651582717896, train/step_reward_min=-2.216327667236328, train/loss_actor=30.554630279541016, train/loss_qvalue=8.869013786315918, train/loss_alpha=-46.989532470703125, train/alpha=9.996994776884094e-05, time/collect=0.14694073768930704, time/replay_extend=0.0005527647263413178, time/train=1.458333719761, time/rb - sample=0.0003071373159235129, time/update=0.009942318674577212, time/speed=90.79740503260847\n",
      "  6%|▌         | 56064/1000000 [05:50<2:54:52, 89.96it/s, r_step=-0.35, π_loss=30.555, α=0.000]step=56064 | train/step_reward_mean=-0.1359487622976303, train/step_reward_std=0.6852515935897827, train/step_reward_max=1.618683934211731, train/step_reward_min=-2.2086732387542725, episode/length=1000.0, episode/return=-293.80898788997104, episode/return_latest=-372.549072265625, episode/num_completed=56.0, train/loss_actor=31.14365577697754, train/loss_qvalue=8.939788818359375, train/loss_alpha=-46.99853515625, train/alpha=9.997004963224754e-05, time/collect=0.14711258727121576, time/replay_extend=0.0005540847778320315, time/train=1.4642667813932515, time/rb - sample=0.0003072408821861227, time/update=0.009946379764768965, time/speed=89.96499341308711\n",
      "  6%|▌         | 56320/1000000 [05:53<2:56:27, 89.14it/s, r_step=-0.14, r_ep=-293.8, n_ep=56, π_loss=31.144, α=0.000]step=56320 | train/step_reward_mean=-0.23280534148216248, train/step_reward_std=0.6303310990333557, train/step_reward_max=1.4196727275848389, train/step_reward_min=-2.5931248664855957, train/loss_actor=31.643972396850586, train/loss_qvalue=8.921491622924805, train/loss_alpha=-46.99668884277344, train/alpha=9.997004963224754e-05, time/collect=0.14723445285450334, time/replay_extend=0.0005553028800270776, time/train=1.4699501980434766, time/rb - sample=0.00030732864317127833, time/update=0.009949028908418985, time/speed=89.13542084694632\n",
      "  6%|▌         | 56576/1000000 [05:56<2:56:50, 88.91it/s, r_step=-0.23, π_loss=31.644, α=0.000]                      step=56576 | train/step_reward_mean=-0.30634400248527527, train/step_reward_std=0.6148591637611389, train/step_reward_max=1.3369851112365723, train/step_reward_min=-2.2212061882019043, train/loss_actor=32.114559173583984, train/loss_qvalue=8.889317512512207, train/loss_alpha=-46.99380111694336, train/alpha=9.997004963224754e-05, time/collect=0.14736991230718696, time/replay_extend=0.0005547061764816356, time/train=1.4755410112406875, time/rb - sample=0.0003073987430862801, time/update=0.009951360703956772, time/speed=88.91149136331636\n",
      "  6%|▌         | 56832/1000000 [05:59<2:56:57, 88.83it/s, r_step=-0.31, π_loss=32.115, α=0.000]step=56832 | train/step_reward_mean=-0.4486212730407715, train/step_reward_std=0.6625698208808899, train/step_reward_max=1.119623064994812, train/step_reward_min=-2.8553409576416016, train/loss_actor=32.62194061279297, train/loss_qvalue=9.04432487487793, train/loss_alpha=-46.98475646972656, train/alpha=9.996994776884094e-05, time/collect=0.14752081600395414, time/replay_extend=0.0005553348644359695, time/train=1.4810960367993196, time/rb - sample=0.00030750569701194346, time/update=0.00995371914654976, time/speed=88.83045892467806\n",
      "  6%|▌         | 57088/1000000 [06:02<2:56:57, 88.81it/s, r_step=-0.45, π_loss=32.622, α=0.000]step=57088 | train/step_reward_mean=-0.2764844000339508, train/step_reward_std=0.6923143863677979, train/step_reward_max=1.510909914970398, train/step_reward_min=-1.922468662261963, episode/length=1000.0, episode/return=-293.69724809077746, episode/return_latest=-287.4398193359375, episode/num_completed=57.0, train/loss_actor=33.0898551940918, train/loss_qvalue=9.015470504760742, train/loss_alpha=-46.970436096191406, train/alpha=9.997004963224754e-05, time/collect=0.14763959854707595, time/replay_extend=0.000555628618317335, time/train=1.4860657544414029, time/rb - sample=0.0003075583557051289, time/update=0.009952395186123944, time/speed=88.8060644887111\n",
      "  6%|▌         | 57344/1000000 [06:04<2:54:47, 89.89it/s, r_step=-0.28, r_ep=-293.7, n_ep=57, π_loss=33.090, α=0.000]step=57344 | train/step_reward_mean=-0.2743597626686096, train/step_reward_std=0.72677081823349, train/step_reward_max=1.6031256914138794, train/step_reward_min=-2.2004964351654053, train/loss_actor=33.653770446777344, train/loss_qvalue=9.0174560546875, train/loss_alpha=-46.989990234375, train/alpha=9.996994776884094e-05, time/collect=0.14776613243988587, time/replay_extend=0.0005559942552021576, time/train=1.4909314385482249, time/rb - sample=0.00030756583363990704, time/update=0.009950727026352317, time/speed=89.88774172325667\n",
      "  6%|▌         | 57600/1000000 [06:07<2:53:02, 90.76it/s, r_step=-0.27, π_loss=33.654, α=0.000]                      step=57600 | train/step_reward_mean=-0.24809065461158752, train/step_reward_std=0.691998302936554, train/step_reward_max=1.5096969604492188, train/step_reward_min=-2.3835062980651855, train/loss_actor=34.10182571411133, train/loss_qvalue=9.031590461730957, train/loss_alpha=-46.99003601074219, train/alpha=9.996994776884094e-05, time/collect=0.14790301534864644, time/replay_extend=0.0005561224619547529, time/train=1.4960316244761156, time/rb - sample=0.0003076528082601685, time/update=0.009950906649464783, time/speed=90.76411182959463\n",
      "  6%|▌         | 57856/1000000 [06:10<2:53:01, 90.75it/s, r_step=-0.25, π_loss=34.102, α=0.000]step=57856 | train/step_reward_mean=-0.28188538551330566, train/step_reward_std=0.5560274720191956, train/step_reward_max=1.155800461769104, train/step_reward_min=-1.921056866645813, train/loss_actor=34.52599334716797, train/loss_qvalue=9.073989868164062, train/loss_alpha=-46.99420166015625, train/alpha=9.996994776884094e-05, time/collect=0.14804122194779665, time/replay_extend=0.0005563645236260071, time/train=1.5006990052957456, time/rb - sample=0.0003077409973786745, time/update=0.009948431384251624, time/speed=90.7520645391919\n",
      "  6%|▌         | 58112/1000000 [06:13<2:51:11, 91.70it/s, r_step=-0.28, π_loss=34.526, α=0.000]step=58112 | train/step_reward_mean=-0.15683956444263458, train/step_reward_std=0.6253816485404968, train/step_reward_max=1.7660659551620483, train/step_reward_min=-2.1794066429138184, episode/length=1000.0, episode/return=-293.5377961520491, episode/return_latest=-284.44903564453125, episode/num_completed=58.0, train/loss_actor=34.995384216308594, train/loss_qvalue=9.104862213134766, train/loss_alpha=-46.988861083984375, train/alpha=9.996994776884094e-05, time/collect=0.1481422537749035, time/replay_extend=0.00055725353929965, time/train=1.505356925174529, time/rb - sample=0.00030783593224791044, time/update=0.009946202085568415, time/speed=91.70167111696647\n",
      "  6%|▌         | 58368/1000000 [06:15<2:50:00, 92.31it/s, r_step=-0.16, r_ep=-293.5, n_ep=58, π_loss=34.995, α=0.000]step=58368 | train/step_reward_mean=-0.29651203751564026, train/step_reward_std=0.6805179119110107, train/step_reward_max=1.3780721426010132, train/step_reward_min=-2.5410053730010986, train/loss_actor=35.493080139160156, train/loss_qvalue=9.162857055664062, train/loss_alpha=-47.00569152832031, train/alpha=9.996994776884094e-05, time/collect=0.1482401960774473, time/replay_extend=0.0005579904506081031, time/train=1.5099923035554723, time/rb - sample=0.00030789040882168436, time/update=0.00994417113287538, time/speed=92.30960709754427\n",
      "  6%|▌         | 58624/1000000 [06:18<2:49:18, 92.67it/s, r_step=-0.30, π_loss=35.493, α=0.000]                      step=58624 | train/step_reward_mean=-0.4541018307209015, train/step_reward_std=0.6182733178138733, train/step_reward_max=0.7207357883453369, train/step_reward_min=-2.372248649597168, train/loss_actor=35.96898651123047, train/loss_qvalue=9.13661003112793, train/loss_alpha=-46.991355895996094, train/alpha=9.997004963224754e-05, time/collect=0.1483494058967158, time/replay_extend=0.0005580639735059448, time/train=1.5148869570686312, time/rb - sample=0.0003078792766300978, time/update=0.009944264579451509, time/speed=92.6702953921425\n",
      "  6%|▌         | 58880/1000000 [06:21<2:50:16, 92.12it/s, r_step=-0.45, π_loss=35.969, α=0.000]step=58880 | train/step_reward_mean=-0.10765641927719116, train/step_reward_std=0.5869475603103638, train/step_reward_max=1.239017367362976, train/step_reward_min=-2.3158297538757324, train/loss_actor=36.47707748413086, train/loss_qvalue=9.131895065307617, train/loss_alpha=-46.97139358520508, train/alpha=9.997004963224754e-05, time/collect=0.14850852489471444, time/replay_extend=0.0005575439204340398, time/train=1.5201632758845458, time/rb - sample=0.00030795985454679103, time/update=0.009947126437174693, time/speed=92.11997744260663\n",
      "  6%|▌         | 59136/1000000 [06:24<2:52:46, 90.76it/s, r_step=-0.11, π_loss=36.477, α=0.000]step=59136 | train/step_reward_mean=-0.2948601543903351, train/step_reward_std=0.6010160446166992, train/step_reward_max=1.4230176210403442, train/step_reward_min=-2.8351082801818848, episode/length=1000.0, episode/return=-292.66896923517777, episode/return_latest=-242.27700805664062, episode/num_completed=59.0, train/loss_actor=36.90096664428711, train/loss_qvalue=9.144342422485352, train/loss_alpha=-46.99419403076172, train/alpha=9.997004963224754e-05, time/collect=0.1486679238158388, time/replay_extend=0.0005591875546938416, time/train=1.5257203909225798, time/rb - sample=0.00030803448284294764, time/update=0.009952146664206275, time/speed=90.75928567355231\n",
      "  6%|▌         | 59392/1000000 [06:27<2:55:42, 89.22it/s, r_step=-0.29, r_ep=-292.7, n_ep=59, π_loss=36.901, α=0.000]step=59392 | train/step_reward_mean=-0.24092642962932587, train/step_reward_std=0.6507329344749451, train/step_reward_max=1.7793645858764648, train/step_reward_min=-2.3330037593841553, train/loss_actor=37.31793975830078, train/loss_qvalue=9.052108764648438, train/loss_alpha=-46.99225997924805, train/alpha=9.996994776884094e-05, time/collect=0.14879084661089148, time/replay_extend=0.0005610862682605615, time/train=1.530314662333193, time/rb - sample=0.00030804353041780997, time/update=0.009951019183629152, time/speed=89.21734757406621\n",
      "  6%|▌         | 59648/1000000 [06:30<2:53:50, 90.16it/s, r_step=-0.24, π_loss=37.318, α=0.000]                      step=59648 | train/step_reward_mean=-0.2893642783164978, train/step_reward_std=0.5353273749351501, train/step_reward_max=1.3485099077224731, train/step_reward_min=-1.5979524850845337, train/loss_actor=37.79964828491211, train/loss_qvalue=9.11438274383545, train/loss_alpha=-46.998130798339844, train/alpha=9.997004963224754e-05, time/collect=0.14890786301936212, time/replay_extend=0.0005613202189171266, time/train=1.5347711651110347, time/rb - sample=0.00030799159396658666, time/update=0.009949316900661816, time/speed=90.15668549453316\n",
      "  6%|▌         | 59904/1000000 [06:32<2:52:06, 91.04it/s, r_step=-0.29, π_loss=37.800, α=0.000]step=59904 | train/step_reward_mean=-0.29668253660202026, train/step_reward_std=0.6351485848426819, train/step_reward_max=1.4350078105926514, train/step_reward_min=-2.8622148036956787, train/loss_actor=38.13703918457031, train/loss_qvalue=9.116992950439453, train/loss_alpha=-46.96462631225586, train/alpha=9.997004963224754e-05, time/collect=0.14903096459869655, time/replay_extend=0.0005620208560911002, time/train=1.5396295531183233, time/rb - sample=0.00030804689919208724, time/update=0.009950465821817465, time/speed=91.03629826744992\n",
      "  6%|▌         | 60160/1000000 [06:35<2:52:56, 90.58it/s, r_step=-0.30, π_loss=38.137, α=0.000]step=60160 | train/step_reward_mean=-0.1819041520357132, train/step_reward_std=0.5589511394500732, train/step_reward_max=1.3199422359466553, train/step_reward_min=-1.4452755451202393, episode/length=1000.0, episode/return=-292.54106559753416, episode/return_latest=-284.9947509765625, episode/num_completed=60.0, train/loss_actor=38.53541946411133, train/loss_qvalue=9.156816482543945, train/loss_alpha=-46.978981018066406, train/alpha=9.997004963224754e-05, time/collect=0.14918852562600005, time/replay_extend=0.0005625694356066118, time/train=1.5443731876129805, time/rb - sample=0.0003080421761758065, time/update=0.009951168279824982, time/speed=90.57758531512866\n",
      "  6%|▌         | 60416/1000000 [06:38<2:53:04, 90.48it/s, r_step=-0.18, r_ep=-292.5, n_ep=60, π_loss=38.535, α=0.000]step=60416 | train/step_reward_mean=-0.463956356048584, train/step_reward_std=0.7386363744735718, train/step_reward_max=1.4017934799194336, train/step_reward_min=-2.8065991401672363, train/loss_actor=39.037593841552734, train/loss_qvalue=9.195295333862305, train/loss_alpha=-46.98137283325195, train/alpha=9.996994776884094e-05, time/collect=0.14930991904210247, time/replay_extend=0.0005638356936179988, time/train=1.549109530650964, time/rb - sample=0.0003081113435059977, time/update=0.00995200270746686, time/speed=90.48026417149032\n",
      "  6%|▌         | 60672/1000000 [06:41<2:53:26, 90.27it/s, r_step=-0.46, π_loss=39.038, α=0.000]                      step=60672 | train/step_reward_mean=-0.3183375597000122, train/step_reward_std=0.5504510402679443, train/step_reward_max=1.1839300394058228, train/step_reward_min=-1.7703750133514404, train/loss_actor=39.43775939941406, train/loss_qvalue=9.026803016662598, train/loss_alpha=-46.974082946777344, train/alpha=9.996994776884094e-05, time/collect=0.1494713533779741, time/replay_extend=0.0005638689934452881, time/train=1.5537129192915653, time/rb - sample=0.0003081314265727974, time/update=0.009952261192458055, time/speed=90.26687447642863\n",
      "  6%|▌         | 60928/1000000 [06:44<2:53:01, 90.45it/s, r_step=-0.32, π_loss=39.438, α=0.000]step=60928 | train/step_reward_mean=-0.35727643966674805, train/step_reward_std=0.591205358505249, train/step_reward_max=1.0495314598083496, train/step_reward_min=-1.9349565505981445, train/loss_actor=39.82345199584961, train/loss_qvalue=9.0892333984375, train/loss_alpha=-46.98796844482422, train/alpha=9.996994776884094e-05, time/collect=0.149577848049773, time/replay_extend=0.0005645030686835284, time/train=1.5583046434306302, time/rb - sample=0.0003082372763372466, time/update=0.009952606454967221, time/speed=90.45226607470701\n",
      "  6%|▌         | 61184/1000000 [06:47<2:52:54, 90.49it/s, r_step=-0.36, π_loss=39.823, α=0.000]step=61184 | train/step_reward_mean=-0.005426603835076094, train/step_reward_std=0.6362979412078857, train/step_reward_max=1.7241486310958862, train/step_reward_min=-1.7459757328033447, episode/length=1000.0, episode/return=-293.088430060715, episode/return_latest=-325.9302978515625, episode/num_completed=61.0, train/loss_actor=40.28239822387695, train/loss_qvalue=8.986058235168457, train/loss_alpha=-47.00083923339844, train/alpha=9.996994776884094e-05, time/collect=0.14969578547457782, time/replay_extend=0.0005661214245911926, time/train=1.5623503190204195, time/rb - sample=0.0003082396619966316, time/update=0.00994970726872418, time/speed=90.4899462599878\n",
      "  6%|▌         | 61440/1000000 [06:49<2:50:38, 91.67it/s, r_step=-0.01, r_ep=-293.1, n_ep=61, π_loss=40.282, α=0.000]step=61440 | train/step_reward_mean=-0.405198872089386, train/step_reward_std=0.5950000882148743, train/step_reward_max=1.0577338933944702, train/step_reward_min=-2.069875955581665, train/loss_actor=40.645572662353516, train/loss_qvalue=9.017887115478516, train/loss_alpha=-46.99394607543945, train/alpha=9.997004963224754e-05, time/collect=0.14982063670953125, time/replay_extend=0.0005667348702748621, time/train=1.5671188116073616, time/rb - sample=0.0003082351824203555, time/update=0.009951821372069314, time/speed=91.67278565574483\n",
      "  6%|▌         | 61696/1000000 [06:52<2:52:22, 90.73it/s, r_step=-0.41, π_loss=40.646, α=0.000]                      step=61696 | train/step_reward_mean=-0.19581520557403564, train/step_reward_std=0.6604820489883423, train/step_reward_max=1.3787121772766113, train/step_reward_min=-2.360031843185425, train/loss_actor=41.037445068359375, train/loss_qvalue=8.995933532714844, train/loss_alpha=-47.00493621826172, train/alpha=9.996994776884094e-05, time/collect=0.14993946087310928, time/replay_extend=0.0005667625126502331, time/train=1.5718190432584145, time/rb - sample=0.0003082750028827113, time/update=0.009953674543390311, time/speed=90.72683962517395\n",
      "  6%|▌         | 61952/1000000 [06:55<2:53:20, 90.19it/s, r_step=-0.20, π_loss=41.037, α=0.000]step=61952 | train/step_reward_mean=-0.22703729569911957, train/step_reward_std=0.6802787184715271, train/step_reward_max=1.7445685863494873, train/step_reward_min=-2.091099262237549, train/loss_actor=41.4343376159668, train/loss_qvalue=8.93442440032959, train/loss_alpha=-46.9843635559082, train/alpha=9.997004963224754e-05, time/collect=0.15004706185711325, time/replay_extend=0.0005700026661896514, time/train=1.5762511698667676, time/rb - sample=0.0003083025137412131, time/update=0.009954019937792784, time/speed=90.18964758878485\n",
      "  6%|▌         | 62208/1000000 [06:58<2:52:55, 90.38it/s, r_step=-0.23, π_loss=41.434, α=0.000]step=62208 | train/step_reward_mean=-0.33138418197631836, train/step_reward_std=0.6810712814331055, train/step_reward_max=1.314408540725708, train/step_reward_min=-2.05549693107605, episode/length=1000.0, episode/return=-291.75757881902877, episode/return_latest=-210.57565307617188, episode/num_completed=62.0, train/loss_actor=41.906028747558594, train/loss_qvalue=9.095182418823242, train/loss_alpha=-46.96403884887695, train/alpha=9.997004963224754e-05, time/collect=0.15013506775530286, time/replay_extend=0.0005704434320269304, time/train=1.5809115804271943, time/rb - sample=0.0003083239322247568, time/update=0.009956087317470871, time/speed=90.38312835184222\n",
      "  6%|▌         | 62464/1000000 [07:01<2:53:52, 89.86it/s, r_step=-0.33, r_ep=-291.8, n_ep=62, π_loss=41.906, α=0.000]step=62464 | train/step_reward_mean=-0.16159281134605408, train/step_reward_std=0.6853106617927551, train/step_reward_max=1.6232903003692627, train/step_reward_min=-2.3779141902923584, train/loss_actor=42.30078887939453, train/loss_qvalue=9.01235580444336, train/loss_alpha=-46.993797302246094, train/alpha=9.996994776884094e-05, time/collect=0.15024148538464416, time/replay_extend=0.0005708375915152134, time/train=1.5852969933728713, time/rb - sample=0.0003083435134315974, time/update=0.009956593010701356, time/speed=89.86319747572989\n",
      "  6%|▋         | 62720/1000000 [07:04<2:53:29, 90.04it/s, r_step=-0.16, π_loss=42.301, α=0.000]                      step=62720 | train/step_reward_mean=-0.2561928331851959, train/step_reward_std=0.7315571308135986, train/step_reward_max=1.4702067375183105, train/step_reward_min=-2.3998498916625977, train/loss_actor=42.64649963378906, train/loss_qvalue=9.08758544921875, train/loss_alpha=-46.98353576660156, train/alpha=9.996994776884094e-05, time/collect=0.1503511565072197, time/replay_extend=0.0005719418428382101, time/train=1.589384431255108, time/rb - sample=0.0003082759967828924, time/update=0.009955481072334097, time/speed=90.04230192882432\n",
      "  6%|▋         | 62976/1000000 [07:06<2:52:03, 90.77it/s, r_step=-0.26, π_loss=42.646, α=0.000]step=62976 | train/step_reward_mean=-0.3582218885421753, train/step_reward_std=0.7260456085205078, train/step_reward_max=1.8997716903686523, train/step_reward_min=-2.5228652954101562, train/loss_actor=43.143070220947266, train/loss_qvalue=9.092865943908691, train/loss_alpha=-46.991294860839844, train/alpha=9.997004963224754e-05, time/collect=0.15045518312996978, time/replay_extend=0.0005721377163398563, time/train=1.5931866634182823, time/rb - sample=0.0003082508271272549, time/update=0.009952721542260078, time/speed=90.77005056732915\n",
      "  6%|▋         | 63232/1000000 [07:09<2:49:51, 91.92it/s, r_step=-0.36, π_loss=43.143, α=0.000]step=63232 | train/step_reward_mean=-0.0720338374376297, train/step_reward_std=0.5345674157142639, train/step_reward_max=1.2555019855499268, train/step_reward_min=-1.7083091735839844, episode/length=1000.0, episode/return=-291.61736830454026, episode/return_latest=-282.92431640625, episode/num_completed=63.0, train/loss_actor=43.44816589355469, train/loss_qvalue=8.847787857055664, train/loss_alpha=-46.980873107910156, train/alpha=9.997004963224754e-05, time/collect=0.1505593104883728, time/replay_extend=0.0005727769874850754, time/train=1.5975562242361223, time/rb - sample=0.00030830398822824046, time/update=0.009953765800843721, time/speed=91.91950060235487\n",
      "  6%|▋         | 63488/1000000 [07:12<2:50:56, 91.31it/s, r_step=-0.07, r_ep=-291.6, n_ep=63, π_loss=43.448, α=0.000]step=63488 | train/step_reward_mean=-0.25103479623794556, train/step_reward_std=0.5517098307609558, train/step_reward_max=1.2539589405059814, train/step_reward_min=-1.8275426626205444, train/loss_actor=43.80476760864258, train/loss_qvalue=8.977510452270508, train/loss_alpha=-46.99049758911133, train/alpha=9.996994776884094e-05, time/collect=0.15064843816141937, time/replay_extend=0.0005726737360800472, time/train=1.6019101210178874, time/rb - sample=0.0003083910089948309, time/update=0.009954885425453239, time/speed=91.31028448090308\n",
      "  6%|▋         | 63744/1000000 [07:15<2:51:48, 90.83it/s, r_step=-0.25, π_loss=43.805, α=0.000]                      step=63744 | train/step_reward_mean=-0.26360654830932617, train/step_reward_std=0.5885185599327087, train/step_reward_max=1.33506441116333, train/step_reward_min=-1.955260157585144, train/loss_actor=44.14925765991211, train/loss_qvalue=8.847129821777344, train/loss_alpha=-46.985015869140625, train/alpha=9.996994776884094e-05, time/collect=0.15074368174296315, time/replay_extend=0.0005728585653036958, time/train=1.6059746024120292, time/rb - sample=0.00030838412624832796, time/update=0.00995445543728581, time/speed=90.82773869321987\n",
      "  6%|▋         | 64000/1000000 [07:18<2:51:17, 91.08it/s, r_step=-0.26, π_loss=44.149, α=0.000]step=64000 | train/step_reward_mean=-0.24521604180335999, train/step_reward_std=0.5615570545196533, train/step_reward_max=1.3818670511245728, train/step_reward_min=-1.831039309501648, episode/length=1000.0, episode/return=-290.2768191099167, episode/return_latest=-205.8222198486328, episode/num_completed=64.0, train/loss_actor=44.5042839050293, train/loss_qvalue=8.923973083496094, train/loss_alpha=-46.969635009765625, train/alpha=9.996994776884094e-05, time/collect=0.1508498125076295, time/replay_extend=0.0005729990005493169, time/train=1.6098641815185555, time/rb - sample=0.00030838313445546235, time/update=0.009953117807657593, time/speed=91.07578207828865\n",
      "  6%|▋         | 64256/1000000 [07:20<2:50:13, 91.62it/s, r_step=-0.25, r_ep=-290.3, n_ep=64, π_loss=44.504, α=0.000]step=64256 | train/step_reward_mean=-0.49659252166748047, train/step_reward_std=0.6806312799453735, train/step_reward_max=1.5565310716629028, train/step_reward_min=-2.0542187690734863, train/loss_actor=44.875999450683594, train/loss_qvalue=9.030391693115234, train/loss_alpha=-46.98773956298828, train/alpha=9.997004963224754e-05, time/collect=0.15093736154624676, time/replay_extend=0.0005737547855453192, time/train=1.6138424122950954, time/rb - sample=0.00030841658424053827, time/update=0.009952524422922023, time/speed=91.618836434417\n",
      "  6%|▋         | 64512/1000000 [07:23<2:49:59, 91.72it/s, r_step=-0.50, π_loss=44.876, α=0.000]                      step=64512 | train/step_reward_mean=-0.12422257661819458, train/step_reward_std=0.652262270450592, train/step_reward_max=1.5619397163391113, train/step_reward_min=-1.535117268562317, train/loss_actor=45.176822662353516, train/loss_qvalue=9.011524200439453, train/loss_alpha=-46.988868713378906, train/alpha=9.997004963224754e-05, time/collect=0.15102780149096545, time/replay_extend=0.0005738574361044268, time/train=1.6178694367408761, time/rb - sample=0.0003084863265675883, time/update=0.009952412804048, time/speed=91.7185299315968\n",
      "  6%|▋         | 64768/1000000 [07:26<2:50:09, 91.60it/s, r_step=-0.12, π_loss=45.177, α=0.000]step=64768 | train/step_reward_mean=-0.2236015796661377, train/step_reward_std=0.6118514537811279, train/step_reward_max=1.605698823928833, train/step_reward_min=-1.8846629858016968, train/loss_actor=45.61872863769531, train/loss_qvalue=9.156858444213867, train/loss_alpha=-46.98065185546875, train/alpha=9.997004963224754e-05, time/collect=0.1511119184757882, time/replay_extend=0.000574345645226038, time/train=1.62201163420093, time/rb - sample=0.0003085001610601549, time/update=0.009953285316721851, time/speed=91.60457694833487\n",
      "  7%|▋         | 65024/1000000 [07:29<2:50:53, 91.18it/s, r_step=-0.22, π_loss=45.619, α=0.000]step=65024 | train/step_reward_mean=-0.015068226493895054, train/step_reward_std=0.5369859933853149, train/step_reward_max=1.630057454109192, train/step_reward_min=-1.2819993495941162, episode/length=1000.0, episode/return=-289.0171941903921, episode/return_latest=-208.4011993408203, episode/num_completed=65.0, train/loss_actor=45.89260482788086, train/loss_qvalue=8.978155136108398, train/loss_alpha=-46.96391296386719, train/alpha=9.996994776884094e-05, time/collect=0.1511862428169552, time/replay_extend=0.000574760549650418, time/train=1.6260742887737252, time/rb - sample=0.0003085824821120604, time/update=0.009953782336110249, time/speed=91.18275840041439\n",
      "  7%|▋         | 65280/1000000 [07:32<2:51:20, 90.92it/s, r_step=-0.02, r_ep=-289.0, n_ep=65, π_loss=45.893, α=0.000]step=65280 | train/step_reward_mean=-0.4647352993488312, train/step_reward_std=0.7311173677444458, train/step_reward_max=1.4487221240997314, train/step_reward_min=-2.3889849185943604, train/loss_actor=46.25572967529297, train/loss_qvalue=9.159870147705078, train/loss_alpha=-46.98406219482422, train/alpha=9.997004963224754e-05, time/collect=0.15129200056487452, time/replay_extend=0.0005751460206274896, time/train=1.6302964818243895, time/rb - sample=0.0003086098210438132, time/update=0.00995553774712028, time/speed=90.92374709359632\n",
      "  7%|▋         | 65536/1000000 [07:35<2:52:42, 90.18it/s, r_step=-0.46, π_loss=46.256, α=0.000]                      step=65536 | train/step_reward_mean=-0.6176693439483643, train/step_reward_std=0.7175942659378052, train/step_reward_max=1.839308261871338, train/step_reward_min=-2.6104767322540283, train/loss_actor=46.61319351196289, train/loss_qvalue=9.16195011138916, train/loss_alpha=-46.99973678588867, train/alpha=9.996994776884094e-05, time/collect=0.1514273248612882, time/replay_extend=0.0005753803998231891, time/train=1.634407468140126, time/rb - sample=0.00030868995419275715, time/update=0.009956725679759821, time/speed=90.17962940218501\n",
      "  7%|▋         | 65792/1000000 [07:37<2:53:02, 89.98it/s, r_step=-0.62, π_loss=46.613, α=0.000]step=65792 | train/step_reward_mean=-0.10513217747211456, train/step_reward_std=0.7215524911880493, train/step_reward_max=2.0418338775634766, train/step_reward_min=-1.9541354179382324, train/loss_actor=46.94883346557617, train/loss_qvalue=9.140541076660156, train/loss_alpha=-46.98197555541992, train/alpha=9.997004963224754e-05, time/collect=0.1515188449087775, time/replay_extend=0.0005754404030885217, time/train=1.638194420922128, time/rb - sample=0.00030873095383867526, time/update=0.009956104314187654, time/speed=89.98315407200958\n",
      "  7%|▋         | 66048/1000000 [07:40<2:51:53, 90.56it/s, r_step=-0.11, π_loss=46.949, α=0.000]step=66048 | train/step_reward_mean=-0.28707048296928406, train/step_reward_std=0.8201167583465576, train/step_reward_max=1.659677267074585, train/step_reward_min=-2.806624412536621, episode/length=1000.0, episode/return=-290.2323253515995, episode/return_latest=-369.2158508300781, episode/num_completed=66.0, train/loss_actor=47.262901306152344, train/loss_qvalue=9.225461959838867, train/loss_alpha=-46.986690521240234, train/alpha=9.996994776884094e-05, time/collect=0.151612771573917, time/replay_extend=0.0005756191505018134, time/train=1.6420615698940078, time/rb - sample=0.0003087671924822071, time/update=0.00995618174928512, time/speed=90.55500423295153\n",
      "  7%|▋         | 66304/1000000 [07:43<2:51:30, 90.73it/s, r_step=-0.29, r_ep=-290.2, n_ep=66, π_loss=47.263, α=0.000]step=66304 | train/step_reward_mean=-0.3663749396800995, train/step_reward_std=0.6685351729393005, train/step_reward_max=1.669912338256836, train/step_reward_min=-1.9438633918762207, train/loss_actor=47.64598083496094, train/loss_qvalue=9.058481216430664, train/loss_alpha=-46.973506927490234, train/alpha=9.997004963224754e-05, time/collect=0.15168635357300758, time/replay_extend=0.0005756565962979235, time/train=1.645786616793011, time/rb - sample=0.0003087564865932044, time/update=0.00995560445719304, time/speed=90.73461836627058\n",
      "  7%|▋         | 66560/1000000 [07:46<2:50:49, 91.07it/s, r_step=-0.37, π_loss=47.646, α=0.000]                      step=66560 | train/step_reward_mean=-0.31237101554870605, train/step_reward_std=0.7025091052055359, train/step_reward_max=1.4854708909988403, train/step_reward_min=-2.070403814315796, train/loss_actor=48.05148696899414, train/loss_qvalue=9.067500114440918, train/loss_alpha=-46.96979522705078, train/alpha=9.997004963224754e-05, time/collect=0.15178691974053027, time/replay_extend=0.0005758468921367942, time/train=1.6496643552413361, time/rb - sample=0.0003087094076480592, time/update=0.00995619848736234, time/speed=91.07391572651764\n",
      "  7%|▋         | 66816/1000000 [07:49<2:51:09, 90.87it/s, r_step=-0.31, π_loss=48.051, α=0.000]step=66816 | train/step_reward_mean=-0.21059420704841614, train/step_reward_std=0.555030107498169, train/step_reward_max=1.4122323989868164, train/step_reward_min=-2.196451187133789, train/loss_actor=48.37578201293945, train/loss_qvalue=9.136441230773926, train/loss_alpha=-46.99082946777344, train/alpha=9.996994776884094e-05, time/collect=0.1518716985695208, time/replay_extend=0.0005758018785966313, time/train=1.6533558240795507, time/rb - sample=0.00030892980625716563, time/update=0.009955542928698305, time/speed=90.86850596433655\n",
      "  7%|▋         | 67072/1000000 [07:51<2:50:35, 91.15it/s, r_step=-0.21, π_loss=48.376, α=0.000]step=67072 | train/step_reward_mean=-0.45975080132484436, train/step_reward_std=0.6336912512779236, train/step_reward_max=1.3360568284988403, train/step_reward_min=-2.3425817489624023, episode/length=1000.0, episode/return=-290.78315951219247, episode/return_latest=-327.1382141113281, episode/num_completed=67.0, train/loss_actor=48.64508819580078, train/loss_qvalue=9.100847244262695, train/loss_alpha=-46.97844314575195, train/alpha=9.996994776884094e-05, time/collect=0.1519543251008479, time/replay_extend=0.0005760602368653279, time/train=1.657169250131564, time/rb - sample=0.0003089553140329578, time/update=0.009956019546723805, time/speed=91.14878817561997\n",
      "  7%|▋         | 67328/1000000 [07:54<2:51:00, 90.90it/s, r_step=-0.46, r_ep=-290.8, n_ep=67, π_loss=48.645, α=0.000]step=67328 | train/step_reward_mean=-0.3221569061279297, train/step_reward_std=0.7421318888664246, train/step_reward_max=1.854256510734558, train/step_reward_min=-2.2147574424743652, train/loss_actor=49.033016204833984, train/loss_qvalue=9.27807331085205, train/loss_alpha=-46.99795913696289, train/alpha=9.997004963224754e-05, time/collect=0.15206243783348874, time/replay_extend=0.0005763619571584263, time/train=1.660949241979041, time/rb - sample=0.00030908766707562395, time/update=0.009956357417156968, time/speed=90.89568633355596\n",
      "  7%|▋         | 67584/1000000 [07:57<2:51:13, 90.76it/s, r_step=-0.32, π_loss=49.033, α=0.000]                      step=67584 | train/step_reward_mean=-0.10748647898435593, train/step_reward_std=0.7988545298576355, train/step_reward_max=2.2168142795562744, train/step_reward_min=-1.9427297115325928, train/loss_actor=49.36048126220703, train/loss_qvalue=9.330863952636719, train/loss_alpha=-46.98931121826172, train/alpha=9.996994776884094e-05, time/collect=0.15215858184930056, time/replay_extend=0.0005768013722968827, time/train=1.6644440446839193, time/rb - sample=0.0003091358819496837, time/update=0.009955189252149629, time/speed=90.75898865521933\n",
      "  7%|▋         | 67840/1000000 [08:00<2:50:10, 91.29it/s, r_step=-0.11, π_loss=49.360, α=0.000]step=67840 | train/step_reward_mean=-0.46371757984161377, train/step_reward_std=0.8582903742790222, train/step_reward_max=1.811220645904541, train/step_reward_min=-2.710825204849243, train/loss_actor=49.68657684326172, train/loss_qvalue=9.140985488891602, train/loss_alpha=-46.99196243286133, train/alpha=9.997004963224754e-05, time/collect=0.1522653111871684, time/replay_extend=0.0005767543360872092, time/train=1.6680280955332634, time/rb - sample=0.0003091671581690508, time/update=0.009954763565301275, time/speed=91.29157782461323\n",
      "  7%|▋         | 68096/1000000 [08:03<2:50:03, 91.33it/s, r_step=-0.46, π_loss=49.687, α=0.000]step=68096 | train/step_reward_mean=-0.18636853992938995, train/step_reward_std=0.7440506219863892, train/step_reward_max=1.6698411703109741, train/step_reward_min=-2.1144585609436035, episode/length=1000.0, episode/return=-290.39721331876865, episode/return_latest=-264.538818359375, episode/num_completed=68.0, train/loss_actor=49.98875427246094, train/loss_qvalue=9.387356758117676, train/loss_alpha=-46.987831115722656, train/alpha=9.996994776884094e-05, time/collect=0.15237705062206533, time/replay_extend=0.0005771602903093615, time/train=1.6718240608846338, time/rb - sample=0.00030922455459656727, time/update=0.009955783176219396, time/speed=91.32990182978152\n",
      "  7%|▋         | 68352/1000000 [08:05<2:50:57, 90.83it/s, r_step=-0.19, r_ep=-290.4, n_ep=68, π_loss=49.989, α=0.000]step=68352 | train/step_reward_mean=-0.3860052824020386, train/step_reward_std=0.6528304219245911, train/step_reward_max=1.3310376405715942, train/step_reward_min=-2.47265887260437, train/loss_actor=50.36056900024414, train/loss_qvalue=9.433320999145508, train/loss_alpha=-46.99584197998047, train/alpha=9.996994776884094e-05, time/collect=0.15246197079004872, time/replay_extend=0.0005771506591682581, time/train=1.6760398555784193, time/rb - sample=0.00030927914468681036, time/update=0.009959544674219533, time/speed=90.82744515911138\n",
      "  7%|▋         | 68608/1000000 [08:08<2:53:37, 89.40it/s, r_step=-0.39, π_loss=50.361, α=0.000]                      step=68608 | train/step_reward_mean=-0.3347010612487793, train/step_reward_std=0.6250406503677368, train/step_reward_max=1.1924307346343994, train/step_reward_min=-2.2968287467956543, train/loss_actor=50.695533752441406, train/loss_qvalue=9.285384178161621, train/loss_alpha=-46.98817825317383, train/alpha=9.996994776884094e-05, time/collect=0.15252326940422634, time/replay_extend=0.0005771072942819172, time/train=1.6794098491099347, time/rb - sample=0.0003092974173830954, time/update=0.009958313603760295, time/speed=89.4046194722283\n",
      "  7%|▋         | 68864/1000000 [08:11<2:51:39, 90.40it/s, r_step=-0.33, π_loss=50.696, α=0.000]step=68864 | train/step_reward_mean=-0.20168699324131012, train/step_reward_std=0.6283939480781555, train/step_reward_max=1.429625391960144, train/step_reward_min=-1.9707907438278198, train/loss_actor=50.96751022338867, train/loss_qvalue=9.386548042297363, train/loss_alpha=-46.99087905883789, train/alpha=9.996994776884094e-05, time/collect=0.15261396865419302, time/replay_extend=0.0005766769324093507, time/train=1.683111267018939, time/rb - sample=0.00030925795760785343, time/update=0.009959333402992767, time/speed=90.40445402441861\n",
      "  7%|▋         | 69120/1000000 [08:14<2:52:00, 90.20it/s, r_step=-0.20, π_loss=50.968, α=0.000]step=69120 | train/step_reward_mean=-0.40486323833465576, train/step_reward_std=0.6926814913749695, train/step_reward_max=1.0872002840042114, train/step_reward_min=-2.6795146465301514, episode/length=1000.0, episode/return=-290.9010041831196, episode/return_latest=-325.1587829589844, episode/num_completed=69.0, train/loss_actor=51.29381561279297, train/loss_qvalue=9.399246215820312, train/loss_alpha=-46.98481369018555, train/alpha=9.997004963224754e-05, time/collect=0.1527030370853566, time/replay_extend=0.000576612684461806, time/train=1.6866421363971855, time/rb - sample=0.00030919656997298843, time/update=0.009959491766515595, time/speed=90.19802731433603\n",
      "  7%|▋         | 69376/1000000 [08:17<2:51:46, 90.30it/s, r_step=-0.40, r_ep=-290.9, n_ep=69, π_loss=51.294, α=0.000]step=69376 | train/step_reward_mean=-0.266000360250473, train/step_reward_std=0.8291627764701843, train/step_reward_max=1.4453221559524536, train/step_reward_min=-2.9464619159698486, train/loss_actor=51.55205154418945, train/loss_qvalue=9.351285934448242, train/loss_alpha=-46.98520278930664, train/alpha=9.996994776884094e-05, time/collect=0.15283037551654668, time/replay_extend=0.0005773125539406644, time/train=1.690275903117613, time/rb - sample=0.0003092711170514414, time/update=0.009960292672588673, time/speed=90.2974972505751\n",
      "  7%|▋         | 69632/1000000 [08:20<2:52:06, 90.10it/s, r_step=-0.27, π_loss=51.552, α=0.000]                      step=69632 | train/step_reward_mean=-0.4574301838874817, train/step_reward_std=0.6762604117393494, train/step_reward_max=1.208256721496582, train/step_reward_min=-2.2254786491394043, train/loss_actor=51.91263961791992, train/loss_qvalue=9.272390365600586, train/loss_alpha=-46.99749755859375, train/alpha=9.996994776884094e-05, time/collect=0.15293933801791257, time/replay_extend=0.0005777250317966241, time/train=1.6937198954470023, time/rb - sample=0.0003092807424919934, time/update=0.009960159175098045, time/speed=90.098181124273\n",
      "  7%|▋         | 69888/1000000 [08:23<2:51:27, 90.41it/s, r_step=-0.46, π_loss=51.913, α=0.000]step=69888 | train/step_reward_mean=-0.39410462975502014, train/step_reward_std=0.7422531247138977, train/step_reward_max=1.305670976638794, train/step_reward_min=-2.387943983078003, train/loss_actor=52.199764251708984, train/loss_qvalue=9.119306564331055, train/loss_alpha=-46.97511291503906, train/alpha=9.996994776884094e-05, time/collect=0.1530374834389041, time/replay_extend=0.0005779816554142883, time/train=1.6972893489586134, time/rb - sample=0.00030934407947246206, time/update=0.009960885704706752, time/speed=90.41102340545712\n",
      "  7%|▋         | 70144/1000000 [08:25<2:51:46, 90.22it/s, r_step=-0.39, π_loss=52.200, α=0.000]step=70144 | train/step_reward_mean=-0.10321000218391418, train/step_reward_std=0.6405104994773865, train/step_reward_max=1.3528234958648682, train/step_reward_min=-2.2923877239227295, episode/length=1000.0, episode/return=-291.8858495439802, episode/return_latest=-359.8401794433594, episode/num_completed=70.0, train/loss_actor=52.55299377441406, train/loss_qvalue=9.303297996520996, train/loss_alpha=-46.99639892578125, train/alpha=9.996994776884094e-05, time/collect=0.15314071891951742, time/replay_extend=0.000578175496010885, time/train=1.7006691885690626, time/rb - sample=0.00030936001889449643, time/update=0.00996066452040855, time/speed=90.22089278067867\n",
      "  7%|▋         | 70400/1000000 [08:28<2:51:05, 90.56it/s, r_step=-0.10, r_ep=-291.9, n_ep=70, π_loss=52.553, α=0.000]step=70400 | train/step_reward_mean=-0.320291668176651, train/step_reward_std=0.6188632845878601, train/step_reward_max=1.1905455589294434, train/step_reward_min=-1.9842344522476196, train/loss_actor=52.854576110839844, train/loss_qvalue=9.229640007019043, train/loss_alpha=-47.009521484375, train/alpha=9.996994776884094e-05, time/collect=0.1532276682420211, time/replay_extend=0.0005790198932994499, time/train=1.7041608593680646, time/rb - sample=0.00030939702698019026, time/update=0.009961242327110913, time/speed=90.55769009253365\n",
      "  7%|▋         | 70656/1000000 [08:31<2:51:13, 90.46it/s, r_step=-0.32, π_loss=52.855, α=0.000]                      step=70656 | train/step_reward_mean=-0.35911470651626587, train/step_reward_std=0.7902552485466003, train/step_reward_max=2.0733203887939453, train/step_reward_min=-2.3243801593780518, train/loss_actor=53.19402313232422, train/loss_qvalue=9.441423416137695, train/loss_alpha=-47.0051155090332, train/alpha=9.996994776884094e-05, time/collect=0.153294905372288, time/replay_extend=0.0005792413932689725, time/train=1.7074764509131948, time/rb - sample=0.0003094517693506267, time/update=0.009960891122217055, time/speed=90.4595414363318\n",
      "  7%|▋         | 70912/1000000 [08:34<2:50:41, 90.72it/s, r_step=-0.36, π_loss=53.194, α=0.000]step=70912 | train/step_reward_mean=-0.31733548641204834, train/step_reward_std=0.6363779306411743, train/step_reward_max=1.5047814846038818, train/step_reward_min=-1.8788697719573975, train/loss_actor=53.43411636352539, train/loss_qvalue=9.547454833984375, train/loss_alpha=-46.99257278442383, train/alpha=9.996994776884094e-05, time/collect=0.15339641794831319, time/replay_extend=0.0005794105116641051, time/train=1.7108421446183963, time/rb - sample=0.0003094761787603291, time/update=0.009961018012836675, time/speed=90.72108506375218\n",
      "  7%|▋         | 71168/1000000 [08:37<2:50:30, 90.79it/s, r_step=-0.32, π_loss=53.434, α=0.000]step=71168 | train/step_reward_mean=-0.35263779759407043, train/step_reward_std=0.6958959102630615, train/step_reward_max=1.2250136137008667, train/step_reward_min=-2.0477631092071533, episode/length=1000.0, episode/return=-291.7990783906319, episode/return_latest=-285.72509765625, episode/num_completed=71.0, train/loss_actor=53.74266815185547, train/loss_qvalue=9.42332649230957, train/loss_alpha=-46.98134994506836, train/alpha=9.997004963224754e-05, time/collect=0.15346808484989968, time/replay_extend=0.000579673609287619, time/train=1.7143608983472103, time/rb - sample=0.0003094897445970472, time/update=0.009962219168632835, time/speed=90.78844421397265\n",
      "  7%|▋         | 71424/1000000 [08:40<2:51:34, 90.20it/s, r_step=-0.35, r_ep=-291.8, n_ep=71, π_loss=53.743, α=0.000]step=71424 | train/step_reward_mean=-0.19979223608970642, train/step_reward_std=0.6256225109100342, train/step_reward_max=1.3824182748794556, train/step_reward_min=-1.9047188758850098, train/loss_actor=53.99844741821289, train/loss_qvalue=9.60200023651123, train/loss_alpha=-46.98151397705078, train/alpha=9.996994776884094e-05, time/collect=0.15359975702019152, time/replay_extend=0.0005801715303920079, time/train=1.7182034668529338, time/rb - sample=0.00030952223300278743, time/update=0.009965477736441748, time/speed=90.19907331365259\n",
      "  7%|▋         | 71680/1000000 [08:42<2:53:49, 89.01it/s, r_step=-0.20, π_loss=53.998, α=0.000]                      step=71680 | train/step_reward_mean=-0.29105454683303833, train/step_reward_std=0.5353394746780396, train/step_reward_max=1.0277698040008545, train/step_reward_min=-1.9202947616577148, train/loss_actor=54.23536682128906, train/loss_qvalue=9.527177810668945, train/loss_alpha=-46.982975006103516, train/alpha=9.996994776884094e-05, time/collect=0.15368088654109416, time/replay_extend=0.0005804674965994702, time/train=1.721335158177785, time/rb - sample=0.0003095227013764477, time/update=0.009964649148204063, time/speed=89.00910504290594\n",
      "  7%|▋         | 71936/1000000 [08:45<2:51:55, 89.97it/s, r_step=-0.29, π_loss=54.235, α=0.000]step=71936 | train/step_reward_mean=-0.2807452082633972, train/step_reward_std=0.5220622420310974, train/step_reward_max=0.9940409660339355, train/step_reward_min=-2.2024738788604736, train/loss_actor=54.43789291381836, train/loss_qvalue=9.363883972167969, train/loss_alpha=-46.984458923339844, train/alpha=9.997004963224754e-05, time/collect=0.1537562960831721, time/replay_extend=0.0005815690946748675, time/train=1.7245166768382882, time/rb - sample=0.0003095518787512948, time/update=0.009964229437806135, time/speed=89.9662732497486\n",
      "  7%|▋         | 72192/1000000 [08:48<2:51:04, 90.39it/s, r_step=-0.28, π_loss=54.438, α=0.000]step=72192 | train/step_reward_mean=-0.42334893345832825, train/step_reward_std=0.6755675673484802, train/step_reward_max=1.271270751953125, train/step_reward_min=-2.6506032943725586, episode/length=1000.0, episode/return=-291.8842414220174, episode/return_latest=-297.9308166503906, episode/num_completed=72.0, train/loss_actor=54.68257522583008, train/loss_qvalue=9.320984840393066, train/loss_alpha=-46.99979782104492, train/alpha=9.996994776884094e-05, time/collect=0.15386147617448315, time/replay_extend=0.0005815485690502414, time/train=1.727812012882098, time/rb - sample=0.00030957774536029633, time/update=0.009964629841616128, time/speed=90.39312850094106\n",
      "  7%|▋         | 72448/1000000 [08:51<2:51:00, 90.40it/s, r_step=-0.42, r_ep=-291.9, n_ep=72, π_loss=54.683, α=0.000]step=72448 | train/step_reward_mean=-0.13092277944087982, train/step_reward_std=0.6808204054832458, train/step_reward_max=1.5479393005371094, train/step_reward_min=-2.223883867263794, train/loss_actor=55.006404876708984, train/loss_qvalue=9.451384544372559, train/loss_alpha=-47.001739501953125, train/alpha=9.997004963224754e-05, time/collect=0.15393930526167268, time/replay_extend=0.0005823302184735089, time/train=1.7312271620275281, time/rb - sample=0.000309550523838048, time/update=0.009965922848712169, time/speed=90.3995233447437\n",
      "  7%|▋         | 72704/1000000 [08:54<2:51:45, 89.98it/s, r_step=-0.13, π_loss=55.006, α=0.000]                      step=72704 | train/step_reward_mean=-0.1374831199645996, train/step_reward_std=0.5612999200820923, train/step_reward_max=1.5828062295913696, train/step_reward_min=-1.6129891872406006, train/loss_actor=55.19101333618164, train/loss_qvalue=9.221585273742676, train/loss_alpha=-46.98869705200195, train/alpha=9.997004963224754e-05, time/collect=0.15402848032158872, time/replay_extend=0.0005823617250147003, time/train=1.734603473837947, time/rb - sample=0.0003096472750851178, time/update=0.009966997609020678, time/speed=89.98180930132774\n",
      "  7%|▋         | 72960/1000000 [08:57<2:52:07, 89.76it/s, r_step=-0.14, π_loss=55.191, α=0.000]step=72960 | train/step_reward_mean=-0.27190566062927246, train/step_reward_std=0.4952036738395691, train/step_reward_max=0.8787326216697693, train/step_reward_min=-1.8151123523712158, train/loss_actor=55.40679931640625, train/loss_qvalue=9.31732177734375, train/loss_alpha=-46.97175598144531, train/alpha=9.996994776884094e-05, time/collect=0.1541070519832143, time/replay_extend=0.0005825795625385487, time/train=1.7377017506381927, time/rb - sample=0.00030973560097528234, time/update=0.009966559485195607, time/speed=89.76207815088219\n",
      "  7%|▋         | 73216/1000000 [08:59<2:51:11, 90.23it/s, r_step=-0.27, π_loss=55.407, α=0.000]step=73216 | train/step_reward_mean=-0.28380945324897766, train/step_reward_std=0.666195273399353, train/step_reward_max=1.8635092973709106, train/step_reward_min=-2.015892744064331, episode/length=1000.0, episode/return=-291.14112153771805, episode/return_latest=-237.63648986816406, episode/num_completed=73.0, train/loss_actor=55.73240661621094, train/loss_qvalue=9.260381698608398, train/loss_alpha=-46.979488372802734, train/alpha=9.996994776884094e-05, time/collect=0.1542017359833618, time/replay_extend=0.0005838320805476264, time/train=1.7412410757758405, time/rb - sample=0.00030980018711594616, time/update=0.00996888318547508, time/speed=90.22552728848397\n",
      "  7%|▋         | 73472/1000000 [09:02<2:52:46, 89.38it/s, r_step=-0.28, r_ep=-291.1, n_ep=73, π_loss=55.732, α=0.000]step=73472 | train/step_reward_mean=-0.21235230565071106, train/step_reward_std=0.7202656269073486, train/step_reward_max=1.2458455562591553, train/step_reward_min=-2.0903141498565674, train/loss_actor=55.9724235534668, train/loss_qvalue=9.422146797180176, train/loss_alpha=-46.98633575439453, train/alpha=9.997004963224754e-05, time/collect=0.15427276481734756, time/replay_extend=0.0005840897975483009, time/train=1.7444078307533935, time/rb - sample=0.00030978841118906595, time/update=0.009969207546428757, time/speed=89.37666322487816\n",
      "  7%|▋         | 73728/1000000 [09:05<2:52:00, 89.75it/s, r_step=-0.21, π_loss=55.972, α=0.000]                      step=73728 | train/step_reward_mean=0.011156238615512848, train/step_reward_std=0.7253934741020203, train/step_reward_max=1.5833513736724854, train/step_reward_min=-1.8943027257919312, train/loss_actor=56.216590881347656, train/loss_qvalue=9.259262084960938, train/loss_alpha=-46.9815559387207, train/alpha=9.997004963224754e-05, time/collect=0.15433502362834087, time/replay_extend=0.000584647059440613, time/train=1.747477514048418, time/rb - sample=0.0003097894655160246, time/update=0.009969073586673156, time/speed=89.75244812915147\n",
      "  7%|▋         | 73984/1000000 [09:08<2:51:03, 90.23it/s, r_step=0.01, π_loss=56.217, α=0.000] step=73984 | train/step_reward_mean=0.1256965696811676, train/step_reward_std=0.5819157361984253, train/step_reward_max=2.3279528617858887, train/step_reward_min=-1.8640714883804321, train/loss_actor=56.417076110839844, train/loss_qvalue=9.374247550964355, train/loss_alpha=-47.00847244262695, train/alpha=9.996994776884094e-05, time/collect=0.1543947091152099, time/replay_extend=0.0005846601044017965, time/train=1.750342787343326, time/rb - sample=0.00030980151495896166, time/update=0.00996785373718025, time/speed=90.22715634210886\n",
      "  7%|▋         | 74240/1000000 [09:11<2:49:30, 91.03it/s, r_step=0.13, π_loss=56.417, α=0.000]step=74240 | train/step_reward_mean=-0.23421254754066467, train/step_reward_std=0.7648892402648926, train/step_reward_max=1.7839503288269043, train/step_reward_min=-2.252704620361328, episode/length=1000.0, episode/return=-288.26333690334013, episode/return_latest=-78.18505859375, episode/num_completed=74.0, train/loss_actor=56.65575408935547, train/loss_qvalue=9.33156681060791, train/loss_alpha=-46.97643280029297, train/alpha=9.997004963224754e-05, time/collect=0.15447125106022278, time/replay_extend=0.0005846993676547348, time/train=1.7535549048719739, time/rb - sample=0.0003098358202320292, time/update=0.009968775001214701, time/speed=91.02755695422765\n",
      "  7%|▋         | 74496/1000000 [09:14<2:50:23, 90.52it/s, r_step=-0.23, r_ep=-288.3, n_ep=74, π_loss=56.656, α=0.000]step=74496 | train/step_reward_mean=-0.5139238238334656, train/step_reward_std=0.5901927947998047, train/step_reward_max=1.1926000118255615, train/step_reward_min=-1.7484558820724487, train/loss_actor=56.98081970214844, train/loss_qvalue=9.360055923461914, train/loss_alpha=-47.004371643066406, train/alpha=9.996994776884094e-05, time/collect=0.15455282021224298, time/replay_extend=0.0005845450044087939, time/train=1.7564905992488273, time/rb - sample=0.0003098922724038656, time/update=0.00996817270601085, time/speed=90.52289350779056\n",
      "  7%|▋         | 74752/1000000 [09:16<2:49:40, 90.89it/s, r_step=-0.51, π_loss=56.981, α=0.000]                      step=74752 | train/step_reward_mean=-0.08528193086385727, train/step_reward_std=0.7097983360290527, train/step_reward_max=1.8419603109359741, train/step_reward_min=-1.8305805921554565, train/loss_actor=57.13563537597656, train/loss_qvalue=9.349903106689453, train/loss_alpha=-46.977821350097656, train/alpha=9.996994776884094e-05, time/collect=0.15464174257565855, time/replay_extend=0.000584800765938955, time/train=1.7596932061731, time/rb - sample=0.00030995577764816634, time/update=0.009969250795741985, time/speed=90.88849557474342\n",
      "  8%|▊         | 75008/1000000 [09:19<2:50:36, 90.36it/s, r_step=-0.09, π_loss=57.136, α=0.000]step=75008 | train/step_reward_mean=-0.5004734992980957, train/step_reward_std=0.6254257559776306, train/step_reward_max=1.6148158311843872, train/step_reward_min=-2.174947500228882, episode/length=1000.0, episode/return=-288.96399281819663, episode/return_latest=-340.8125305175781, episode/num_completed=75.0, train/loss_actor=57.40822219848633, train/loss_qvalue=9.395251274108887, train/loss_alpha=-46.98366928100586, train/alpha=9.997004963224754e-05, time/collect=0.15472205262949038, time/replay_extend=0.0005852744847841231, time/train=1.762359913705559, time/rb - sample=0.00030995492481303283, time/update=0.009967381757094964, time/speed=90.35951902330265\n",
      "  8%|▊         | 75264/1000000 [09:22<2:48:25, 91.51it/s, r_step=-0.50, r_ep=-289.0, n_ep=75, π_loss=57.408, α=0.000]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Converting a tensordict to boolean value is not permitted",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/objectives/utils.py:532\u001b[39m, in \u001b[36m_vmap_func.<locals>.decorated_module\u001b[39m\u001b[34m(*module_args_params)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     r = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/sequence.py:633\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/sequence.py:579\u001b[39m, in \u001b[36mTensorDictSequential._run_module\u001b[39m\u001b[34m(self, module, tensordict, **kwargs)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    577\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensordict.keys(include_nested=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.in_keys\n\u001b[32m    578\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     tensordict = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/probabilistic.py:1365\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m   1364\u001b[39m     tensordict_exec = \u001b[38;5;28mself\u001b[39m.get_dist_params(tensordict_exec, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_last_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_requires_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_requires_sample\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inplace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/probabilistic.py:614\u001b[39m, in \u001b[36mProbabilisticTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, _requires_sample)\u001b[39m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _requires_sample:\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     out_tensors = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dist_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteraction_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43minteraction_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    616\u001b[39m         \u001b[38;5;66;03m# TODO: capture contiguous error here\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/probabilistic.py:691\u001b[39m, in \u001b[36mProbabilisticTensorDictModule._dist_sample\u001b[39m\u001b[34m(self, dist, interaction_type)\u001b[39m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dist, \u001b[33m\"\u001b[39m\u001b[33mdeterministic_sample\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeterministic_sample\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    693\u001b[39m     \u001b[38;5;66;03m# Fallbacks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/modules/distributions/continuous.py:477\u001b[39m, in \u001b[36mTanhNormal.deterministic_sample\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     m = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/distributions/transforms.py:161\u001b[39m, in \u001b[36mTransform.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._cache_size == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m x_old, y_old = \u001b[38;5;28mself\u001b[39m._cached_x_y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/modules/distributions/continuous.py:109\u001b[39m, in \u001b[36mSafeTanhTransform._call\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msafetanh_noeps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/autograd/function.py:576\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m     args = \u001b[43mbind_default_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    579\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/autograd/function.py:569\u001b[39m, in \u001b[36mFunction.apply.<locals>.bind_default_args\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m    568\u001b[39m signature = inspect.signature(func)\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m bound_args = \u001b[43msignature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m bound_args.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/inspect.py:3195\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3191\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3192\u001b[39m \u001b[33;03mand `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3193\u001b[39m \u001b[33;03mif the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3194\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/SL/lib/python3.11/inspect.py:3068\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3066\u001b[39m arg_vals = \u001b[38;5;28miter\u001b[39m(args)\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   3069\u001b[39m     \u001b[38;5;66;03m# Let's iterate through the positional arguments and corresponding\u001b[39;00m\n\u001b[32m   3070\u001b[39m     \u001b[38;5;66;03m# parameters\u001b[39;00m\n\u001b[32m   3071\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[32m~/.cache/ipykernel_1719719/1593614133.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m     65\u001b[39m cfg = build_halfcheetah_config(total_frames=\u001b[32m1_000_000\u001b[39m)\n\u001b[32m     66\u001b[39m train_env = env_maker(cfg, device=cfg.device)\n\u001b[32m     67\u001b[39m agent = SAC(env=train_env, config=cfg)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m agent.train()\n\u001b[32m     69\u001b[39m \n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Quick deterministic rollout on a fresh eval env to verify predict() -------\u001b[39;00m\n\u001b[32m     71\u001b[39m eval_env = env_maker(cfg, device=cfg.device)\n",
      "\u001b[32m~/Documents/Research/SkillLearning/RLOpt/rlopt/agent/sac/sac.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    468\u001b[39m \n\u001b[32m    469\u001b[39m                         \u001b[38;5;28;01mwith\u001b[39;00m timeit(\u001b[33m\"update\"\u001b[39m):\n\u001b[32m    470\u001b[39m                             torch.compiler.cudagraph_mark_step_begin()\n\u001b[32m    471\u001b[39m                             \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m                             loss = self.update(sampled_tensordict).clone()\n\u001b[32m    473\u001b[39m                         losses_list.append(\n\u001b[32m    474\u001b[39m                             loss.select(\u001b[33m\"loss_actor\"\u001b[39m, \u001b[33m\"loss_qvalue\"\u001b[39m, \u001b[33m\"loss_alpha\"\u001b[39m)\n\u001b[32m    475\u001b[39m                         )\n",
      "\u001b[32m~/Documents/Research/SkillLearning/RLOpt/rlopt/agent/sac/sac.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, sampled_tensordict)\u001b[39m\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m update(self, sampled_tensordict: TensorDict) -> TensorDict:\n\u001b[32m    349\u001b[39m         \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m         loss_td = self.loss_module(sampled_tensordict)\n\u001b[32m    351\u001b[39m         loss_td = self._sanitize_loss_tensordict(loss_td, \u001b[33m\"update:raw_loss\"\u001b[39m)\n\u001b[32m    352\u001b[39m \n\u001b[32m    353\u001b[39m         actor_loss = loss_td[\u001b[33m\"loss_actor\"\u001b[39m]\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/nn/modules/module.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _wrapped_call_impl(self, *args, **kwargs):\n\u001b[32m   1772\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self._compiled_call_impl \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1773\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._call_impl(*args, **kwargs)\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/nn/modules/module.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1907\u001b[39m                         warnings.warn(\"module forward hook with ``always_call=True`` raised an exception \"\n\u001b[32m   1908\u001b[39m                                       f\"that was silenced as another error was raised in forward: {str(e)}\")\n\u001b[32m   1909\u001b[39m                         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1910\u001b[39m             \u001b[38;5;66;03m# raise exception raised in try block\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/nn/modules/module.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1825\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m full_backward_hooks \u001b[38;5;28;01mor\u001b[39;00m backward_pre_hooks:\n\u001b[32m   1826\u001b[39m                 bw_hook = BackwardHook(self, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1827\u001b[39m                 args = bw_hook.setup_input_hook(args)\n\u001b[32m   1828\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1829\u001b[39m             result = forward_call(*args, **kwargs)\n\u001b[32m   1830\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;28;01mor\u001b[39;00m self._forward_hooks:\n\u001b[32m   1831\u001b[39m                 for hook_id, hook in (\n\u001b[32m   1832\u001b[39m                     *_global_forward_hooks.items(),\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/objectives/common.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     54\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m func(self, *args, **kwargs)\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     56\u001b[39m             em.__exit__(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m             rm.__exit__(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/nn/common.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m                 out = tuple(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;28;01min\u001b[39;00m dest)\n\u001b[32m    325\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m len(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    326\u001b[39m \n\u001b[32m    327\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m func(_self, tensordict, *args, **kwargs)\n\u001b[32m    329\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/objectives/sac.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m    616\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self._version == \u001b[32m1\u001b[39m:\n\u001b[32m    617\u001b[39m             loss_qvalue, value_metadata = self._qvalue_v1_loss(tensordict)\n\u001b[32m    618\u001b[39m             loss_value, _ = self._value_loss(tensordict)\n\u001b[32m    619\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m             loss_qvalue, value_metadata = self._qvalue_v2_loss(tensordict)\n\u001b[32m    621\u001b[39m             loss_value = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    622\u001b[39m         loss_actor, metadata_actor = self._actor_loss(tensordict)\n\u001b[32m    623\u001b[39m         loss_alpha = self._alpha_loss(log_prob=metadata_actor[\u001b[33m\"log_prob\"\u001b[39m])\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/objectives/sac.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m    914\u001b[39m     def _qvalue_v2_loss(\n\u001b[32m    915\u001b[39m         self, tensordict: TensorDictBase\n\u001b[32m    916\u001b[39m     ) -> tuple[Tensor, dict[str, Tensor]]:\n\u001b[32m    917\u001b[39m         \u001b[38;5;66;03m# we pass the alpha value to the tensordict. Since it's a scalar, we must erase the batch-size first.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m         target_value = self._compute_target_v2(tensordict)\n\u001b[32m    919\u001b[39m \n\u001b[32m    920\u001b[39m         tensordict_expand = self._vmap_qnetworkN0(\n\u001b[32m    921\u001b[39m             tensordict.select(*self.qvalue_network.in_keys, strict=\u001b[38;5;28;01mFalse\u001b[39;00m),\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/objectives/sac.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m    891\u001b[39m                         next_dist, next_action, self.tensor_keys.log_prob\n\u001b[32m    892\u001b[39m                     )\n\u001b[32m    893\u001b[39m \n\u001b[32m    894\u001b[39m             \u001b[38;5;66;03m# get q-values\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m             next_tensordict_expand = self._vmap_qnetworkN0(\n\u001b[32m    896\u001b[39m                 next_tensordict, self.target_qvalue_network_params\n\u001b[32m    897\u001b[39m             )\n\u001b[32m    898\u001b[39m             state_action_value = next_tensordict_expand.get(\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/_functorch/apis.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m         return vmap_impl(\n\u001b[32m    209\u001b[39m             func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs\n\u001b[32m    210\u001b[39m         )\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/_functorch/vmap.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    278\u001b[39m             **kwargs,\n\u001b[32m    279\u001b[39m         )\n\u001b[32m    280\u001b[39m \n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     return _flat_vmap(\n\u001b[32m    283\u001b[39m         func,\n\u001b[32m    284\u001b[39m         batch_size,\n\u001b[32m    285\u001b[39m         flat_in_dims,\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torch/_functorch/vmap.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    429\u001b[39m         batched_inputs = _create_batched_inputs(\n\u001b[32m    430\u001b[39m             flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    431\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m         batched_outputs = func(*batched_inputs, **kwargs)\n\u001b[32m    433\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/torchrl/objectives/utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*module_args_params)\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m decorated_module(*module_args_params):\n\u001b[32m    528\u001b[39m             params = module_args_params[-\u001b[32m1\u001b[39m]\n\u001b[32m    529\u001b[39m             module_args = module_args_params[:-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m params.to_module(module):\n\u001b[32m    531\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    532\u001b[39m                     r = module(*module_args)\n\u001b[32m    533\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~/miniforge3/envs/SL/lib/python3.11/site-packages/tensordict/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __bool__(self) -> bool:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m RuntimeError(\u001b[33m\"Converting a tensordict to boolean value is not permitted\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Converting a tensordict to boolean value is not permitted"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 75264/1000000 [09:40<2:48:25, 91.51it/s, r_step=-0.50, r_ep=-289.0, n_ep=75, π_loss=57.408, α=0.000]"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from rlopt.agent.sac import SAC, SACRLOptConfig\n",
    "from rlopt.config_base import NetworkConfig\n",
    "from rlopt.env_utils import env_maker\n",
    "\n",
    "\n",
    "def build_halfcheetah_config(total_frames: int = 1024) -> SACRLOptConfig:\n",
    "    \"\"\"Return a minimally tuned SAC config for HalfCheetah-v5 smoke tests.\"\"\"\n",
    "\n",
    "    cfg = SACRLOptConfig()\n",
    "    cfg.seed = 7\n",
    "    cfg.device = \"cpu\"\n",
    "\n",
    "    # Environment + collector knobs -----------------------------------------\n",
    "    cfg.env.env_name = \"HalfCheetah-v5\"\n",
    "    cfg.env.library = \"gymnasium\"\n",
    "    cfg.env.num_envs = 8\n",
    "\n",
    "    cfg.collector.frames_per_batch = 256\n",
    "    cfg.collector.total_frames = total_frames\n",
    "    cfg.collector.init_random_frames = 25_000\n",
    "    cfg.collector.prefetch = 1\n",
    "\n",
    "    # Replay + optimization -------------------------------------------------\n",
    "    cfg.loss.mini_batch_size = 256\n",
    "    cfg.replay_buffer.size = 1_000_000\n",
    "    cfg.replay_buffer.prefetch = 1\n",
    "    cfg.optim.lr = 3e-4\n",
    "    cfg.optim.scheduler = None\n",
    "    cfg.optim.target_update_polyak = 0.995\n",
    "    cfg.sac.utd_ratio = 1.0\n",
    "\n",
    "    # Lightweight logging so the notebook runs without external services ----\n",
    "    log_dir = Path.cwd() / \"notebook_logs\"\n",
    "    cfg.logger.backend = \"\"\n",
    "    cfg.logger.log_to_file = True\n",
    "    cfg.logger.log_dir = str(log_dir)\n",
    "    cfg.logger.exp_name = \"sac_halfcheetah_smoketest\"\n",
    "    cfg.logger.python_level = \"info\"\n",
    "\n",
    "    # Network dimensions depend on env specs --------------------------------\n",
    "    dummy_env = gym.make(cfg.env.env_name)\n",
    "    obs_dim = dummy_env.observation_space.shape[0]\n",
    "    action_dim = dummy_env.action_space.shape[0]\n",
    "    dummy_env.close()\n",
    "\n",
    "    cfg.policy.input_dim = obs_dim\n",
    "    cfg.policy.num_cells = [256, 256]\n",
    "    cfg.policy.activation_fn = \"relu\"\n",
    "\n",
    "    cfg.q_function = NetworkConfig(\n",
    "        num_cells=[256, 256],\n",
    "        input_dim=obs_dim + action_dim,\n",
    "        input_keys=[\"observation\", \"action\"],\n",
    "        activation_fn=\"relu\",\n",
    "    )\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "cfg = build_halfcheetah_config(total_frames=1_000_000)\n",
    "train_env = env_maker(cfg, device=cfg.device)\n",
    "agent = SAC(env=train_env, config=cfg)\n",
    "agent.train()\n",
    "\n",
    "# Quick deterministic rollout on a fresh eval env to verify predict() -------\n",
    "eval_env = env_maker(cfg, device=cfg.device)\n",
    "with torch.no_grad():\n",
    "    td = eval_env.reset().to(agent.device)\n",
    "    action = agent.predict(td.clone())\n",
    "print(f\"Deterministic action sample (shape={tuple(action.shape)}):\\n{action}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
